{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 23: Evaluator-Optimizer Pattern â€” Reviewing and Editing the Brown Agent\n",
    "\n",
    "In this lesson, we'll explore how to implement the evaluator-optimizer pattern to review and edit generated articles. Building on the foundation from Lesson 22, we'll add a quality assurance layer that ensures the generated content meets all requirements.\n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "- Understand the evaluator-optimizer pattern and its real-world applications\n",
    "- Implement an article reviewing system that checks content against multiple profiles\n",
    "- Extend the article writer to handle review feedback\n",
    "- Configure the entire system from a single YAML file\n",
    "- Glue everything together into a robust LangGraph workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> ðŸ’¡ Remember that you can also run `brown` as a standalone Python package by going to `lessons/writing_workflow/` and following the instructions from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we define some standard Magic Python commands to autoreload Python packages whenever they change:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Python Environment\n",
    "\n",
    "To set up your Python virtual environment using `uv` and load it into the Notebook, follow the step-by-step instructions from the `Course Admin` lesson from the beginning of the course.\n",
    "\n",
    "**TL/DR:** Be sure the correct kernel pointing to your `uv` virtual environment is selected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API\n",
    "\n",
    "To run this lesson, you'll need several API keys configured:\n",
    "\n",
    "1. **Gemini API Key**, `GOOGLE_API_KEY` variable: Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from `/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import env\n",
    "\n",
    "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Key Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Using Pretty Prints\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from utils import pretty_print\n",
    "\n",
    "nest_asyncio.apply()  # Allow nested async usage in notebooks\n",
    "\n",
    "pretty_print.wrapped(\"Using Pretty Prints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Required Files\n",
    "\n",
    "We need to download the configuration files and input data that Brown uses for article generation and editing.\n",
    "\n",
    "First, let's download the configs folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf configs\n",
    "!curl -L -o configs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/configs.zip\n",
    "!unzip configs.zip\n",
    "!rm -rf configs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the inputs folder containing profiles, examples, and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf inputs\n",
    "!curl -L -o inputs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/inputs.zip\n",
    "!unzip inputs.zip\n",
    "!rm -rf inputs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify what we downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aritcle_guideline.md   \u001b[1m\u001b[36minputs\u001b[m\u001b[m/                notebook_guideline.md\n",
      "\u001b[1m\u001b[36mconfigs\u001b[m\u001b[m/               notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Directory Constants\n",
    "\n",
    "Now let's define constants to reference these directories throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs directory exists: True\n",
      "Inputs directory exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIGS_DIR = Path(\"configs\")\n",
    "INPUTS_DIR = Path(\"inputs\")\n",
    "\n",
    "# Verify they exist\n",
    "print(f\"Configs directory exists: {CONFIGS_DIR.exists()}\")\n",
    "print(f\"Inputs directory exists: {INPUTS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples directory exists: True\n",
      "Examples directory exists: True\n",
      "Profiles directory exists: True\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_DIR = Path(\"inputs/tests/01_sample\")\n",
    "EXAMPLES_DIR = Path(\"inputs/examples/course_lessons\")\n",
    "PROFILES_DIR = Path(\"inputs/profiles\")\n",
    "\n",
    "print(f\"Samples directory exists: {SAMPLE_DIR.exists()}\")\n",
    "print(f\"Examples directory exists: {EXAMPLES_DIR.exists()}\")\n",
    "print(f\"Profiles directory exists: {PROFILES_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How the Writing Agent Works with Review-Edit Loop\n",
    "\n",
    "Before diving into the implementation, let's understand how the writing agent now incorporates the review-editing process through the evaluator-optimizer pattern.\n",
    "\n",
    "### The Extended Workflow\n",
    "\n",
    "In Lesson 22, we learned about the three-step workflow:\n",
    "\n",
    "1. **Load Context into Memory** - Gather guidelines, research, profiles, and examples\n",
    "2. **Generate Media Items** - Use the orchestrator-worker pattern to create diagrams\n",
    "3. **Write the Article** - Generate the first draft using the ArticleWriter\n",
    "\n",
    "Now we're adding a fourth and fifth step that loops multiple times:\n",
    "\n",
    "4. **Review the Article** (Evaluator) - Check the article against all profiles and guidelines\n",
    "5. **Edit the Article** (Optimizer) - Fix all identified issues based on the reviews\n",
    "\n",
    "This review-edit pattern continues for a configurable number of iterations, gradually improving the article quality.\n",
    "\n",
    "### The Evaluator-Optimizer Pattern Explained\n",
    "\n",
    "The evaluator-optimizer pattern is a fundamental AI workflow pattern that mirrors real-world quality assurance processes:\n",
    "\n",
    "- **Evaluator**: Analyzes output and identifies issues or areas for improvement\n",
    "- **Optimizer**: Takes the feedback and makes targeted improvements\n",
    "\n",
    "In our case:\n",
    "- **Article Reviewer Node** = Evaluator (checks if article follows all the standards)\n",
    "- **Article Writer Node** = Optimizer (edits the article based on reviews)\n",
    "\n",
    "This approach is extremely similar to how a real-world writing process works:\n",
    "\n",
    "1. The writer writes the article (initial draft)\n",
    "2. A reviewer provides feedback from outside eyes\n",
    "3. The same writer edits the article based on the provided feedback\n",
    "4. Repeat steps 2-3 until satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Visualization\n",
    "\n",
    "Let's visualize the complete workflow with the review-edit loop:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/images/l23_writing_workflow.png\" alt=\"Workflow\" height=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Review Entities: Modeling Feedback\n",
    "\n",
    "Now let's explore the new Pydantic entities we need for the review process. In Lesson 22, we already covered the core entities like `Article`, `ArticleGuideline`, and `ArticleProfiles`. Now we need entities to represent the reviewing logic.\n",
    "\n",
    "### Why Two Types of Reviews?\n",
    "\n",
    "We support two review modes:\n",
    "\n",
    "1. **Whole Article Reviews**: Review the entire article from top to bottom\n",
    "2. **Selected Text Reviews**: Review only a specific portion of the article\n",
    "\n",
    "Most of the time, only a section of the article needs editing, not the whole thing. This targeted approach saves time and reduces API costs by only reviewing what matters.\n",
    "\n",
    "### The Review Entities\n",
    "\n",
    "From `brown.entities.reviews`, we have these core entities:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Review Entity\n",
    "\n",
    "A `Review` represents a single piece of feedback about the article:\n",
    "\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from brown.entities.mixins import ContextMixin\n",
    "\n",
    "\n",
    "class Review(BaseModel, ContextMixin):\n",
    "    profile: str = Field(\n",
    "        description=\"The profile type listing the constraints based on which we will write the comment.\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        description=\"The location from within the article where the comment is made. For example, the title of a section.\"\n",
    "    )\n",
    "    comment: str = Field(\n",
    "        description=\"The comment made by the reviewer stating the issue relative to the profile.\"\n",
    "    )\n",
    "\n",
    "    def to_context(self) -> str:\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    <profile>{self.profile}</profile>\n",
    "    <location>{self.location}</location>\n",
    "    <comment>{self.comment}</comment>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Fields:**\n",
    "\n",
    "- **profile**: Which requirement was violated (e.g., \"tonality_profile\", \"article_guideline\", \"structured_profile\")\n",
    "- **location**: Where in the article the issue exists, usually the title of the article section (e.g., \"Introduction - Second paragraph\")\n",
    "- **comment**: Detailed explanation of what's wrong and why it deviates from the requirement\n",
    "\n",
    "**Example Review:**\n",
    "\n",
    "```python\n",
    "Review(\n",
    "    profile=\"tonality_profile\",\n",
    "    location=\"Introduction - First paragraph\",\n",
    "    comment=\"The tone is overly formal. The tonality profile specifies a conversational, friendly tone. The current opening reads like an academic paper rather than an engaging blog post.\"\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The ArticleReviews Entity\n",
    "\n",
    "`ArticleReviews` bundles multiple reviews for the whole article:\n",
    "\n",
    "\n",
    "```python\n",
    "class ArticleReviews(BaseModel, ContextMixin):\n",
    "    article: Article\n",
    "    reviews: list[Review]\n",
    "\n",
    "    def to_context(self, include_article: bool = False) -> str:\n",
    "        reviews_str = \"\\n\".join([review.to_context() for review in self.reviews])\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    {f\"<article>{self.article}</article>\" if include_article else \"\"}\n",
    "    <reviews>\n",
    "    {reviews_str}\n",
    "    </reviews>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Reviews(len_reviews={len(self.reviews)})\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The SelectedText Entity\n",
    "\n",
    "Before understanding `SelectedTextReviews`, we need to see the `SelectedText` entity from `brown.entities.articles` to understand how we will model the selected text relative to how we did for the whole article:\n",
    "\n",
    "\n",
    "```python\n",
    "class SelectedText(BaseModel, ContextMixin):\n",
    "    article: Article\n",
    "    content: str\n",
    "    first_line_number: int\n",
    "    last_line_number: int\n",
    "\n",
    "    def to_context(self) -> str:\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    <content>{self.content}</content>\n",
    "    <first_line_number>{self.first_line_number}</first_line_number>\n",
    "    <last_line_number>{self.last_line_number}</last_line_number>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Contains the full `article` for context\n",
    "- `content`: The specific text selection to review/edit\n",
    "- Line numbers help locate the selection within the full article\n",
    "- This enables targeted reviews of specific sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The SelectedTextReviews Entity\n",
    "\n",
    "`SelectedTextReviews` handles reviews for just a portion of the article:\n",
    "\n",
    "\n",
    "```python\n",
    "class SelectedTextReviews(BaseModel, ContextMixin):\n",
    "    article: Article\n",
    "    selected_text: SelectedText\n",
    "    reviews: list[Review]\n",
    "\n",
    "    def to_context(self, include_article: bool = False) -> str:\n",
    "        reviews_str = \"\\n\".join([review.to_context() for review in self.reviews])\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    {f\"<article>{self.article.to_context()}</article>\" if include_article else \"\"}\n",
    "    <selected_text>{self.selected_text.to_context()}</selected_text>\n",
    "    <reviews>\n",
    "    {reviews_str}\n",
    "    </reviews>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Use Case:**\n",
    "\n",
    "When a user identifies a specific problematic section, we can:\n",
    "1. Create a `SelectedText` entity pointing to that section\n",
    "2. Review only that selection (faster, cheaper)\n",
    "3. Edit only that selection\n",
    "4. Replace the selection in the full article\n",
    "\n",
    "This is particularly useful for human-in-the-loop workflows where humans can highlight specific sections for improvement. More on this in Lesson 24.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Relationships\n",
    "\n",
    "Let's visualize how these entities relate:\n",
    "\n",
    "```\n",
    "Article\n",
    "  â””â”€â”€ ArticleReviews\n",
    "       â””â”€â”€ reviews: list[Review]\n",
    "\n",
    "Article + SelectedText\n",
    "  â””â”€â”€ SelectedTextReviews  \n",
    "       â”œâ”€â”€ selected_text: SelectedText\n",
    "       â””â”€â”€ reviews: list[Review]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Article Reviewer Node: The Evaluator\n",
    "\n",
    "Now let's explore the `ArticleReviewer` node, which acts as the **evaluator** in our evaluator-optimizer pattern. This node analyzes articles against all requirements and generates detailed feedback.\n",
    "\n",
    "Remember that the core expectations are that the article follows the article guidelines and that all the writing profiles are respected.\n",
    "\n",
    "### Node Abstraction Recap\n",
    "\n",
    "First, a quick reminder that we leverage the same `Node` abstraction from Lesson 22 to implement all our nodes.\n",
    "\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "\n",
    "from brown.nodes.base import Node, Toolkit\n",
    "\n",
    "\n",
    "class Node(ABC):\n",
    "    def __init__(self, model: Runnable, toolkit: Toolkit) -> None:\n",
    "        self.toolkit = toolkit\n",
    "        self.model = self._extend_model(model)\n",
    "\n",
    "    def _extend_model(self, model: Runnable) -> Runnable:\n",
    "        # Can be overridden to bind tools, structured output, etc.\n",
    "        return model\n",
    "\n",
    "    @abstractmethod\n",
    "    async def ainvoke(self) -> Any:\n",
    "        pass\n",
    "```\n",
    "\n",
    "All workflow nodes inherit from this base class, providing a consistent interface throughout the system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArticleReviewer Class Structure\n",
    "\n",
    "Let's examine the `ArticleReviewer` class from `brown.nodes.article_reviewer`:\n",
    "\n",
    "**1. The Class and Initialization:**\n",
    "\n",
    "```python\n",
    "class ArticleReviewer(Node):\n",
    "    system_prompt_template = \"\"\"...\"\"\"  # We'll see this shortly\n",
    "    selected_text_system_prompt_template = \"\"\"...\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        to_review: Article | SelectedText,\n",
    "        article_guideline: ArticleGuideline,\n",
    "        model: Runnable,\n",
    "        article_profiles: ArticleProfiles,\n",
    "    ) -> None:\n",
    "        self.to_review = to_review\n",
    "        self.article_guideline = article_guideline\n",
    "        self.article_profiles = article_profiles\n",
    "\n",
    "        super().__init__(model, toolkit=Toolkit(tools=[]))\n",
    "```\n",
    "\n",
    "**Key Design Decisions:**\n",
    "\n",
    "- `to_review` can be either a full `Article` or just `SelectedText` (polymorphic design)\n",
    "- Takes all the requirements: guideline, profiles\n",
    "- No tools needed (empty toolkit), as reviewing is a pure generation task and no tools are required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Model Extension with Structured Output:**\n",
    "\n",
    "```python\n",
    "    def _extend_model(self, model: Runnable) -> Runnable:\n",
    "        model = cast(BaseChatModel, super()._extend_model(model))\n",
    "        model = model.with_structured_output(ReviewsOutput)\n",
    "        \n",
    "        return model\n",
    "```\n",
    "\n",
    "The reviewer uses structured output to ensure we get properly formatted reviews. First, we need an intermediate Pydantic model:\n",
    "\n",
    "```python\n",
    "class ReviewsOutput(BaseModel):\n",
    "    reviews: list[Review]\n",
    "```\n",
    "\n",
    "**Why an intermediate model?**\n",
    "\n",
    "The LLM outputs `ReviewsOutput`, but the node returns either `ArticleReviews` or `SelectedTextReviews` (which include the article/selected_text). This separation keeps the LLM output schema simple to avoid any potential LLM inference errors, while allowing richer node outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. The ainvoke Method:**\n",
    "\n",
    "```python\n",
    "    async def ainvoke(self) -> ArticleReviews | SelectedTextReviews:\n",
    "        # Build the main system prompt with all requirements\n",
    "        system_prompt = self.system_prompt_template.format(\n",
    "            human_feedback=self.human_feedback.to_context() if self.human_feedback else \"\",\n",
    "            article=self.article.to_context(),\n",
    "            article_guideline=self.article_guideline.to_context(),\n",
    "            character_profile=self.article_profiles.character.to_context(),\n",
    "            article_profile=self.article_profiles.article.to_context(),\n",
    "            structure_profile=self.article_profiles.structure.to_context(),\n",
    "            mechanics_profile=self.article_profiles.mechanics.to_context(),\n",
    "            terminology_profile=self.article_profiles.terminology.to_context(),\n",
    "            tonality_profile=self.article_profiles.tonality.to_context(),\n",
    "        )\n",
    "        \n",
    "        user_input_content = self.build_user_input_content(inputs=[system_prompt])\n",
    "        inputs = [{\"role\": \"user\", \"content\": user_input_content}]\n",
    "        \n",
    "        # If reviewing selected text, add additional instructions\n",
    "        if self.is_selected_text:\n",
    "            inputs.extend([\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": self.selected_text_system_prompt_template.format(\n",
    "                        selected_text=self.to_review.to_context()\n",
    "                    ),\n",
    "                }\n",
    "            ])\n",
    "        \n",
    "        # Generate reviews\n",
    "        reviews = await self.model.ainvoke(inputs)\n",
    "        if not isinstance(reviews, ReviewsOutput):\n",
    "            raise InvalidOutputTypeException(ReviewsOutput, type(reviews))\n",
    "        \n",
    "        # Return appropriate review type\n",
    "        if self.is_selected_text:\n",
    "            return SelectedTextReviews(\n",
    "                article=self.article,\n",
    "                selected_text=cast(SelectedText, self.to_review),\n",
    "                reviews=reviews.reviews,\n",
    "            )\n",
    "        else:\n",
    "            return ArticleReviews(\n",
    "                article=self.article,\n",
    "                reviews=reviews.reviews,\n",
    "            )\n",
    "```\n",
    "\n",
    "**Flow:**\n",
    "\n",
    "1. Format the system prompt with all requirements\n",
    "2. If reviewing selected text, add special instructions\n",
    "3. Generate structured reviews from the LLM\n",
    "4. Package the output entity into the appropriate review type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The System Prompt (Main Review Logic):**\n",
    "\n",
    "Here's the system prompt which is carefully designed to create thorough, actionable reviews based on the article guideline and writing profiles:\n",
    "\n",
    "```python\n",
    "class ArticleReviewer(Node):\n",
    "    system_prompt_template = \"\"\"\n",
    "You are Brown, an expert article writer, editor and reviewer specialized in reviewing technical, educative and informational articles.\n",
    "\n",
    "Your task is to review a given article against a set of expected requirements and provide detailed feedback \n",
    "about any deviations. You will act as a quality assurance reviewer, identifying specific issues and suggesting \n",
    "how the article fails to meet the expected requirements.\n",
    "\n",
    "These reviews will further be used to edit the article, ensuring it follows all the requirements.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "The requirements are a set of rules, guidelines or profiles that the article should follow. Here they are:\n",
    "\n",
    "- **article guideline:** the user intent describing how the article should look like. Specific to this particular article.\n",
    "- **article profile:** rules specific to writing articles. Generic for all articles.\n",
    "- **character profile:** the character you will impersonate while writing. Generic for all content.\n",
    "- **structure profile:** Structure rules guiding the final output format. Generic for all content.\n",
    "- **mechanics profile:** Mechanics rules guiding the writing process. Generic for all content.\n",
    "- **terminology profile:** Terminology rules guiding word choice and phrasing. Generic for all content.\n",
    "- **tonality profile:** Tonality rules guiding the writing style. Generic for all content.\n",
    "\n",
    "## Article to Review\n",
    "\n",
    "Here is the article that needs to be reviewed:\n",
    "\n",
    "{article}\n",
    "\n",
    "## Article Guideline\n",
    "\n",
    "The <article_guideline> represents the user intent, describing how the actual article should look like.\n",
    "\n",
    "The <article_guideline> will ALWAYS contain:\n",
    "- all the sections of the article expected to be written, in the correct order\n",
    "- a level of detail for each section, describing what each section should contain. Depending on how much detail you have in a\n",
    "particular section of the <article_guideline>, you will use more or less information from the <research> tags to write the section.\n",
    "\n",
    "The <article_guideline> can ALSO contain:\n",
    "- length constraints for each section, such as the number of characters, words or reading time. If present, you will respect them.\n",
    "- important (golden) references as URLs or titles present in the <research> tags. If present, always prioritize them over anything else \n",
    "from the <research>.\n",
    "- information about anchoring the article into a series such as a course or a book. Extremely important when the article is part of \n",
    "something bigger and we have to anchor the article into the learning journey of the reader. For example, when introducing concepts\n",
    "in previous articles that we don't want to reintroduce into the current one.\n",
    "- concrete information about writing the article. If present, you will ALWAYS priotize the instructions from the <article_guideline> \n",
    "over any other instructions.\n",
    "\n",
    "Here is the article guideline:\n",
    "{article_guideline}\n",
    "\n",
    "## Character Profile\n",
    "\n",
    "To make the writing more personable, we impersonated the following character profile when writing the article:\n",
    "{character_profile}\n",
    "\n",
    "## Terminology Profile\n",
    "\n",
    "Here is the terminology profile, describing how to choose the right words and phrases:\n",
    "to the target audience:\n",
    "{terminology_profile}\n",
    "\n",
    "## Tonality Profile\n",
    "\n",
    "Here is the tonality profile, describing the tone, voice and style of the writing:\n",
    "{tonality_profile}\n",
    "\n",
    "## Mechanics Profile\n",
    "\n",
    "Here is the mechanics profile, describing how the sentences and words should be written:\n",
    "{mechanics_profile}\n",
    "\n",
    "## Structure Profile\n",
    "\n",
    "Here is the structure profile, describing general rules on how to structure text, such as the sections, paragraphs, lists,\n",
    "code blocks, or media items:\n",
    "{structure_profile}\n",
    "\n",
    "## Article Profile\n",
    "\n",
    "Here is the article profile, describing particularities on how the end-to-end article should look like:\n",
    "{article_profile}\n",
    "\n",
    "## Reviewing Process\n",
    "\n",
    "You will review the article against all the requirements above, creating a one-to-many relationship between each requirement and the \n",
    "number of required reviews. In other words, for each requirement, you will create 0 to N reviews. If the article follows the \n",
    "requirement 100%, you will not create any reviews for it. If it doesn't follow the requirement, you will create as many reviews \n",
    "as required to ensure the article follows the requirement.\n",
    "\n",
    "Remember that these reviews will further be used to edit the article, ensuring it follows all the requirements. Thus, it's\n",
    "important to make a thorough review, covering all the requirements and not missing any detail.\n",
    "\n",
    "## Reviewing Rules\n",
    "\n",
    "- **The first most important rule:** The requirements can contain some special sections labeled as \"rules\" or \n",
    "\"correction rules\". You should look for <(.*)?rules(.*)?> XML tags like <correction_media_rules>, \n",
    "<abbreviations_or_acronyms_never_to_expand_rules>, <correction_reference_rules>. These are special highlights that \n",
    "should always be prioritized over other rules during the review process. They should be respected at all costs when \n",
    "writing the article. You will always prioritize these rules over other rules from the requirements making them your \n",
    "No.1 focus.\n",
    "- **The second most important rule:** The adherence to the <article_guideline>.\n",
    "- **The third most important rule:** The adherence to the <article_profile>.\n",
    "- **The fourth most important rule:** The adherence to the rest of the requirements.\n",
    "\n",
    "Other more generic rules:\n",
    "- Be thorough but fair - only flag genuine issues\n",
    "- Emphasize WHY something is wrong, not just WHAT is wrong\n",
    "- Focus on significant deviations, not minor nitpicks \n",
    "\n",
    "## Output Format\n",
    "\n",
    "For each issue you identify, create a review with:\n",
    "- **profile**: The requirement where the issue was found (e.g., \"human_feedback\", \"article_guideline\", \"character_profile\", \n",
    "\"article_profile\", \"structure_profile\", \"mechanics_profile\", \"terminology_profile\", \"tonality_profile\")\n",
    "- **location**: The section title where the issue was found and the paragraph number. For example, \"Introduction - First paragraph\" \n",
    "or \"Implementing GraphRAG - Third paragraph\"\n",
    "- **comment**: A detailed explanation of why it's wrong, what's wrong and how it deviates from the requirement.\n",
    "\n",
    "## Chain of Thoughts\n",
    "\n",
    "1. Read and analyze the article.\n",
    "2. Read and analyze the <human_feedback>.\n",
    "3. Read and analyze all the requirements considering the <human_feedback> as a guiding force.\n",
    "4. Carefully compare the article against the requirements as instructed by the rules above.\n",
    "5. For each requirement, create 0 to N reviews\n",
    "6. Return the reviews of the article.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Prompt Engineering Techniques:**\n",
    "\n",
    "1. **Clear Role**: Expert reviewer with specific expertise\n",
    "2. **Explicit Priority System**: Rules are ranked (special rules > guideline > article profile > other profiles)\n",
    "3. **Output**: Clear instructions on what we want the LLM to fill for each attribute\n",
    "5. **Chain of Thought**: Explicit reasoning steps that glue together all the other sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. The Selected Text System Prompt:**\n",
    "\n",
    "When reviewing only a selected portion, we append additional instructions:\n",
    "\n",
    "```python\n",
    "class ArticleReviewer(Node):\n",
    "    system_prompt_template = \"\"\"...\"\"\"\n",
    "    \n",
    "    selected_text_system_prompt_template = \"\"\"\n",
    "You already reviewed and edited the whole article. Now we want to further review only a specific portion\n",
    "of the article, which we label as the <selected_text>. Despite reviewing the selected text, instead of the\n",
    "article as a whole, you will follow the exact same instructions from above as if you were reviewing the article as a whole.\n",
    "\n",
    "## Selected Text to Review\n",
    "\n",
    "Here is the selected text that needs to be reviewed:\n",
    "\n",
    "{selected_text}\n",
    "\n",
    "As pointed out before, the selected text is part of the larger <article> that is already reviewed.\n",
    "You will use the full <article> as context and anchoring the reviewing process within the bigger picture.\n",
    "\n",
    "The <first_line_number> and <last_line_number> numbers from the <selected_text> indicate the first and \n",
    "last line/row numbers of the selected text from the <article>. Use them to locate the selected text within the <article>.\n",
    "\n",
    "## Chain of Thoughts\n",
    "\n",
    "Here is the new chain of thoughts logic you will follow when reviewing the selected text. You can ignore the\n",
    "previous chain of thoughts:\n",
    "\n",
    "1. Read and analyze the article.\n",
    "2. Locate the <selected_text> within the <article> based on the <first_line_number> and <last_line_number>.\n",
    "3. Read and analyze the <human_feedback>.\n",
    "4. Read and analyze all the requirements considering the <human_feedback> as a guiding force.\n",
    "5. Carefully compare the selected text against the requirements as instructed by the rules above.\n",
    "6. For each requirement, create 0 to N reviews\n",
    "7. Return the reviews of the selected text.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "This allows focused reviews on specific sections while maintaining context of the full article. As this system prompt is passed together with the `system_prompt_template` system prompt it has to act only as an extension on explaining what to do with a selected text.\n",
    "\n",
    "The special trick here is that it adds a new `Chain of Thoughts` section that overrides the one from the original system prompts adding specialized instructions on how to reason across the new task, while still having all the context from both system prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Reviewing a Whole Article\n",
    "\n",
    "Now let's see the `ArticleReviewer` in action by reviewing a sample article.\n",
    "\n",
    "First load the sample article guideline and the standard profiles:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 20:24:02.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading environment file from `.env`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------- Sample article guideline -------------------------------------\u001b[0m\n",
      "  ## Outline\n",
      "\n",
      "1. Introduction: The Critical Decision Every AI Engineer Faces\n",
      "2. Understanding the Spectrum: From Workflows to Agents\n",
      "3. Choosing Your Path\n",
      "4. Exploring Common Patterns\n",
      "5. Zooming In on Our Favorite Examples\n",
      "6. The Challenges of Every AI Engineer\n",
      "\n",
      "## Section 1 - Introduction: The Critical Decision Every AI Engineer Faces\n",
      "\n",
      "- **The Problem:** When building AI applications, engineers face a critical architectural decision early in their development process. Should they create a predictable, step-by-step workflow where they control every action, or should they build an autonomous agent that can think and decide for itself? This is one of the key decisions that will impact everything from the product such as development time and costs to reliability and user experience.\n",
      "- **Why This Decision Matters:** Choose the wrong approach and you might end up with:\n",
      "  - An overly rigid system that breaks when users deviate from expected patterns or developers try to add new features\n",
      "  - An\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.loaders import MarkdownArticleGuidelineLoader, MarkdownArticleLoader, MarkdownArticleProfilesLoader\n",
    "from brown.models import SupportedModels, get_model\n",
    "from brown.nodes import ArticleReviewer\n",
    "from utils import pretty_print\n",
    "\n",
    "# Load the article guideline\n",
    "guideline_loader = MarkdownArticleGuidelineLoader(uri=Path(\"article_guideline.md\"))\n",
    "article_guideline = guideline_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load the article profiles\n",
    "profiles_input = {\n",
    "    \"article\": PROFILES_DIR / \"article_profile.md\",\n",
    "    \"character\": PROFILES_DIR / \"character_profiles\" / \"paul_iusztin.md\",\n",
    "    \"mechanics\": PROFILES_DIR / \"mechanics_profile.md\",\n",
    "    \"structure\": PROFILES_DIR / \"structure_profile.md\",\n",
    "    \"terminology\": PROFILES_DIR / \"terminology_profile.md\",\n",
    "    \"tonality\": PROFILES_DIR / \"tonality_profile.md\",\n",
    "}\n",
    "profiles_loader = MarkdownArticleProfilesLoader(uri=profiles_input)\n",
    "article_profiles = profiles_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "pretty_print.wrapped(article_guideline.content[:1000], title=\"Sample article guideline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sample article to review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------- Sample article to review -------------------------------------\u001b[0m\n",
      "  # AI Agents vs. LLM Workflows: The Critical Decision Every AI Engineer Faces\n",
      "### A pragmatic guide to choosing the right architecture for your AI application.\n",
      "\n",
      "When building AI applications, engineers face a critical architectural decision early in their development process. Should you create a predictable, step-by-step workflow where you control every action, or should you build an autonomous agent that can think and decide for itself? This is one of the key decisions that will impact everything from development time and costs to reliability and user experience.\n",
      "\n",
      "Choose the wrong approach, and you might end up with an overly rigid system that breaks when users deviate from expected patterns. Or you could build an unpredictable agent that works brilliantly 80% of the time but fails catastrophically when it matters most. Either path can lead to months of wasted development time, frustrated users, and executives questioning the skyrocketing operational costs.\n",
      "\n",
      "In the real world of 2024 and 2025, billion-dollar AI startups succeed or fail based primarily on this architectural decision. The successful companies, teams, and AI engineers know when to use workflows versus agents and, more importantly, how to combine both approaches effectively.\n",
      "\n",
      "This lesson will provide a framework to help you make this critical decision with confidence. We will systematically explore the spectrum from rigid workflows to autonomous agents, helping you understand the trade-offs. By the end, you will \n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "article_loader = MarkdownArticleLoader(uri=Path(\"article.md\"))\n",
    "article = article_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "pretty_print.wrapped(article.content[:1500], title=\"Sample article to review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the article reviewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing article...\n",
      "\u001b[93m----------------------------------------- Article reviews -----------------------------------------\u001b[0m\n",
      "  Generated 87 reviews:\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 1 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction - First paragraph\",\n",
      "  \"Comment\": \"The introduction does not fully align with the 'The Problem' detail from the article guideline. It should emphasize the architectural decision as the core problem, not just 'one of the key decisions'....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 2 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction - Second paragraph\",\n",
      "  \"Comment\": \"The section 'Why This Decision Matters' from the article guideline specifies concrete negative outcomes: 'An overly rigid system that breaks when users deviate from expected patterns or developers try...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 3 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction - Third paragraph\",\n",
      "  \"Comment\": \"The article guideline requests a 'quick reference to the real-world where in 2024-2025 billion-dollar AI startups succeed or fail based primarily on this architectural decision'. The article includes ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 4 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction - Fourth paragraph\",\n",
      "  \"Comment\": \"The article guideline states, 'Quick walkthrough of what we'll learn by the end of this lesson: Take the core ideas of what we'll learn in the lesson from the `What We Are Planning to Share` subsectio...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 5 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction - Full Section\",\n",
      "  \"Comment\": \"The 'Introduction' section exceeds the specified length of 300 words. It currently has approximately 150 words more than allowed.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 6 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Fifth paragraph\",\n",
      "  \"Comment\": \"The article states, 'We will explore advanced workflow patterns like chaining, routing, and the orchestrator-worker model in future lessons, as well as the core components of agents like tools, memory...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 7 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Full Section\",\n",
      "  \"Comment\": \"The section 'Understanding the Spectrum: From Workflows to Agents' exceeds the specified length of 400 words. It currently has approximately 60 words more than allowed.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 8 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline provides a detailed list of examples for 'When to use LLM workflows', including 'Pipelines for data extraction and transformation from sources such as the web, messaging tools li...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 9 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Second paragraph\",\n",
      "  \"Comment\": \"The 'Strengths' for LLM workflows, as per the guideline, specifically mention 'potentially lower operational costs as we can leverage simpler and smaller models specialized in given sub-tasks' and 'Ul...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 10 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline details 'Weaknesses' for LLM workflows, stating 'Potentially more development time required as each step is manually engineered. The user experience is rigid as it cannot handle ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 11 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline specifies that workflows are 'Usually preferred in enterprises or regulated fiels as they require predictable programs that work all the time. For example, in finance, when a fin...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 12 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Third paragraph\",\n",
      "  \"Comment\": \"The guideline for 'When to use AI agents' includes specific points for 'Weaknesses' like 'AI agents usually require more LLM calls to understand the user intent and take various actions, which can res...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 13 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Third paragraph\",\n",
      "  \"Comment\": \"The article guideline includes a specific 'Funny story on the current issues with agents: People had their code deleted by Replit Agent or Claude Code and making jokes about it as 'Anyway I wanted to ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 14 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Fourth paragraph\",\n",
      "  \"Comment\": \"The guideline specifies, 'Generate a mermaid to illustrate the AI generation and human verification loop.' The article includes the diagram, but the caption format does not include an explicit citatio...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 15 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Full Section\",\n",
      "  \"Comment\": \"The section 'Choosing Your Path' exceeds the specified length of 500 words. It currently has approximately 200 words more than allowed.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 16 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - First paragraph\",\n",
      "  \"Comment\": \"The article guideline states, 'Explain them as if this is the first time the reader hears about them.' The article's introduction to this section is 'To build an intuition for AI engineering, let's lo...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 17 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflow Patterns - First paragraph\",\n",
      "  \"Comment\": \"The article guideline for 'Chaining and routing' specifies to 'automate together multiple LLM calls. As a first automation step, it helps gluing together multiple LLM calls and deciding between multip...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 18 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - First paragraph\",\n",
      "  \"Comment\": \"The article guideline explicitly states, 'Explain at a high-level that the pattern is used to automatically decide what action to take, interpret the output of the action, and repeat until the given t...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 19 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - Fifth paragraph\",\n",
      "  \"Comment\": \"The guideline states, 'Make a reference that this is how the ReAct pattern works, which we will explain in a lot of detail in Lessons 7 and 8. Highlight that almost all modern agents from the industry...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 20 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - Full Section\",\n",
      "  \"Comment\": \"The section 'Exploring Common Patterns' exceeds the specified length of 550 words. It currently has approximately 100 words more than allowed.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 21 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - First paragraph\",\n",
      "  \"Comment\": \"The article guideline requires, 'Explain everything as if speaking to a 7-year-old.' While the article attempts to keep it high-level, the language still uses terms like 'architectural decision,' 'mul...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 22 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Document Summarization in Google Workspace (Workflow) - Problem subsection\",\n",
      "  \"Comment\": \"The problem description for 'Document summarization and analysis workflow by Gemini in Google Workspace' from the article guideline specifies, 'When working in teams and looking for the right document...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 23 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - Problem subsection\",\n",
      "  \"Comment\": \"The article guideline's problem description for 'Gemini CLI coding assistant' includes 'When working on new code bases, understanding it is a slow process. When working with a new programming language...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 24 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline states, 'This is how Gemini CLI works based on our latest research from August 2025. Also, specify that `gemini-cli` is open-sourced on GitHub. Thus, on this particular example, ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 25 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - Use cases subsection\",\n",
      "  \"Comment\": \"The article guideline provides a detailed list of 'Use cases' for the Gemini CLI coding assistant, including 'Writing code from scratch, without requiring any coding experience (known as vibe coding)'...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 26 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - Problem subsection\",\n",
      "  \"Comment\": \"The article guideline requests parallels like 'tools as actions' and 'context as state or working memory' for making examples intuitive. The article uses 'working memory' and 'tools' but does not expl...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 27 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - Tool Execution subsection\",\n",
      "  \"Comment\": \"The guideline for 'Tool Execution' states 'The selected actions, known as tools, are executed. The tools can be things such as file operations to read the current state of the code, web requests to do...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 28 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - More tool examples subsection\",\n",
      "  \"Comment\": \"The guideline provides a detailed list of 'More tool examples' like 'grep functions to read specific functions or classes from the codebase', 'listing the directory structure of the codebase or module...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 29 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Problem subsection\",\n",
      "  \"Comment\": \"The problem description for 'Perplexity deep research' from the guideline includes 'Most of the time we don't know where to start. What is the right blog, paper, YouTube video or course to start readi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 30 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline states, 'This is how Perplexity Deep Research agent works based on our latest research from August 2025. Also, specify that the solution is closed-source. Thus, everything that w...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 31 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Research Planning & Decomposition subsection\",\n",
      "  \"Comment\": \"The guideline for 'Research Planning & Decomposition' states, 'Highlight how the orchestrator leverages the orchestrator-worker pattern to deploy multiple research agents with different sub-questions....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 32 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Parallel Information Gathering subsection\",\n",
      "  \"Comment\": \"The guideline for 'Parallel Information Gathering' states, 'As the research agents are isolated between each other, the input tokens are smaller, helping the LLM to stay focused.' This crucial detail ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 33 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Analysis & Synthesis subsection\",\n",
      "  \"Comment\": \"The guideline for 'Analysis & Synthesis' states, 'each agent validates and scores each source using strategies such as domain credibility or relevance scoring relative to the query. Then, each source ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 34 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Iterative Refinement & Gap Analysis subsection\",\n",
      "  \"Comment\": \"The guideline for 'Iterative Refinement & Gap Analysis' states, 'to avoid infinite loops, a max number of steps is reached.' The article mentions 'until the research is complete or a step limit is rea...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 35 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Sixth paragraph\",\n",
      "  \"Comment\": \"The guideline for the concluding paragraph of this example states, 'Highlight how the deep research agent operates as a hybrid between workflows and agents combining structured planning with dynamic a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 36 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Full Section\",\n",
      "  \"Comment\": \"The section 'Zooming In on Our Favorite Examples' exceeds the specified length of 900 words. It currently has approximately 150 words more than allowed.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 37 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The article guideline for 'The Reality of AI Engineering' in the conclusion states 'whether working at a startup or a Fortune 500 company faces these same fundamental challenges whenever it has to des...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 38 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline specifies additional details for 'Context Limits': 'Ensuring consistent output quality across different agent specializations presents a continuous challenge.' This detail is mis...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 39 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline specifies additional details for 'Data Integration': 'Building pipelines to pull information from Slack, web APIs, SQL databases, and data lakes while ensuring only high-quality ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 40 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\",\n",
      "  \"Comment\": \"The article guideline states, 'To transition from this lesson to the next, specify what we will learn in future lessons. First mention what we will learn in next lesson, which is Lesson 3. Next levera...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 41 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Full Section\",\n",
      "  \"Comment\": \"The section 'Conclusion: The Challenges of Every AI Engineer' exceeds the specified length of 350 words. It currently has approximately 60 words more than allowed.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 42 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Full Article - Overall Structure\",\n",
      "  \"Comment\": \"The article titles and section titles are formatted with H2 headers (`##`). The article guideline specifies that the 'Introduction, conclusion and section titles use H2 headers, marked as `##`', and '...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 43 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Full Article - General Article Structure\",\n",
      "  \"Comment\": \"The 'Subtitle' has an explicit instruction 'Do not capitalize the subtitle'. The current subtitle 'A pragmatic guide to choosing the right architecture for your AI application.' has a capitalized 'A' ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 44 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Introduction - First paragraph\",\n",
      "  \"Comment\": \"The article profile states, 'The introduction is a short summary of the article, quickly presenting the `why` (problem), `what` (solution), and captivating the reader to continue reading.' While it to...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 45 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Introduction - Fourth paragraph\",\n",
      "  \"Comment\": \"The article profile states, 'Wrap-up the introduction with a clear highlight of what will be covered within the article with a concise, itemized overview.' The current concluding sentence of the intro...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 46 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Introduction - First paragraph\",\n",
      "  \"Comment\": \"The article starts with 'When building AI applications, engineers face a critical architectural decision early in their development process. Should you create a predictable, step-by-step workflow wher...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 47 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Full Article - Section Transitions\",\n",
      "  \"Comment\": \"The transitions between sections, while present, often lack the explicit 'why' and 'what' on why the new section is needed, as emphasized in the `transition_rules`. For example, the transition from 'U...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 48 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"character_profile\",\n",
      "  \"Location\": \"Introduction - Second paragraph\",\n",
      "  \"Comment\": \"The 'Vibe' from the `character_profile` includes 'zero hype', 'straight-to-the-point content'. The sentence 'Either path can lead to months of wasted development time, frustrated users, and executives...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 49 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"character_profile\",\n",
      "  \"Location\": \"Introduction - Fourth paragraph\",\n",
      "  \"Comment\": \"The 'Vibe' from the `character_profile` includes 'zero hype', 'straight-to-the-point content'. The sentence 'By the end, you will have the knowledge to architect AI systems that are not only powerful ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 50 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"character_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The 'Vibe' from the `character_profile` includes 'zero hype', 'straight-to-the-point content'. The phrase 'fails spectacularly' in the first paragraph of the conclusion is overly dramatic and deviates...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 51 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"character_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Third paragraph\",\n",
      "  \"Comment\": \"The 'Vibe' from the `character_profile` includes 'zero hype', 'straight-to-the-point content'. The sentence 'The good news is that these challenges are solvable' uses 'good news', which can be perceiv...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 52 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"character_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\",\n",
      "  \"Comment\": \"The 'Vibe' from the `character_profile` includes 'zero hype', 'straight-to-the-point content'. The phrase 'messy, unpredictable real world' in the final paragraph of the conclusion is slightly dramati...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 53 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Introduction - First paragraph\",\n",
      "  \"Comment\": \"The paragraph 'When building AI applications, engineers face a critical architectural decision early in their development process. Should you create a predictable, step-by-step workflow where you cont...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 54 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Introduction - Second paragraph\",\n",
      "  \"Comment\": \"The paragraph 'Choose the wrong approach, and you might end up with an overly rigid system that breaks when users deviate from expected patterns. Or you could build an unpredictable agent that works b...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 55 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Introduction - Third paragraph\",\n",
      "  \"Comment\": \"The paragraph 'In the real world of 2024 and 2025, billion-dollar AI startups succeed or fail based primarily on this architectural decision. The successful companies, teams, and AI engineers know whe...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 56 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Second paragraph\",\n",
      "  \"Comment\": \"The paragraph defining LLM workflows has 58 words, which is acceptable by itself, but the definition is very dense. It includes 'A sequence of tasks that involves LLM calls or other operations, such a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 57 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Fourth paragraph\",\n",
      "  \"Comment\": \"The paragraph defining AI agents has 82 words, exceeding the maximum paragraph length of 80 words as per the `paragraph_rules`.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 58 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Fifth paragraph\",\n",
      "  \"Comment\": \"The paragraph 'Both workflows and agents require an orchestration layer, but its role differs significantly. In a workflow, the orchestrator executes a predefined plan, like a conductor following a mu...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 59 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Second paragraph\",\n",
      "  \"Comment\": \"The paragraph describing workflow strengths and weaknesses has 121 words, significantly exceeding the maximum paragraph length of 80 words as per the `paragraph_rules`. It also contains multiple ideas...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 60 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Third paragraph\",\n",
      "  \"Comment\": \"The paragraph describing agent strengths and weaknesses has 130 words, significantly exceeding the maximum paragraph length of 80 words as per the `paragraph_rules`. It also contains multiple ideas (s...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 61 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Fourth paragraph\",\n",
      "  \"Comment\": \"The paragraph describing hybrid approaches and the 'autonomy slider' has 98 words, exceeding the maximum paragraph length of 80 words as per the `paragraph_rules`. It also introduces Andrej Karpathy a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 62 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflow Patterns - First paragraph\",\n",
      "  \"Comment\": \"The paragraph defining 'Chaining and Routing' has 60 words. While not exceeding the 80-word limit, it's quite dense with multiple concepts: fundamental pattern, output of one LLM to input of next, rou...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 63 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflow Patterns - Third paragraph\",\n",
      "  \"Comment\": \"The paragraph defining 'Evaluator-Optimizer Loop' has 94 words, exceeding the maximum paragraph length of 80 words as per the `paragraph_rules`. It also contains multiple ideas (LLM generates, LLM rev...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 64 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - First paragraph\",\n",
      "  \"Comment\": \"The paragraph introducing ReAct has 45 words. While short, it is dense. It states 'Nearly all modern agents use a pattern called ReAct, which stands for Reason and Act. This framework enables an agent...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 65 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - Fifth paragraph\",\n",
      "  \"Comment\": \"The paragraph 'We will dive deep into the ReAct pattern in future lessons, but for now, understanding these basic components is enough to build a solid foundation.' has 31 words, which is within the s...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 66 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Document Summarization in Google Workspace (Workflow) - Problem subsection\",\n",
      "  \"Comment\": \"The paragraph 'The Problem: Finding the right information in a shared drive can be a time-consuming process, especially when documents are long and numerous. A quick, embedded summary can guide your s...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 67 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Document Summarization in Google Workspace (Workflow) - Second paragraph\",\n",
      "  \"Comment\": \"The paragraph 'This is a perfect use case for a pure, multi-step workflow. The process is linear and predictable, involving a chain of LLM calls.' has 27 words. While within the limit, it introduces t...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 68 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant (Agent) - Problem subsection\",\n",
      "  \"Comment\": \"The paragraph 'The Problem: Writing code is a slow process that often involves reading dense documentation or sifting through outdated blog posts. A coding assistant can dramatically speed up developm...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 69 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity's Deep Research (Hybrid System) - Problem subsection\",\n",
      "  \"Comment\": \"The paragraph 'The Problem: Researching a new topic can be daunting. It is hard to know where to start, which sources are reliable, and how to synthesize information from dozens of articles or papers....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 70 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The paragraph 'Now that you understand the spectrum from LLM workflows to AI agents, it is important to recognize that every AI engineer faces these same fundamental challenges when designing a new ap...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 71 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Second paragraph\",\n",
      "  \"Comment\": \"The paragraph listing daily challenges has 154 words, significantly exceeding the maximum paragraph length of 80 words as per the `paragraph_rules`. It also lists multiple distinct challenges (Reliabi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 72 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\",\n",
      "  \"Comment\": \"The paragraph 'Your path forward as an AI engineer is about mastering these realities. By the end of this course, you will have the knowledge to architect AI systems that are not only powerful but als...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 73 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Introduction - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'Before we can choose between workflows and agents, we need a clear understanding of what they are.' uses 'we' to refer to the writer and 'we' to refer to the reader. The `point_of_view` ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 74 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'Before we can choose between workflows and agents, we need a clear understanding of what they are.' uses 'we' for both the author and the reader, which violates the `point_of_view` rule ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 75 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Full Article - References section\",\n",
      "  \"Comment\": \"The article uses citations with identifiers like [[1]], [[2]], [[3]] directly followed by a URL in the text, e.g., `[[1]](https://www.youtube.com/watch?v=y5mdI_aBC4Y)`. The `citation_guideline_technic...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 76 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Full Article - References section\",\n",
      "  \"Comment\": \"The reference section is missing the 'Author Name. (Publish Date). Full Title. Source.' format from the `references_rules`. For example, for '1. Karpathy, A. (2024, May 24). Software in the Era of AI....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 77 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'This lesson will provide a framework to help you make this critical decision with confidence.' contains 'critical decision with confidence', which is listed in the `AI Slop Banned Expres...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 78 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'You can think of an agent as a skilled human expert tackling an unfamiliar problem, adapting their approach with each new piece of information.' contains 'tackling an unfamiliar problem'...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 79 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'Most real-world systems blend elements of both. Think of it as an 'autonomy slider' where you decide how much control to give the LLM versus the user.' uses the phrasing 'Think of it as....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 80 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Conclusion of section\",\n",
      "  \"Comment\": \"The phrase 'The ultimate goal is to accelerate the loop between AI generation and human verification' and 'This is often achieved through a well-designed architecture that combines the reliability of ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 81 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'This architectural choice is one of the core decisions that determine whether your AI application succeeds in production or fails spectacularly.' contains the phrase 'fails spectacularly...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 82 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'Your path forward as an AI engineer is about mastering these realities.' contains 'Your path forward as an AI engineer is about mastering these realities.', which is listed in the `AI Sl...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 83 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'By the end of this course, you will have the knowledge to architect AI systems that are not only powerful but also robust, efficient, and safe.' contains 'robust, efficient, and safe', w...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 84 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"tonality_profile\",\n",
      "  \"Location\": \"Introduction - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'By the end, you will have the knowledge to architect AI systems that are not only powerful but also robust, efficient, and safe.' uses language that is slightly overconfident, which is a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 85 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"tonality_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The phrase 'fails spectacularly' in the first paragraph of the conclusion is an example of over-dramatic language. The `tonality_profile` prefers a 'realistic, pragmatic and resilient' tone about nega...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 86 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"tonality_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Third paragraph\",\n",
      "  \"Comment\": \"The phrase 'The good news is that these challenges are solvable.' uses a very positive and almost marketing-like framing ('good news'). While a positive tone is desired, the `tonality_profile` emphasi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 87 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"tonality_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'Your path forward as an AI engineer is about mastering these realities. By the end of this course, you will have the knowledge to architect AI systems that are not only powerful but also...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create and run the reviewer\n",
    "model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "reviewer = ArticleReviewer(\n",
    "    to_review=article,\n",
    "    article_guideline=article_guideline,\n",
    "    article_profiles=article_profiles,\n",
    "    model=model,\n",
    "    human_feedback=None,  # No human feedback for this example\n",
    ")\n",
    "\n",
    "print(\"Reviewing article...\")\n",
    "article_reviews = await reviewer.ainvoke()\n",
    "\n",
    "pretty_print.wrapped(f\"Generated {len(article_reviews.reviews)} reviews:\", title=\"Article reviews\")\n",
    "for i, review in enumerate(article_reviews.reviews, 1):\n",
    "    review_dict = {\n",
    "        \"Profile\": review.profile,\n",
    "        \"Location\": review.location,\n",
    "        \"Comment\": review.comment[:200] + \"...\" if len(review.comment) > 200 else review.comment,\n",
    "    }\n",
    "    pretty_print.wrapped(review_dict, title=f\"Review {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Reviewing Selected Text\n",
    "\n",
    "Now let's review only a specific section of the article:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------- Selected text to review -------------------------------------\u001b[0m\n",
      "  Selected text: 2577 characters\n",
      "Lines: 11-44\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------- Selected text context (first 1500 characters) --------------------------\u001b[0m\n",
      "  \n",
      "<selected_text>\n",
      "    \n",
      "    <content>## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "Before we can choose between workflows and agents, we need a clear understanding of what they are. Rather than focusing on the technical specifics, let's look at their core properties and how they function in practice.\n",
      "\n",
      "An LLM workflow is a sequence of tasks that involves LLM calls or other operations, such as reading from a database or writing to a file system. It is largely predefined and orchestrated by developer-written code. The steps are defined in advance, resulting in deterministic or rule-based paths with predictable execution and explicit control flow. Think of it like a factory assembly line, where each station performs a specific, repeatable task in a set order.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Input\"] --> B[\"tool_calling_llm\"]\n",
      "    B --> C[\"Tools\"]\n",
      "    C --> D[\"End\"]\n",
      "```\n",
      "Image 1: A simple LLM workflow illustrating a sequence of predefined tasks, where an input leads to a tool-calling LLM, which interacts with tools before the workflow ends.\n",
      "\n",
      "On the other end of the spectrum, we have AI agents. These are systems where an LLM plays a central role in dynamically deciding the sequence of steps, reasoning, and actions to achieve a goal. The steps are not defined in advance but are planned based on the task and the current state of the environment. This makes them adaptive and capable of handling novelty. You can think of an agent as a skilled human expert tackling an unfamiliar probl\n",
      "...\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.entities.articles import SelectedText\n",
    "\n",
    "# Let's extract a specific section to review\n",
    "article_lines = article.content.split(\"\\n\")\n",
    "first_line_number = 11\n",
    "last_line_number = 44\n",
    "selected_content = \"\\n\".join(article_lines[first_line_number:last_line_number])\n",
    "\n",
    "selected_text = SelectedText(\n",
    "    article=article,\n",
    "    content=selected_content,\n",
    "    first_line_number=first_line_number,\n",
    "    last_line_number=last_line_number,\n",
    ")\n",
    "\n",
    "text = [\n",
    "    f\"Selected text: {len(selected_content)} characters\",\n",
    "    f\"Lines: {selected_text.first_line_number}-{selected_text.last_line_number}\",\n",
    "]\n",
    "pretty_print.wrapped(\"\\n\".join(text), title=\"Selected text to review\")\n",
    "pretty_print.wrapped(f\"{selected_text.to_context()[:1500]}\\n...\", title=\"Selected text context (first 1500 characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's review the selected text (note how we used the same `ArticleReviewer` class for both inputs containing the business logic in a single place):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing selected text...\n",
      "\u001b[93m-------------------------------------- Selected text reviews --------------------------------------\u001b[0m\n",
      "  Generated 3 reviews for selected text:\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 1 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'Before we can choose between workflows and agents, we need a clear understanding of what they are.' uses 'we' to refer to the student, which is incorrect. The point of view rule states t...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 2 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Section level\",\n",
      "  \"Comment\": \"The section 'Understanding the Spectrum: From Workflows to Agents' has a word count of 267 words. The article guideline specifies a length constraint of 400 words for this section, indicating it is si...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 3 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Fourth paragraph\",\n",
      "  \"Comment\": \"The analogy 'You can think of an agent as a skilled human expert tackling an unfamiliar problem, adapting their approach with each new piece of information.' starts with 'You can think of...'. The ter...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "reviewer = ArticleReviewer(\n",
    "    to_review=selected_text,  # Now passing SelectedText instead of Article\n",
    "    article_guideline=article_guideline,\n",
    "    article_profiles=article_profiles,\n",
    "    model=model,\n",
    "    human_feedback=None,\n",
    ")\n",
    "\n",
    "print(\"Reviewing selected text...\")\n",
    "selected_text_reviews = await reviewer.ainvoke()\n",
    "\n",
    "pretty_print.wrapped(\n",
    "    f\"Generated {len(selected_text_reviews.reviews)} reviews for selected text:\", title=\"Selected text reviews\"\n",
    ")\n",
    "for i, review in enumerate(selected_text_reviews.reviews, 1):\n",
    "    review_dict = {\n",
    "        \"Profile\": review.profile,\n",
    "        \"Location\": review.location,\n",
    "        \"Comment\": review.comment[:200] + \"...\" if len(review.comment) > 200 else review.comment,\n",
    "    }\n",
    "    pretty_print.wrapped(review_dict, title=f\"Review {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hooking Reviews to the Article Writer\n",
    "\n",
    "Now let's see how the `ArticleWriter` node handles reviews to act as the **optimizer** in our evaluator-optimizer pattern.\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "To keep the \"writing\" logic contained and avoid duplicated code, the `ArticleWriter` serves dual purposes:\n",
    "\n",
    "1. **Writer**: Generates the initial article draft\n",
    "2. **Editor**: Edits the article based on reviews\n",
    "\n",
    "This mirrors real-world writing processes where the original author both writes and edits their own work based on feedback. It keeps all writing knowledge in one place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes to ArticleWriter __init__\n",
    "\n",
    "The `ArticleWriter` now accepts an optional `reviews` parameter:\n",
    "\n",
    "\n",
    "```python\n",
    "class ArticleWriter(Node):\n",
    "    def __init__(\n",
    "        self,\n",
    "        article_guideline: ArticleGuideline,\n",
    "        research: Research,\n",
    "        article_profiles: ArticleProfiles,\n",
    "        media_items: MediaItems,\n",
    "        article_examples: ArticleExamples,\n",
    "        model: Runnable,\n",
    "        reviews: ArticleReviews | SelectedTextReviews | None = None,  # NEW!\n",
    "    ) -> None:\n",
    "        super().__init__(model, toolkit=Toolkit(tools=[]))\n",
    "        \n",
    "        self.article_guideline = article_guideline\n",
    "        self.research = research\n",
    "        self.article_profiles = article_profiles\n",
    "        self.media_items = media_items\n",
    "        self.article_examples = article_examples\n",
    "        self.reviews = reviews  # Store reviews for editing mode\n",
    "```\n",
    "\n",
    "**Key Insight:**\n",
    "\n",
    "When `reviews=None`, the writer generates a new article from scratch. When reviews are provided, it edits the existing article based on the feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes to the ainvoke Method\n",
    "\n",
    "The `ainvoke` method now handles both writing and editing:\n",
    "```python\n",
    "async def ainvoke(self) -> Article | SelectedText:\n",
    "    # Step 1: Build the main system prompt (same as before)\n",
    "    system_prompt = self.system_prompt_template.format(\n",
    "        article_guideline=self.article_guideline.to_context(),\n",
    "        research=self.research.to_context(),\n",
    "        # ... all other context ...\n",
    "    )\n",
    "    \n",
    "    user_input_content = self.build_user_input_content(\n",
    "        inputs=[system_prompt], \n",
    "        image_urls=self.research.image_urls\n",
    "    )\n",
    "    inputs = [{\"role\": \"user\", \"content\": user_input_content}]\n",
    "    \n",
    "    # Step 2: If reviews exist, add them to the conversation\n",
    "    if self.reviews:\n",
    "        # First, provide the previously written article as the assistant's response.\n",
    "        # This is important because the editing will be done relative to the article.\n",
    "        # Thus, we have to anchor the reviews on the evaluated article.\n",
    "        inputs.extend([\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": self.reviews.article.to_context(),\n",
    "            },\n",
    "        ])\n",
    "        \n",
    "        # Then, provide the reviews as user feedback, along with a new system prompt that\n",
    "        # instructs the agent on how to edit the article. In this way, we can \"hijack\"\n",
    "        # the original system template to edit the article instead of writing it from scratch.\n",
    "        if isinstance(self.reviews, ArticleReviews):\n",
    "            reviews_prompt = self.article_reviews_prompt_template.format(\n",
    "                reviews=self.reviews.to_context(include_article=False),\n",
    "            )\n",
    "        elif isinstance(self.reviews, SelectedTextReviews):\n",
    "            reviews_prompt = self.selected_text_reviews_prompt_template.format(\n",
    "                selected_text=self.reviews.selected_text.to_context(),\n",
    "                reviews=self.reviews.to_context(include_article=False),\n",
    "            )\n",
    "        \n",
    "        inputs.extend([{\"role\": \"user\", \"content\": reviews_prompt}])\n",
    "    \n",
    "    # Step 3: Generate/edit the article\n",
    "    written_output = await self.model.ainvoke(inputs)\n",
    "    written_output = cast(str, written_output.text)\n",
    "    \n",
    "    # Step 4: Return appropriate type\n",
    "    if isinstance(self.reviews, SelectedTextReviews):\n",
    "        return SelectedText(\n",
    "            article=self.reviews.article,\n",
    "            content=written_output,\n",
    "            first_line_number=self.reviews.selected_text.first_line_number,\n",
    "            last_line_number=self.reviews.selected_text.last_line_number,\n",
    "        )\n",
    "    else:\n",
    "        return Article(content=written_output)\n",
    "```\n",
    "\n",
    "**Context engineering for editing:**\n",
    "\n",
    "1. **User**: System prompt with all context (guidelines, profiles, etc.)\n",
    "2. **Assistant**: The previously written article\n",
    "3. **User**: The reviews with specific issues to fix\n",
    "4. **Assistant**: The edited article (generated by LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Review Prompt Templates\n",
    "\n",
    "The writer has two additional prompt templates for handling reviews. One for editing the whole article and whole for the selected text.\n",
    "\n",
    "**1. Article Reviews Prompt:**\n",
    "\n",
    "```python\n",
    "article_reviews_prompt_template = \"\"\"\n",
    "We personally reviewed the article and compiled a list of reviews based on which you have to \n",
    "edit the article you wrote one step before.\n",
    "\n",
    "## Reviewing Logic\n",
    "\n",
    "Here is how we created the feedback reviews:\n",
    "- We compared the article against the <article_guideline> to ensure it follows user intent\n",
    "- We compared against all profile constraints\n",
    "- Manual human reviews create special \"human_feedback\" reviews (highest priority)\n",
    "- For each broken rule, we created a review\n",
    "\n",
    "## Ranking the Importance of the Reviews\n",
    "\n",
    "1. Always prioritize the human feedback reviews above everything else\n",
    "2. Next prioritize reviews based on the <article_guideline>\n",
    "3. Finally prioritize reviews based on other profiles\n",
    "\n",
    "## Reviews\n",
    "\n",
    "Here are the reviews you have to fix:\n",
    "{reviews}\n",
    "\n",
    "## Chain of Thought\n",
    "\n",
    "1. Analyze the reviews to understand what needs to be changed\n",
    "2. Prioritize the reviews based on the importance ranking\n",
    "3. Apply necessary edits while following all instructions from profiles and guidelines\n",
    "4. Ensure edited text is still anchored in <research> and <article_guideline>\n",
    "5. Ensure edited text flows naturally with surrounding content\n",
    "6. Return the fully edited article\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Explains the review creation process\n",
    "- Provides clear priority ranking\n",
    "- New chain of thought section adding the new reasoning steps and final task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Selected Text Reviews Prompt:**\n",
    "\n",
    "```python\n",
    "selected_text_reviews_prompt_template = \"\"\"\n",
    "We personally reviewed only a portion of the article and compiled reviews for editing just that \n",
    "selected text.\n",
    "\n",
    "## Selected Text to Edit\n",
    "\n",
    "{selected_text}\n",
    "\n",
    "Remember this selected text is part of the article from one step before. Anchor your editing within \n",
    "the broader context of the article.\n",
    "\n",
    "Selected text editing guidelines:\n",
    "- Keep selected text consistent with surrounding article context\n",
    "- Use first and last line numbers to locate the selection\n",
    "- Only edit the selected text, don't modify the entire article\n",
    "\n",
    "## [Rest similar to article reviews prompt - reviewing logic, priority ranking, etc.]\n",
    "\n",
    "{reviews}\n",
    "\n",
    "## Chain of Thought\n",
    "\n",
    "1. Place the selected text in context of the full article\n",
    "2. Analyze the reviews\n",
    "3. Prioritize reviews based on importance ranking\n",
    "4. Apply edits while following all instructions\n",
    "5. Ensure edited selected text is still anchored in research/guideline\n",
    "6. Ensure edited selected text flows naturally with surrounding content\n",
    "7. Return the fully edited selected text\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "The prompt is similar to the one for editing the whole article, but we added special details on clearly explaining how to manipulate the selected text. Remember that LLMs have zero clue of what is going on within your application and business logic. Thus, you have to explain all your processes super clearly for this to work well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. End-to-End Example: Review and Edit Loop\n",
    "\n",
    "Now let's run a complete example showing the full workflow: generate media, write article, review, and edit. First, let's run it without LangGraph. Next, we will glue everything together into a standalone LangGraph workflow that can further be shipped to production.\n",
    "\n",
    "### Step 1: Load all necessary context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 1: Loading Context\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Guideline: 23,127 characters\n",
      "âœ“ Research: 211,792 characters, 18 images\n",
      "âœ“ Profiles: 6 profiles loaded\n",
      "âœ“ Examples: 2 article examples\n"
     ]
    }
   ],
   "source": [
    "from brown.loaders import (\n",
    "    MarkdownArticleExampleLoader,\n",
    "    MarkdownArticleGuidelineLoader,\n",
    "    MarkdownArticleProfilesLoader,\n",
    "    MarkdownResearchLoader,\n",
    ")\n",
    "\n",
    "pretty_print.wrapped(\"STEP 1: Loading Context\", width=100)\n",
    "\n",
    "# Load guideline\n",
    "guideline_loader = MarkdownArticleGuidelineLoader(uri=Path(\"article_guideline.md\"))\n",
    "article_guideline = guideline_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load research\n",
    "research_loader = MarkdownResearchLoader(uri=Path(\"research.md\"))\n",
    "research = research_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load profiles\n",
    "profiles_input = {\n",
    "    \"article\": PROFILES_DIR / \"article_profile.md\",\n",
    "    \"character\": PROFILES_DIR / \"character_profiles\" / \"paul_iusztin.md\",\n",
    "    \"mechanics\": PROFILES_DIR / \"mechanics_profile.md\",\n",
    "    \"structure\": PROFILES_DIR / \"structure_profile.md\",\n",
    "    \"terminology\": PROFILES_DIR / \"terminology_profile.md\",\n",
    "    \"tonality\": PROFILES_DIR / \"tonality_profile.md\",\n",
    "}\n",
    "profiles_loader = MarkdownArticleProfilesLoader(uri=profiles_input)\n",
    "article_profiles = profiles_loader.load()\n",
    "\n",
    "# Load examples\n",
    "examples_loader = MarkdownArticleExampleLoader(uri=EXAMPLES_DIR)\n",
    "article_examples = examples_loader.load()\n",
    "\n",
    "print(f\"âœ“ Guideline: {len(article_guideline.content):,} characters\")\n",
    "print(f\"âœ“ Research: {len(research.content):,} characters, {len(research.image_urls)} images\")\n",
    "print(\"âœ“ Profiles: 6 profiles loaded\")\n",
    "print(f\"âœ“ Examples: {len(article_examples.examples)} article examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate media items (we'll skip this for brevity - covered in Lesson 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 2: Generating Media Items\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Media items: 0 items (using empty for demo)\n"
     ]
    }
   ],
   "source": [
    "from brown.entities.media_items import MediaItems\n",
    "\n",
    "pretty_print.wrapped(\"STEP 2: Generating Media Items\", width=100)\n",
    "\n",
    "# For this example, we'll use empty media items to save time\n",
    "# In a real scenario, you'd run the MediaGeneratorOrchestrator as shown in Lesson 22\n",
    "media_items_entity = MediaItems.build([])\n",
    "\n",
    "print(f\"âœ“ Media items: {len(media_items_entity.media_items)} items (using empty for demo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write the first draft of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 3: Writing Article (First Draft)\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "This may take 1-2 minutes...\n",
      "âœ“ Article generated: 25,636 characters\n",
      "\u001b[93m-------------------------------------------- First Draft (First 1000 chars) --------------------------------------------\u001b[0m\n",
      "  # AI Workflows vs. Agents: The Architectural Decision Every Engineer Faces\n",
      "### Navigating the Spectrum of AI Autonomy to Build Production-Ready Systems\n",
      "\n",
      "When you build AI applications, you face a critical architectural decision early in the development process. Will you create a predictable, step-by-step workflow where you control every action, or will you build an autonomous agent that can think and decide for itself? This choice impacts everything from development time and costs to reliability and user experience.\n",
      "\n",
      "Choosing the wrong approach can lead to real headaches. An overly rigid system might break when users deviate from expected patterns, or developers try to add new features. Conversely, an unpredictable agent might work brilliantly 80% of the time but fail catastrophically when it matters most, leading to frustrated users and executives facing high operational costs. Billion-dollar AI startups in 2024-2025 succeed or fail based primarily on this architectural decision. Succ\n",
      "\u001b[93m------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.nodes import ArticleWriter\n",
    "\n",
    "pretty_print.wrapped(\"STEP 3: Writing Article (First Draft)\", width=100)\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "writer_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_writer = ArticleWriter(\n",
    "    article_guideline=article_guideline,\n",
    "    research=research,\n",
    "    article_profiles=article_profiles,\n",
    "    media_items=media_items_entity,\n",
    "    article_examples=article_examples,\n",
    "    model=writer_model,\n",
    "    reviews=None,  # No reviews for first draft\n",
    ")\n",
    "\n",
    "article = await article_writer.ainvoke()\n",
    "\n",
    "print(f\"âœ“ Article generated: {len(article.content):,} characters\")\n",
    "pretty_print.wrapped(article.content[:1000], title=\"First Draft (First 1000 chars)\", width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Review the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 4: Reviewing Article\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Generated 36 reviews\n",
      "\n",
      "Reviews:\n",
      "\n",
      "  1. Profile: structure_profile\n",
      "     Location: Image 1: A simple Retrieval-Augmented Generation (RAG) workflow.\n",
      "     Comment: The image caption for 'Image 1' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It should...\n",
      "\n",
      "  2. Profile: structure_profile\n",
      "     Location: Image 2: The components of an LLM-powered agent (Image by author from [A Developerâ€™s Guide to Building Scalable AI: Workflows vs Agents](https://towardsdatascience.com/a-developers-guide-to-building-scalable-ai-workflows-vs-agents/))\n",
      "     Comment: The image caption for 'Image 2' incorrectly uses the format '(Image by author from [A Developerâ€™s Guide to Building Scalable AI: Workflows vs Agents](...\n",
      "\n",
      "  3. Profile: structure_profile\n",
      "     Location: Image 3: Differences between workflows and agents (Source [Exploring the difference between agents and workflows](https://decodingml.substack.com/p/llmops-for-production-agentic-rag))\n",
      "     Comment: The image caption for 'Image 3' incorrectly uses the format '(Source [Exploring the difference between agents and workflows](https://decodingml.substa...\n",
      "\n",
      "  4. Profile: structure_profile\n",
      "     Location: Image 5: The chaining and routing pattern for LLM workflows.\n",
      "     Comment: The image caption for 'Image 5' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It should...\n",
      "\n",
      "  5. Profile: structure_profile\n",
      "     Location: Image 6: The orchestrator-worker pattern.\n",
      "     Comment: The image caption for 'Image 6' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It should...\n",
      "\n",
      "  6. Profile: structure_profile\n",
      "     Location: Image 7: The evaluator-optimizer loop pattern.\n",
      "     Comment: The image caption for 'Image 7' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It should...\n",
      "\n",
      "  7. Profile: structure_profile\n",
      "     Location: Image 8: The core components of an AI agent, illustrating the ReAct pattern.\n",
      "     Comment: The image caption for 'Image 8' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It should...\n",
      "\n",
      "  8. Profile: structure_profile\n",
      "     Location: Image 9: Document summarization and analysis workflow by Gemini in Google Workspace.\n",
      "     Comment: The image caption for 'Image 9' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It should...\n",
      "\n",
      "  9. Profile: structure_profile\n",
      "     Location: Image 10: The operational loop of the Gemini CLI coding assistant.\n",
      "     Comment: The image caption for 'Image 10' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It shoul...\n",
      "\n",
      "  10. Profile: structure_profile\n",
      "     Location: Image 11: The iterative multi-step process of Perplexity Deep Research.\n",
      "     Comment: The image caption for 'Image 11' is missing the source URL and citation as required by the `image_caption` format in the `structure_profile`. It shoul...\n",
      "\n",
      "  11. Profile: article_guideline\n",
      "     Location: Section 1 - Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\n",
      "     Comment: The section is missing the 'Quick walkthrough of what we'll learn by the end of this lesson' as specified in the article guideline. The guideline requ...\n",
      "\n",
      "  12. Profile: article_guideline\n",
      "     Location: Section 1 - Introduction: The Critical Decision Every AI Engineer Faces\n",
      "     Comment: The word count for this section is 172 words. The `article_guideline` specifies a section length of 300 words, indicating that the current content is ...\n",
      "\n",
      "  13. Profile: article_guideline\n",
      "     Location: Section 2 - Understanding the Spectrum: From Workflows to Agents\n",
      "     Comment: The word count for this section is 242 words. The `article_guideline` specifies a section length of 400 words, indicating that the current content is ...\n",
      "\n",
      "  14. Profile: article_guideline\n",
      "     Location: Section 3: Choosing Your Path\n",
      "     Comment: The word count for this section is 762 words (excluding the mermaid diagram code). The `article_guideline` specifies a section length of 500 words, in...\n",
      "\n",
      "  15. Profile: structure_profile\n",
      "     Location: Section 3: Choosing Your Path - Third paragraph\n",
      "     Comment: The article uses the phrase 'Ultimately, using smaller models reduces infrastructure overhead.' The 'Ultimately' adverb falls into the 'AI Slop' categ...\n",
      "\n",
      "  16. Profile: structure_profile\n",
      "     Location: Section 3: Choosing Your Path - Sixth paragraph\n",
      "     Comment: The paragraph exceeds the maximum length of 80 words. It has 87 words. The `structure_profile` under 'Sentence and paragraph length patterns' states, ...\n",
      "\n",
      "  17. Profile: article_guideline\n",
      "     Location: Section 4: Exploring Common Patterns\n",
      "     Comment: The article's Section 4 is missing the mermaid diagrams for 'Chaining and routing', 'Orchestrator-worker', and 'Evaluator-optimizer loop' LLM workflow...\n",
      "\n",
      "  18. Profile: article_guideline\n",
      "     Location: Section 4: Exploring Common Patterns\n",
      "     Comment: The word count for this section is 471 words. The `article_guideline` specifies a section length of 550 words, indicating that the current content is ...\n",
      "\n",
      "  19. Profile: article_guideline\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples\n",
      "     Comment: The article's Section 5 is missing the mermaid diagrams for 'Document summarization and analysis workflow by Gemini in Google Workspace', 'Gemini CLI ...\n",
      "\n",
      "  20. Profile: article_guideline\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples\n",
      "     Comment: The word count for this section is 1238 words (excluding the mermaid diagram code). The `article_guideline` specifies a section length of 900 words, i...\n",
      "\n",
      "  21. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Second paragraph\n",
      "     Comment: The paragraph exceeds the maximum length of 80 words. It has 94 words. The `structure_profile` under 'Sentence and paragraph length patterns' states, ...\n",
      "\n",
      "  22. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Third paragraph\n",
      "     Comment: The article states 'To build up the intuition on agents, we present at a very high and intuitive level how the Gemini CLI tool leverages the ReAct (Re...\n",
      "\n",
      "  23. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Fifth paragraph\n",
      "     Comment: The article states 'To keep the examples light and intuitive, use parallels such as: tools as actions context as state or working memory'. This phrasi...\n",
      "\n",
      "  24. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Sixth paragraph\n",
      "     Comment: The paragraph exceeds the maximum length of 80 words. It has 82 words. The `structure_profile` under 'Sentence and paragraph length patterns' states, ...\n",
      "\n",
      "  25. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Seventh paragraph\n",
      "     Comment: The article uses a numbered list to explain the Gemini CLI's operational loop. While numbered lists are allowed for 'big chunks of information', the d...\n",
      "\n",
      "  26. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Ninth paragraph\n",
      "     Comment: The article states 'To build up the intuition on LLM workflows and AI agents hybrid systems we will present how the Perplexity's Deep Research agent a...\n",
      "\n",
      "  27. Profile: structure_profile\n",
      "     Location: Section 5: Zooming In on Our Favorite Examples - Eleventh paragraph\n",
      "     Comment: The article uses a numbered list to explain 'Perplexity's Deep Research agent could work'. While numbered lists are allowed for 'big chunks of informa...\n",
      "\n",
      "  28. Profile: article_guideline\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer\n",
      "     Comment: The word count for this section is 436 words. The `article_guideline` specifies a section length of 350 words, indicating that the current content is ...\n",
      "\n",
      "  29. Profile: structure_profile\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - First paragraph\n",
      "     Comment: The article uses the phrase 'Now that you understand the spectrum from LLM workflows to AI agents, it's important to recognize that every AI Engineerâ€”...\n",
      "\n",
      "  30. Profile: structure_profile\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - Second paragraph\n",
      "     Comment: The article states 'To set the scene for future lessons and patterns we will learn, present some daily challenges every AI engineer battles:'. This ph...\n",
      "\n",
      "  31. Profile: terminology_profile\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - Second paragraph - 'Context Limits' item\n",
      "     Comment: The article uses the word 'presents' in 'Ensuring consistent output quality across different agent specializations presents a continuous challenge.' T...\n",
      "\n",
      "  32. Profile: terminology_profile\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - Second paragraph - 'Cost-Performance Trap' item\n",
      "     Comment: The article uses the word 'feasible' in 'making them economically unfeasible for many applications.' The `terminology_profile` under 'Word Choice Patt...\n",
      "\n",
      "  33. Profile: terminology_profile\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - Second paragraph - 'Security Concerns' item\n",
      "     Comment: The article uses the word 'critical' in 'delete critical files'. The `terminology_profile` under 'AI Slop Banned Words List' explicitly bans the word ...\n",
      "\n",
      "  34. Profile: terminology_profile\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - Third paragraph\n",
      "     Comment: The article uses the phrase 'The good news is that these challenges are solvable.' The `terminology_profile` under 'AI Slop Banned Words List' explici...\n",
      "\n",
      "  35. Profile: article_guideline\n",
      "     Location: Section 6 - Conclusion: The Challenges of Every AI Engineer - Fourth paragraph\n",
      "     Comment: The paragraph should clearly transition to the next lesson (Lesson 3) and make slight references to other topics from `Concepts That Will Be Introduce...\n",
      "\n",
      "  36. Profile: mechanics_profile\n",
      "     Location: References\n",
      "     Comment: The references section has several issues with the APA 7th edition format and numbering as per `references_rules` and `correction_reference_rules`. \n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\"STEP 4: Reviewing Article\", width=100)\n",
    "\n",
    "reviewer_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_reviewer = ArticleReviewer(\n",
    "    to_review=article,\n",
    "    article_guideline=article_guideline,\n",
    "    article_profiles=article_profiles,\n",
    "    model=reviewer_model,\n",
    "    human_feedback=None,\n",
    ")\n",
    "\n",
    "article_reviews = await article_reviewer.ainvoke()\n",
    "\n",
    "print(f\"âœ“ Generated {len(article_reviews.reviews)} reviews\")\n",
    "print(\"\\nReviews:\")\n",
    "for i, review in enumerate(article_reviews.reviews, 1):\n",
    "    print(f\"\\n  {i}. Profile: {review.profile}\")\n",
    "    print(f\"     Location: {review.location}\")\n",
    "    print(\n",
    "        f\"     Comment: {review.comment[:150]}...\" if len(review.comment) > 150 else f\"     Comment: {review.comment}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the article based on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 5: Editing Article Based on Reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "This may take 1-2 minutes...\n",
      "âœ“ Article edited: 27,590 characters\n",
      "\u001b[93m------------------------------------------ Edited Article (First 1000 chars) ------------------------------------------\u001b[0m\n",
      "  Here is the revised article, incorporating all the feedback and adhering to the specified profiles.\n",
      "\n",
      "<article>\n",
      "# AI Workflows vs. Agents: The Architectural Decision Every Engineer Faces\n",
      "### Navigating the Spectrum of AI Autonomy to Build Production-Ready Systems\n",
      "\n",
      "When you build AI applications, you face a critical architectural decision early in the development process. Will you create a predictable, step-by-step workflow where you control every action, or will you build an autonomous agent that can think and decide for itself? This choice impacts everything from development time and costs to reliability and user experience.\n",
      "\n",
      "Choosing the wrong approach can lead to real headaches. An overly rigid system might break when users deviate from expected patterns, or developers try to add new features. Conversely, an unpredictable agent might work brilliantly 80% of the time but fail catastrophically when it matters most, leading to frustrated users and executives facing high operational cost\n",
      "\u001b[93m------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\"STEP 5: Editing Article Based on Reviews\", width=100)\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "editor_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_editor = ArticleWriter(\n",
    "    article_guideline=article_guideline,\n",
    "    research=research,\n",
    "    article_profiles=article_profiles,\n",
    "    media_items=media_items_entity,\n",
    "    article_examples=article_examples,\n",
    "    model=editor_model,\n",
    "    reviews=article_reviews,  # Pass reviews to trigger editing mode\n",
    ")\n",
    "\n",
    "edited_article = await article_editor.ainvoke()\n",
    "\n",
    "print(f\"âœ“ Article edited: {len(edited_article.content):,} characters\")\n",
    "pretty_print.wrapped(edited_article.content[:1000], title=\"Edited Article (First 1000 chars)\", width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compare original vs edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------- COMPARISON: Original vs Edited ----------------------------------\u001b[0m\n",
      "  Original length: 25,636 characters\n",
      "Edited length: 27,590 characters\n",
      "Difference: +1,954 characters\n",
      "\n",
      "Number of reviews addressed: 36\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "comparison_text = f\"\"\"Original length: {len(article.content):,} characters\n",
    "Edited length: {len(edited_article.content):,} characters\n",
    "Difference: {len(edited_article.content) - len(article.content):+,} characters\n",
    "\n",
    "Number of reviews addressed: {len(article_reviews.reviews)}\"\"\"\n",
    "\n",
    "pretty_print.wrapped(comparison_text, title=\"COMPARISON: Original vs Edited\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Save the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved first draft to: inputs/tests/01_sample/article_draft.md\n",
      "âœ“ Saved edited version to: inputs/tests/01_sample/article_edited.md\n"
     ]
    }
   ],
   "source": [
    "from brown.renderers import MarkdownArticleRenderer\n",
    "\n",
    "renderer = MarkdownArticleRenderer()\n",
    "\n",
    "# Save first draft\n",
    "first_draft_path = SAMPLE_DIR / \"article_draft.md\"\n",
    "renderer.render(article, output_uri=first_draft_path)\n",
    "\n",
    "# Save edited version\n",
    "edited_path = SAMPLE_DIR / \"article_edited.md\"\n",
    "renderer.render(edited_article, output_uri=edited_path)\n",
    "\n",
    "print(f\"\\nâœ“ Saved first draft to: {first_draft_path}\")\n",
    "print(f\"âœ“ Saved edited version to: {edited_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. App Configuration: Centralized Control\n",
    "\n",
    "Before gluing everything together into a LangGraph workflow, let's explore our centralized configuration system. This allows us to configure the entire application from a single YAML file.\n",
    "\n",
    "### Why Centralized Configuration?\n",
    "\n",
    "As our system grows more complex, we need:\n",
    "\n",
    "- **Single source of truth**: One file that controls everything\n",
    "- **Easy experimentation**: Change models, parameters without touching code\n",
    "- **Environment-specific configs**: Different settings for dev/prod\n",
    "- **Version control**: Track configuration changes over time\n",
    "\n",
    "The Brown agent uses a Pydantic-based configuration system that validates all settings at load time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The AppConfig Class Structure\n",
    "\n",
    "From `brown.config_app`, here's the configuration class hierarchy:\n",
    "\n",
    "**1. Context Configuration:**\n",
    "\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, DirectoryPath, Field\n",
    "from typing import Literal, Annotated\n",
    "\n",
    "\n",
    "class Context(BaseModel):\n",
    "    # Article guideline\n",
    "    article_guideline_loader: Literal[\"markdown\"]\n",
    "    article_guideline_uri: Path\n",
    "\n",
    "    # Research\n",
    "    research_loader: Literal[\"markdown\"]\n",
    "    research_uri: Path\n",
    "\n",
    "    # Article\n",
    "    article_loader: Literal[\"markdown\"]\n",
    "    article_renderer: Literal[\"markdown\"]\n",
    "    article_uri: Path\n",
    "\n",
    "    # Profiles\n",
    "    profiles_loader: Literal[\"markdown\"]\n",
    "    profiles_uri: Annotated[DirectoryPath, Field(description=\"URI to profiles directory\")]\n",
    "    character_profile: str\n",
    "\n",
    "    # Examples\n",
    "    examples_loader: Literal[\"markdown\"]\n",
    "    examples_uri: Annotated[DirectoryPath, Field(description=\"URI to examples directory\")]\n",
    "\n",
    "    def build_article_uri(self, iteration: int) -> Path:\n",
    "        return self.article_uri.with_stem(f\"{self.article_uri.stem}_{iteration:03d}\")\n",
    "```\n",
    "\n",
    "This defines all the paths and loaders for different content types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Node and Tool Configuration:**\n",
    "```python\n",
    "from brown.models.config import ModelConfig, SupportedModels\n",
    "\n",
    "\n",
    "class ToolConfig(BaseModel):\n",
    "    name: str\n",
    "    model_id: SupportedModels\n",
    "    config: ModelConfig\n",
    "\n",
    "\n",
    "class NodeConfig(BaseModel):\n",
    "    model_id: SupportedModels\n",
    "    config: ModelConfig\n",
    "    tools: dict[str, ToolConfig]\n",
    "```\n",
    "\n",
    "Each node can have its own model and configuration. Tools (like diagram generators) have their own configs too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Memory Configuration:**\n",
    "```python\n",
    "class Memory(BaseModel):\n",
    "    checkpointer: Literal[\"in_memory\", \"sqlite\"]\n",
    "```\n",
    "\n",
    "Controls which checkpointing strategy to use for workflow state persistence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The Main AppConfig Class:**\n",
    "```python\n",
    "from annotated_types import Ge\n",
    "\n",
    "\n",
    "class AppConfig(BaseModel):\n",
    "    context: Context\n",
    "    memory: Memory\n",
    "    \n",
    "    num_reviews: Annotated[int, Ge(1), Field(\n",
    "        description=\"The number of reviews to perform while generating the article\"\n",
    "    )]\n",
    "    nodes: dict[str, NodeConfig]\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, file_path: Path) -> \"AppConfig\":\n",
    "        \"\"\"Load configuration from a YAML file.\"\"\"\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"Configuration file not found: {file_path}\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        return cls(**data)\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- `num_reviews`: How many review-edit iterations to run\n",
    "- `nodes`: Configuration for each workflow node\n",
    "- `from_yaml()`: Load configuration from YAML file\n",
    "- Full Pydantic validation ensures type safety\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Configuration File\n",
    "\n",
    "Let's look at an actual configuration file from `configs/course.yaml`:\n",
    "\n",
    "```yaml\n",
    "context:\n",
    "  article_guideline_loader: \"markdown\"\n",
    "  article_guideline_uri: \"article_guideline.md\"\n",
    "  research_loader: \"markdown\"\n",
    "  research_uri: \"research.md\"\n",
    "  article_loader: \"markdown\"\n",
    "  article_renderer: \"markdown\"\n",
    "  article_uri: \"article.md\"\n",
    "  profiles_loader: \"markdown\"\n",
    "  profiles_uri: \"inputs/profiles\"\n",
    "  character_profile: \"paul_iusztin.md\"\n",
    "  examples_loader: \"markdown\"\n",
    "  examples_uri: \"inputs/examples/course_lessons\"\n",
    "\n",
    "memory:\n",
    "  checkpointer: \"in_memory\"\n",
    "\n",
    "num_reviews: 2\n",
    "\n",
    "nodes:\n",
    "  generate_media_items:\n",
    "    model_id: \"google_genai:gemini-2.5-flash\"\n",
    "    model_config:\n",
    "      temperature: 0.0\n",
    "      include_thoughts: false\n",
    "      thinking_budget: null\n",
    "    tools:\n",
    "      mermaid_diagram_generator:\n",
    "        model_id: \"google_genai:gemini-2.5-flash\"\n",
    "        config:\n",
    "          temperature: 0.0\n",
    "          include_thoughts: false\n",
    "\n",
    "  write_article:\n",
    "    model_id: \"google_genai:gemini-2.5-pro\"\n",
    "    model_config:\n",
    "      temperature: 0.7\n",
    "      include_thoughts: false\n",
    "\n",
    "  review_article:\n",
    "    model_id: \"google_genai:gemini-2.5-pro\"\n",
    "    model_config:\n",
    "      temperature: 0.0\n",
    "      include_thoughts: false\n",
    "\n",
    "  edit_article:\n",
    "    model_id: \"google_genai:gemini-2.5-pro\"\n",
    "    model_config:\n",
    "      temperature: 0.1\n",
    "      include_thoughts: false\n",
    "```\n",
    "\n",
    "**Configuration Highlights:**\n",
    "\n",
    "- **Media generation**: Uses fast Flash model with 0 temperature (deterministic)\n",
    "- **Article writing**: Uses Pro model with higher temperature (0.7) for creativity\n",
    "- **Reviewing**: Uses Pro model with 0 temperature (strict adherence to rules)\n",
    "- **Editing**: Uses Pro model with low temperature (0.1) for focused changes\n",
    "- **2 review iterations**: Runs the review-edit loop twice\n",
    "\n",
    "This fine-grained control lets you optimize for quality, speed, and cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Using the Configuration\n",
    "\n",
    "Let's load a configuration file and examine it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ Configuration ------------------------------------------\u001b[0m\n",
      "  \n",
      "Configuration loaded successfully!\n",
      "Num review iterations: 2\n",
      "Memory checkpointer: in_memory\n",
      "Character profile: paul_iusztin.md\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------- Configured nodes -----------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"generate_media_items\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.0,\n",
      "    \"Tools\": [\n",
      "      \"mermaid_diagram_generator\"\n",
      "    ]\n",
      "  },\n",
      "  \"write_article\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.7\n",
      "  },\n",
      "  \"review_article\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.0\n",
      "  },\n",
      "  \"edit_article\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.1\n",
      "  },\n",
      "  \"review_selected_text\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.0\n",
      "  },\n",
      "  \"edit_selected_text\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.1\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.config_app import AppConfig\n",
    "\n",
    "# Load configuration from YAML\n",
    "config_path = CONFIGS_DIR / \"course.yaml\"\n",
    "app_config = AppConfig.from_yaml(config_path)\n",
    "\n",
    "text = f\"\"\"\n",
    "Configuration loaded successfully!\n",
    "Num review iterations: {app_config.num_reviews}\n",
    "Memory checkpointer: {app_config.memory.checkpointer}\n",
    "Character profile: {app_config.context.character_profile}\n",
    "\"\"\"\n",
    "pretty_print.wrapped(text, title=\"Configuration\", width=100)\n",
    "\n",
    "node_info = {}\n",
    "for node_name, node_config in app_config.nodes.items():\n",
    "    node_dict = {\n",
    "        \"Model\": node_config.model_id,\n",
    "        \"Temperature\": node_config.config.temperature,\n",
    "    }\n",
    "    if node_config.tools:\n",
    "        node_dict[\"Tools\"] = list(node_config.tools.keys())\n",
    "    node_info[node_name] = node_dict\n",
    "pretty_print.wrapped(node_info, title=\"Configured nodes\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of This Approach\n",
    "\n",
    "1. **Experimentation**: Change models/temperatures without editing code\n",
    "2. **Cost optimization**: Use cheaper models for simple tasks\n",
    "3. **Quality tuning**: Adjust temperatures per task\n",
    "4. **Environment flexibility**: Different configs for dev/staging/prod\n",
    "5. **Reproducibility**: Version control your configurations\n",
    "6. **Global overview**: You can see the whole setup in a glance\n",
    "\n",
    "This configuration-driven approach makes the system highly flexible and easy to iterate on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LangGraph Workflow Integration\n",
    "\n",
    "Now let's explore how everything is glued together into a robust LangGraph workflow. The complete workflow is in `brown.workflows.generate_article`.\n",
    "\n",
    "### Workflow Architecture\n",
    "\n",
    "The workflow uses LangGraph's Function API to orchestrate the complete article generation process. Let's break down the key components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Workflow\n",
    "\n",
    "**1. The Build Function:**\n",
    "```python\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "\n",
    "\n",
    "def build_generate_article_workflow(checkpointer: BaseCheckpointSaver):\n",
    "    \"\"\"Create a generate article workflow with optional checkpointer.\n",
    "    \n",
    "    Args:\n",
    "        checkpointer: Checkpointer to use for workflow state persistence\n",
    "        \n",
    "    Returns:\n",
    "        Configured workflow entrypoint\n",
    "    \"\"\"\n",
    "    return entrypoint(checkpointer=checkpointer)(_generate_article_workflow)\n",
    "```\n",
    "\n",
    "**Why This Pattern?**\n",
    "\n",
    "We could directly decorate `_generate_article_workflow` with `@entrypoint`, but this builder function allows us to:\n",
    "\n",
    "1. **Inject dependencies at runtime**: Pass the checkpointer when building the workflow\n",
    "2. **Follow clean architecture**: Separate infrastructure (checkpointer) from business logic\n",
    "3. **Enable testing**: Easily swap checkpointers for different environments\n",
    "\n",
    "This pattern makes sense when you see how it's called in the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. The Workflow Input:**\n",
    "\n",
    "```python\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class GenerateArticleInput(TypedDict):\n",
    "    dir_path: Path\n",
    "```\n",
    "\n",
    "Simple typed input containing just the directory path where all resources are located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. The Main Workflow Function:**\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.config import get_stream_writer, RunnableConfig\n",
    "\n",
    "\n",
    "async def _generate_article_workflow(inputs: GenerateArticleInput, config: RunnableConfig) -> str:\n",
    "    dir_path = inputs[\"dir_path\"]\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    writer = get_stream_writer()\n",
    "    \n",
    "    # Step 1: Load context\n",
    "    writer(WorkflowProgress(progress=0, message=\"Loading context\").model_dump(mode=\"json\"))\n",
    "    context = {}\n",
    "    loaders = build_loaders(app_config)\n",
    "    for context_name in [\"article_guideline\", \"research\", \"profiles\", \"examples\"]:\n",
    "        loader = cast(Loader, loaders[context_name])\n",
    "        context[context_name] = loader.load(working_uri=dir_path)\n",
    "    writer(WorkflowProgress(progress=2, message=\"Loaded context\").model_dump(mode=\"json\"))\n",
    "    \n",
    "    # Step 2: Generate media items\n",
    "    writer(WorkflowProgress(progress=3, message=\"Generating media items\").model_dump(mode=\"json\"))\n",
    "    media_items = await generate_media_items(context[\"article_guideline\"], context[\"research\"])\n",
    "    writer(WorkflowProgress(progress=10, message=\"Generated media items\").model_dump(mode=\"json\"))\n",
    "    \n",
    "    # Step 3: Write article\n",
    "    writer(WorkflowProgress(progress=15, message=\"Writing article\").model_dump(mode=\"json\"))\n",
    "    article = await write_article(...) \n",
    "    writer(WorkflowProgress(progress=20, message=\"Written raw article\").model_dump(mode=\"json\"))\n",
    "    \n",
    "    # Save iteration 0\n",
    "    article_path = dir_path / app_config.context.build_article_uri(0)\n",
    "    article_renderer = build_article_renderer(app_config)\n",
    "    article_renderer.render(article, output_uri=article_path)\n",
    "    \n",
    "    # Steps 4-5: Review and edit loop\n",
    "    for i in range(1, app_config.num_reviews + 1):\n",
    "        # Review\n",
    "        reviews = await generate_reviews(article, context[\"article_guideline\"], context[\"profiles\"])\n",
    "        \n",
    "        # Edit\n",
    "        article = await edit_based_on_reviews(...)\n",
    "        \n",
    "        # Save iteration i\n",
    "        article_path = dir_path / app_config.context.build_article_uri(i)\n",
    "        article_renderer.render(article, output_uri=article_path)\n",
    "    \n",
    "    # Save final article\n",
    "    article_path = dir_path / app_config.context.article_uri\n",
    "    article_renderer.render(article, output_uri=article_path)\n",
    "    \n",
    "    return f\"Final article rendered to `{article_path}`.\"\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "1. **Progress reporting**: Uses `get_stream_writer()` to send progress updates\n",
    "2. **Iterative refinement**: Loops through review-edit cycles\n",
    "3. **Version saving**: Saves each iteration for comparison\n",
    "4. **Configuration-driven**: Uses `app_config` for all settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The Task Functions with Retry Policies:**\n",
    "\n",
    "Each major step is wrapped in a `@task` decorator with retry policies:\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.func import task\n",
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "retry_policy = RetryPolicy(max_attempts=3, retry_on=Exception)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_media_items(article_guideline: ArticleGuideline, research: Research) -> MediaItems:\n",
    "    writer = get_stream_writer()\n",
    "    \n",
    "    model, toolkit = build_model(app_config, node=\"generate_media_items\")\n",
    "    media_generator_orchestrator = MediaGeneratorOrchestrator(...)\n",
    "    media_items_to_generate_jobs = await media_generator_orchestrator.ainvoke()\n",
    "    \n",
    "    # Generate media items in parallel\n",
    "    coroutines = [tool.ainvoke(job[\"args\"]) for job in media_items_to_generate_jobs]\n",
    "    media_items = await asyncio.gather(*coroutines)\n",
    "    \n",
    "    return MediaItems.build(media_items)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def write_article(...) -> Article:\n",
    "    model, _ = build_model(app_config, node=\"write_article\")\n",
    "    article_writer = ArticleWriter(...)\n",
    "    article = await article_writer.ainvoke()\n",
    "    return cast(Article, article)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_reviews(...) -> ArticleReviews:\n",
    "    model, _ = build_model(app_config, node=\"review_article\")\n",
    "    article_reviewer = ArticleReviewer(...)\n",
    "    reviews = await article_reviewer.ainvoke()\n",
    "    return cast(ArticleReviews, reviews)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def edit_based_on_reviews(...) -> Article:\n",
    "    model, _ = build_model(app_config, node=\"edit_article\")\n",
    "    article_writer = ArticleWriter(..., reviews=reviews)\n",
    "    article = await article_writer.ainvoke()\n",
    "    return cast(Article, article)\n",
    "```\n",
    "\n",
    "**Why Retry Policies?**\n",
    "\n",
    "- **Resilience**: API failures, rate limits, network issues happen\n",
    "- **Automatic recovery**: Retry failed steps without manual intervention\n",
    "- **Task-level granularity**: Only retry the failed step, not the entire workflow\n",
    "- **Production-ready**: Makes the system robust for real-world use\n",
    "\n",
    "Having each step as a separate task with single responsibility makes retry policies extremely effective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Short-Term Memory: Checkpointing\n",
    "\n",
    "Before running the complete workflow, let's understand the checkpointing system that provides workflow state persistence.\n",
    "\n",
    "### Why Checkpointing?\n",
    "\n",
    "Checkpointing serves several purposes:\n",
    "\n",
    "1. **Resume from failure**: If a workflow crashes, resume from the last checkpoint. For example, resume from the last `generate_reviews` step that crashed.\n",
    "2. **State inspection**: Examine workflow state at any point\n",
    "3. **Debugging**: Step through workflow execution\n",
    "4. **Human-in-the-loop**: Pause for human input, then resume\n",
    "\n",
    "For our use case, checkpointing enables the review-edit iterations to maintain state between steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InMemory Checkpointer\n",
    "\n",
    "From `brown.memory`, we have a simple in-memory checkpointer factory:\n",
    "\n",
    "\n",
    "```python\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import AsyncIterator\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def build_in_memory_checkpointer() -> AsyncIterator[InMemorySaver]:\n",
    "    \"\"\"Build an in-memory checkpointer.\n",
    "    \n",
    "    Returns an async context manager that yields an InMemorySaver.\n",
    "    \n",
    "    Yields:\n",
    "        InMemorySaver instance\n",
    "    \"\"\"\n",
    "    yield InMemorySaver()\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "\n",
    "- **Ephemeral**: State lost when process ends\n",
    "- **Development-friendly**: Perfect for testing and iteration\n",
    "- **No persistence**: Not suitable for production long-running workflows\n",
    "\n",
    "**When to use**: Development, testing, short-lived workflows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Complete LangGraph Example\n",
    "\n",
    "Now let's run the complete workflow with LangGraph integration! This brings together everything we've learned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  COMPLETE WORKFLOW WITH LANGGRAPH\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from brown.memory import build_in_memory_checkpointer\n",
    "from brown.workflows.generate_article import GenerateArticleInput, build_generate_article_workflow\n",
    "\n",
    "pretty_print.wrapped(\"COMPLETE WORKFLOW WITH LANGGRAPH\", width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Building short-term memory...\n",
      "   âœ“ In-memory checkpointer created\n",
      "\n",
      "2. Building workflow...\n",
      "   âœ“ Workflow built with checkpointer\n",
      "\n",
      "3. Configuring workflow...\n",
      "   âœ“ Thread ID: 0eaae8af-a61a-405b-86b3-10bf38655a42\n",
      "\n",
      "4. Running workflow...\n",
      "   This will take several minutes...\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 0,\n",
      "  \"message\": \"Loading context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 2,\n",
      "  \"message\": \"Loaded context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 3,\n",
      "  \"message\": \"Genererating media items\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  Found 8 media items to generate using the following tool configurations:\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 1: mermaid_diagram_generator_tool - A flowchart illustrating the AI generation and human verification loop. It should show a human initiating an LLM call, which then performs an action on an environment. Feedback from the environment is returned to the LLM call. The loop should include a human verification step and a stop condition, emphasizing the iterative nature and the human's role in supervising and validating AI-generated output, similar to the 'autonomy slider' concept.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 2: mermaid_diagram_generator_tool - A flowchart illustrating the 'Chaining and Routing' pattern for LLM workflows. The diagram should show an input entering a router or a conditional logic component. From there, the flow should branch to multiple distinct LLM calls or specialized tasks based on the routing decision, ultimately leading to a consolidated output. This visual should highlight how inputs are directed to appropriate processing paths.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 3: mermaid_diagram_generator_tool - A flowchart illustrating the 'Orchestrator-Worker' pattern in LLM workflows. The diagram should depict a central Orchestrator LLM receiving an initial input. This orchestrator should then dynamically delegate various sub-tasks to multiple Worker LLMs or specialized tools. After the worker components complete their tasks, the orchestrator should gather and synthesize their individual results into a final, comprehensive output.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 4: mermaid_diagram_generator_tool - A flowchart illustrating the 'Evaluator-Optimizer Loop' pattern for LLM output refinement. The diagram should show a Generator LLM producing an initial output. This output is then fed to an Evaluator LLM, which analyzes it and generates feedback or an error report. This feedback is then sent back to the Generator LLM, forming an iterative loop for continuous refinement and auto-correction until the output meets desired criteria.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 5: mermaid_diagram_generator_tool - A diagram illustrating the core components and dynamics of an AI agent using the ReAct (Reason and Act) pattern. The diagram should feature an 'Agent' (representing the LLM) at its center. This agent should interact with 'Tools' (for taking actions in the environment) and 'Memory' (including short-term and long-term components). The flow should clearly show an iterative loop where the agent 'Reasons', then 'Acts' by calling a tool, 'Observes' the tool's output, and then 'Reasons' again to decide the next step, emphasizing the dynamic decision-making process.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 6: mermaid_diagram_generator_tool - A flowchart illustrating a simple LLM workflow for document summarization and analysis, specifically for Gemini in Google Workspace. The workflow should consist of the following sequential steps: 'Read Document', followed by 'Summarize using LLM Call', then 'Extract Key Points using another LLM Call', subsequently 'Save Results to Database', and finally 'Show Results to User'. The diagram should clearly depict these steps in a linear, chained fashion to highlight its workflow nature.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 7: mermaid_diagram_generator_tool - A flowchart illustrating the operational loop of the Gemini CLI coding assistant, which leverages the ReAct agent architecture. The loop should clearly show the following sequential and iterative steps: 'Context Gathering', 'LLM Reasoning', 'Human in the Loop (Validation)', 'Tool Execution', 'Evaluation (Running/Compiling Code)', and 'Loop Decision'. The diagram should emphasize the iterative nature of these steps, the point of human interaction for validation, and the use of tools within the execution phase.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 8: mermaid_diagram_generator_tool - A complex flowchart illustrating the iterative multi-step process of Perplexity's Deep Research agent, a hybrid system combining ReAct reasoning with LLM workflow patterns. The diagram should show an 'Orchestrator' initiating 'Research Planning & Decomposition' into sub-questions. This should lead to parallel execution of 'Specialized Search Agents' (workers) for 'Parallel Information Gathering' using 'Tools'. The agents then perform 'Analysis & Synthesis' of sources. The orchestrator then conducts 'Iterative Refinement & Gap Analysis', potentially generating follow-up queries in a loop. Finally, 'Report Generation' consolidates the findings. The diagram should highlight the orchestrator-worker pattern and the iterative nature of the research process.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  Executing 8 media item generation jobs in parallel.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  Generated 8 media items.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 10,\n",
      "  \"message\": \"Generated media items\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 15,\n",
      "  \"message\": \"Writing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 20,\n",
      "  \"message\": \"Written raw article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 25,\n",
      "  \"message\": \"Rendered raw article to `inputs/tests/01_sample/article_000.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 37,\n",
      "  \"message\": \"Rewiewing article [Iteration 1 / 2]\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 37,\n",
      "  \"message\": \"Generated reviews\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 50,\n",
      "  \"message\": \"Editing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 50,\n",
      "  \"message\": \"Edited article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 62,\n",
      "  \"message\": \"Rendered article to `inputs/tests/01_sample/article_001.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 75,\n",
      "  \"message\": \"Rewiewing article [Iteration 2 / 2]\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 75,\n",
      "  \"message\": \"Generated reviews\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 87,\n",
      "  \"message\": \"Editing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 87,\n",
      "  \"message\": \"Edited article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 99,\n",
      "  \"message\": \"Rendered article to `inputs/tests/01_sample/article_002.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 100,\n",
      "  \"message\": \"Final article rendered to `inputs/tests/01_sample/article.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Output ----------------------------------------------\u001b[0m\n",
      "  Final article rendered to`inputs/tests/01_sample/article.md`.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  WORKFLOW COMPLETE - Check SAMPLE_DIR for generated articles\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Building short-term memory...\")\n",
    "async with build_in_memory_checkpointer() as checkpointer:\n",
    "    print(\"   âœ“ In-memory checkpointer created\")\n",
    "\n",
    "    print(\"\\n2. Building workflow...\")\n",
    "    workflow = build_generate_article_workflow(checkpointer=checkpointer)\n",
    "    print(\"   âœ“ Workflow built with checkpointer\")\n",
    "\n",
    "    print(\"\\n3. Configuring workflow...\")\n",
    "    thread_id = str(uuid.uuid4())\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    print(f\"   âœ“ Thread ID: {thread_id}\")\n",
    "\n",
    "    print(\"\\n4. Running workflow...\")\n",
    "    print(\"   This will take several minutes...\")\n",
    "\n",
    "    inputs = GenerateArticleInput(dir_path=SAMPLE_DIR)\n",
    "\n",
    "    async for event in workflow.astream(inputs, config=config, stream_mode=[\"custom\", \"values\"]):\n",
    "        # Print progress updates\n",
    "        event_type, event_data = event\n",
    "        if event_type == \"custom\":\n",
    "            pretty_print.wrapped(event_data, title=\"Event\")\n",
    "        elif event_type == \"values\":\n",
    "            pretty_print.wrapped(event_data, title=\"Output\")\n",
    "\n",
    "pretty_print.wrapped(\"WORKFLOW COMPLETE - Check SAMPLE_DIR for generated articles\", width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated article files:\n",
      "  - article.md: 29,529 bytes\n",
      "  - article_000.md: 26,203 bytes\n",
      "  - article_001.md: 26,144 bytes\n",
      "  - article_002.md: 29,529 bytes\n",
      "  - article_draft.md: 25,644 bytes\n",
      "  - article_edited.md: 27,598 bytes\n",
      "  - article_guideline.md: 23,131 bytes\n"
     ]
    }
   ],
   "source": [
    "# Check the generated articles\n",
    "print(\"\\nGenerated article files:\")\n",
    "article_files = sorted(SAMPLE_DIR.glob(\"article*.md\"))\n",
    "for article_file in article_files:\n",
    "    size = article_file.stat().st_size\n",
    "    print(f\"  - {article_file.name}: {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "Let's break down the workflow execution:\n",
    "\n",
    "**Infrastructure Setup:**\n",
    "1. Created an in-memory checkpointer for state persistence\n",
    "2. Built the workflow by injecting the checkpointer\n",
    "3. Generated a unique thread ID for this workflow run\n",
    "\n",
    "**Workflow Execution:**\n",
    "1. **Loaded Context** (Progress: 0-2%): All guidelines, research, profiles, examples\n",
    "2. **Generated Media** (Progress: 3-10%): Orchestrator identified and delegated media generation\n",
    "3. **Wrote Article** (Progress: 15-20%): ArticleWriter created first draft\n",
    "4. **Review-Edit Loop** (Progress: 25-99%): For each iteration:\n",
    "   - ArticleReviewer analyzed the article\n",
    "   - ArticleWriter edited based on reviews\n",
    "   - Saved intermediate version\n",
    "5. **Final Save** (Progress: 100%): Saved the final refined article\n",
    "\n",
    "**Key LangGraph Features Used:**\n",
    "- **Checkpointing**: State persistence between steps\n",
    "- **Streaming**: Real-time progress updates\n",
    "- **Retry policies**: Automatic recovery from failures\n",
    "- **Tasks**: Composable, retryable workflow steps\n",
    "- **Configuration**: Thread-based workflow isolation\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "Saved to the sample input directory:\n",
    "\n",
    "- `article_000.md`: Initial draft\n",
    "- `article_001.md`: After first review-edit iteration\n",
    "- `article_002.md`: After second review-edit iteration (if num_reviews=2)\n",
    "- `article.md`: Final refined article\n",
    "\n",
    "This demonstrates a production-ready implementation of the evaluator-optimizer pattern!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the saved files at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('inputs/tests/01_sample')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('inputs/tests/01_sample/article_draft.md'),\n",
       " PosixPath('inputs/tests/01_sample/article_edited.md'),\n",
       " PosixPath('inputs/tests/01_sample/article.md'),\n",
       " PosixPath('inputs/tests/01_sample/article_001.md'),\n",
       " PosixPath('inputs/tests/01_sample/article_000.md'),\n",
       " PosixPath('inputs/tests/01_sample/article_002.md'),\n",
       " PosixPath('inputs/tests/01_sample/article_guideline.md')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(SAMPLE_DIR.glob(\"article*.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Future Steps\n",
    "\n",
    "Congratulations! You've learned how to implement the evaluator-optimizer pattern and integrate it into a production-ready workflow.\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "**1. The Evaluator-Optimizer Pattern:**\n",
    "- Evaluator (ArticleReviewer) identifies issues against requirements\n",
    "- Optimizer (ArticleWriter) fixes issues based on feedback\n",
    "- Iterative refinement gradually improves quality\n",
    "- Transparent, debuggable, and improvable process\n",
    "\n",
    "**2. Centralized Configuration:**\n",
    "- Single YAML file controls everything\n",
    "- Per-node model and parameter configuration\n",
    "- Easy experimentation and optimization\n",
    "- Type-safe with Pydantic validation\n",
    "\n",
    "**3. LangGraph Integration:**\n",
    "- Workflow orchestration with Function API\n",
    "- Task-based architecture with retry policies\n",
    "- Checkpointing for state persistence\n",
    "- Streaming for progress reporting\n",
    "- Production-ready error handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for Extension\n",
    "\n",
    "Now that you understand the system, here are ways to extend it:\n",
    "\n",
    "**1. Different AI Frameworks:**\n",
    "\n",
    "Replace LangGraph Function API with LangGraph Graph API. Try PydanticAI or other frameworks. The clean architecture makes swapping easy.\n",
    "\n",
    "**2. Improve the Reviewer:**\n",
    "\n",
    "Play around with the reviewer, get a feeling of how it extract the reviews from the profiles and tweak either the profiles or the reviewer for better results.\n",
    "\n",
    "**3. Modify the configuration:**\n",
    "\n",
    "Change models, temperatures, num_reviews from the `configs/course.yaml` file and see how the output of the article changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next in the Course\n",
    "\n",
    "In **Lesson 24: Human-in-the-Loop**, we'll explore:\n",
    "\n",
    "- Adding two new workflows for iteratively editing the whole article or just a selected piece of text.\n",
    "- Properly add humans in the loop between the generated article and future edit iterations.\n",
    "- Expose the workflows as MCP tools.\n",
    "\n",
    "You'll see why having a fixed number of review iterations (rather than scoring until \"good enough\") makes perfect sense when humans are in the loop.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Brown Package**: Explore `../writing_workflow/` for complete source code\n",
    "- **Configuration Examples**: Check `configs/` for different configurations\n",
    "- **Test Data**: Use `inputs/tests/` for additional testing scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
