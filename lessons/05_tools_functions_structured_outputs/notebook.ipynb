{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools and Structured Outputs with Gemini\n",
    "\n",
    "This notebook explores two powerful features for building capable AI agents with Large Language Models (LLMs): **Tools (Function Calling)** and **Structured Outputs**. We will use the `google-genai` library to interact with Google's Gemini models.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "1.  **Understand and implement tool use (function calling)** to allow an LLM to interact with external systems.\n",
    "2.  **Enforce structured data formats (JSON)** from an LLM for reliable data extraction.\n",
    "3.  **Leverage Pydantic models** to define and manage complex data structures for both function arguments and structured outputs, improving code robustness and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the necessary Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -q google-generativeai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API Key\n",
    "\n",
    "To use the Gemini API, you need an API key. \n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
    "2.  Create a file named `.env` in the root of this project.\n",
    "3.  Add the following line to the `.env` file, replacing `your_api_key_here` with your actual key:\n",
    "    ```\n",
    "    GEMINI_API_KEY=\"your_api_key_here\"\n",
    "    ```\n",
    "The code below will load this key from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load environment variables from `/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "REPOSITORY_ROOT_DIR = Path().absolute().parent.parent\n",
    "DOTENV_FILE_PATH = REPOSITORY_ROOT_DIR / \".env\"\n",
    "print(f\"Trying to load environment variables from `{DOTENV_FILE_PATH}`\")\n",
    "\n",
    "if not DOTENV_FILE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Environment file `{DOTENV_FILE_PATH}` not found.\")\n",
    "\n",
    "load_dotenv(dotenv_path=DOTENV_FILE_PATH)\n",
    "\n",
    "assert \"GOOGLE_API_KEY\" in os.environ, \"`GOOGLE_API_KEY` is not set\"\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Gemini Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants\n",
    "\n",
    "We will use the `gemini-2.5-flash` model, which is fast, cost-effective, and supports advanced features like tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing structured outputs from scratch using JSON\n",
    "\n",
    "Sometimes, you don't need the LLM to take an action, but you need its output in a specific, machine-readable format. Forcing the output to be JSON is a common way to achieve this.\n",
    "\n",
    "We can instruct the model to do this by:\n",
    "1.  **Prompting**: Clearly describe the desired JSON structure in the prompt.\n",
    "2.  **Configuration**: Setting `response_mime_type` to `\"application/json\"` in the generation configuration, which forces the model's output to be a valid JSON object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Extracting Metadata from a Document\n",
    "\n",
    "Let's imagine we have a markdown document and we want to extract key information like a summary, tags, and keywords into a clean JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"summary\": \"The article explores recent advancements in AI agents, focusing on their ability to perform complex tasks. It highlights the ReAct framework, the importance of tool use, and the challenges of long-term planning in the context of Large Language Models.\",\n",
      "  \"tags\": [\"AI Agents\", \"Autonomous Agents\", \"Large Language Models\", \"LLMs\", \"ReAct Framework\", \"Tool Use\", \"Long-Term Planning\"],\n",
      "  \"keywords\": [\"AI\", \"agents\", \"LLMs\", \"ReAct\", \"planning\", \"autonomous\", \"software development\"]\n",
      "}\n",
      "\n",
      "--- Parsed JSON Object ---\n",
      "{'summary': 'The article explores recent advancements in AI agents, focusing on their ability to perform complex tasks. It highlights the ReAct framework, the importance of tool use, and the challenges of long-term planning in the context of Large Language Models.', 'tags': ['AI Agents', 'Autonomous Agents', 'Large Language Models', 'LLMs', 'ReAct Framework', 'Tool Use', 'Long-Term Planning'], 'keywords': ['AI', 'agents', 'LLMs', 'ReAct', 'planning', 'autonomous', 'software development']}\n"
     ]
    }
   ],
   "source": [
    "document = \"\"\"\n",
    "# Article: The Rise of AI Agents\n",
    "\n",
    "This article discusses the recent advancements in AI, focusing on autonomous agents. \n",
    "to perform complex, multi-step tasks. Key topics include the ReAct framework, \n",
    "We explore how Large Language Models (LLMs) are moving beyond simple text generation \n",
    "the importance of tool use, and the challenges of long-term planning. The future \n",
    "of software development may be significantly impacted by these new AI paradigms.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract metadata from it. \n",
    "The output must be a single, valid JSON object with the following structure:\n",
    "{{ \"summary\": \"A concise summary of the article.\", \"tags\": [\"list\", \"of\", \"relevant\", \"tags\"], \"keywords\": [\"list\", \"of\", \"key\", \"concepts\"] }}\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "# Configure the model to output JSON\n",
    "config = types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(response.text)\n",
    "\n",
    "# You can now reliably parse the JSON string\n",
    "metadata_obj = json.loads(response.text)\n",
    "\n",
    "print(\"\\n--- Parsed JSON Object ---\")\n",
    "print(metadata_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing structured outputs from scratch using Pydantic\n",
    "\n",
    "While prompting for JSON is effective, it can be fragile. A more robust and modern approach is to use **Pydantic**. Pydantic allows you to define data structures as Python classes. This gives you:\n",
    "\n",
    "- **A single source of truth**: The Pydantic model defines the structure.\n",
    "- **Automatic schema generation**: You can easily generate a JSON Schema from the model.\n",
    "- **Data validation**: You can validate the LLM's output against the model to ensure it conforms to the expected structure and types.\n",
    "\n",
    "Let's recreate the previous example using Pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    \"\"\"A class to hold structured metadata for a document.\"\"\"\n",
    "\n",
    "    summary: str = Field(description=\"A concise, 1-2 sentence summary of the document.\")\n",
    "    tags: List[str] = Field(\n",
    "        description=\"A list of 3-5 high-level tags relevant to the document.\"\n",
    "    )\n",
    "    keywords: List[str] = Field(\n",
    "        description=\"A list of specific keywords or concepts mentioned.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting Pydantic Schema into the Prompt\n",
    "\n",
    "We can generate a JSON Schema from our Pydantic model and inject it directly into the prompt. This is a more formal way of telling the LLM what structure to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"summary\": \"This article discusses recent advancements in AI, focusing on autonomous agents capable of performing complex, multi-step tasks. It explores how Large Language Models (LLMs) are evolving beyond simple text generation through frameworks like ReAct, emphasizing tool use and addressing challenges in long-term planning, potentially impacting future software development.\",\n",
      "  \"tags\": [\n",
      "    \"AI\",\n",
      "    \"Autonomous Agents\",\n",
      "    \"Large Language Models\",\n",
      "    \"Software Development\",\n",
      "    \"Advanced AI\"\n",
      "  ],\n",
      "  \"keywords\": [\n",
      "    \"AI Agents\",\n",
      "    \"ReAct framework\",\n",
      "    \"Large Language Models\",\n",
      "    \"LLMs\",\n",
      "    \"Tool use\",\n",
      "    \"Long-term planning\",\n",
      "    \"Multi-step tasks\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "--- Pydantic Validated Object ---\n",
      "summary='This article discusses recent advancements in AI, focusing on autonomous agents capable of performing complex, multi-step tasks. It explores how Large Language Models (LLMs) are evolving beyond simple text generation through frameworks like ReAct, emphasizing tool use and addressing challenges in long-term planning, potentially impacting future software development.' tags=['AI', 'Autonomous Agents', 'Large Language Models', 'Software Development', 'Advanced AI'] keywords=['AI Agents', 'ReAct framework', 'Large Language Models', 'LLMs', 'Tool use', 'Long-term planning', 'Multi-step tasks']\n",
      "\n",
      "Validation successful!\n"
     ]
    }
   ],
   "source": [
    "schema = DocumentMetadata.model_json_schema()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract metadata from it. \n",
    "The output must be a single, valid JSON object that conforms to the following JSON Schema:\n",
    "```json\n",
    "{json.dumps(schema, indent=2)}\n",
    "```\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "config = types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME, contents=prompt, config=config\n",
    ")\n",
    "\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(response.text)\n",
    "\n",
    "# Now, we can validate the output with Pydantic\n",
    "try:\n",
    "    document_metadata = DocumentMetadata.model_validate_json(response.text)\n",
    "    print(\"\\n--- Pydantic Validated Object ---\")\n",
    "    print(document_metadata)\n",
    "    print(\"\\nValidation successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nValidation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing structured ouputs using Gemini and Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentMetadata(summary='This article explores the advancements in AI, specifically autonomous agents performing complex tasks. It highlights the ReAct framework, LLMs, tool use, and challenges in long-term planning, suggesting a significant impact on software development.', tags=['AI Agents', 'Large Language Models', 'Autonomous Systems', 'Software Development'], keywords=['AI', 'autonomous agents', 'ReAct framework', 'LLMs', 'tool use', 'long-term planning'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = types.GenerateContentConfig(\n",
    "    response_mime_type=\"application/json\", response_schema=DocumentMetadata\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME, contents=prompt, config=config\n",
    ")\n",
    "response.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementing tool calls from scratch\n",
    "\n",
    "LLMs are trained on text and can't perform actions in the real world on their own. **Tools** (or **Function Calling**) are the mechanism we use to bridge this gap. We provide the LLM with a list of available tools, and it can decide which one to use and with what arguments to fulfill a user's request.\n",
    "\n",
    "The process is a loop:\n",
    "1.  **You**: Send the LLM a prompt and a list of available tools.\n",
    "2.  **LLM**: Responds with a `function_call` request, specifying the tool and arguments.\n",
    "3.  **You**: Execute the requested function in your code.\n",
    "4.  **You**: Send the function's output back to the LLM.\n",
    "5.  **LLM**: Uses the tool's output to generate a final, user-facing response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Mock Tools\n",
    "\n",
    "Let's create two simple, mocked functions. One simulates searching Google Drive, and the other simulates sending a Discord message. The function docstrings are crucial, as the LLM uses them to understand what each tool does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_drive(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for a file on Google Drive and returns its content or a summary.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to find the file, e.g., 'Q3 earnings report'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representing the search results, including file names and summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    # In a real scenario, this would interact with the Google Drive API.\n",
    "    # Here, we mock the response for demonstration.\n",
    "    if \"q3 earnings report\" in query.lower():\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"files\": [\n",
    "                    {\n",
    "                        \"name\": \"Q3_Earnings_Report_2024.pdf\",\n",
    "                        \"id\": \"file12345\",\n",
    "                        \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return json.dumps({\"files\": []})\n",
    "\n",
    "\n",
    "def send_discord_message(channel_id: str, message: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a message to a specific Discord channel.\n",
    "\n",
    "    Args:\n",
    "        channel_id (str): The ID of the channel to send the message to, e.g., '#finance'.\n",
    "        message (str): The content of the message to send.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string confirming the action, e.g., '{\"status\": \"success\"}'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mocking a successful API call\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"status\": \"success\",\n",
    "            \"channel\": channel_id,\n",
    "            \"message_preview\": f\"{message[:50]}...\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def summarize_financial_report(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes a financial report.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summary of the text.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"The Q3 earnings report shows an increase in company metrics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_google_drive_declaration = {\n",
    "    \"name\": \"search_google_drive\",\n",
    "    \"description\": \"Searches for a file on Google Drive and returns its content or a summary.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query to find the file, e.g., 'Q3 earnings report'.\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "send_discord_message_declaration = {\n",
    "    \"name\": \"send_discord_message\",\n",
    "    \"description\": \"Sends a message to a specific Discord channel.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"channel_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The ID of the channel to send the message to, e.g., '#finance'.\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The content of the message to send.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"channel_id\", \"message\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "summarize_financial_report_declaration = {\n",
    "    \"name\": \"summarize_financial_report\",\n",
    "    \"description\": \"Summarizes a financial report.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The text to summarize.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"text\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "TOOLS = {\n",
    "    \"search_google_drive\": {\n",
    "        \"handler\": search_google_drive,\n",
    "        \"declaration\": search_google_drive_declaration,\n",
    "    },\n",
    "    \"send_discord_message\": {\n",
    "        \"handler\": send_discord_message,\n",
    "        \"declaration\": send_discord_message_declaration,\n",
    "    },\n",
    "    \"summarize_financial_report\": {\n",
    "        \"handler\": summarize_financial_report,\n",
    "        \"declaration\": summarize_financial_report_declaration,\n",
    "    },\n",
    "}\n",
    "TOOLS_BY_NAME = {tool_name: tool[\"handler\"] for tool_name, tool in TOOLS.items()}\n",
    "TOOLS_SCHEMA = [tool[\"declaration\"] for tool in TOOLS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_google_drive': <function __main__.search_google_drive(query: str) -> str>,\n",
       " 'send_discord_message': <function __main__.send_discord_message(channel_id: str, message: str) -> str>,\n",
       " 'summarize_financial_report': <function __main__.summarize_financial_report(text: str) -> str>}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOLS_BY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_google_drive',\n",
       "  'description': 'Searches for a file on Google Drive and returns its content or a summary.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': \"The search query to find the file, e.g., 'Q3 earnings report'.\"}},\n",
       "   'required': ['query']}},\n",
       " {'name': 'send_discord_message',\n",
       "  'description': 'Sends a message to a specific Discord channel.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'channel_id': {'type': 'string',\n",
       "     'description': \"The ID of the channel to send the message to, e.g., '#finance'.\"},\n",
       "    'message': {'type': 'string',\n",
       "     'description': 'The content of the message to send.'}},\n",
       "   'required': ['channel_id', 'message']}},\n",
       " {'name': 'summarize_financial_report',\n",
       "  'description': 'Summarizes a financial report.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'text': {'type': 'string',\n",
       "     'description': 'The text to summarize.'}},\n",
       "   'required': ['text']}}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOLS_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_CALLING_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful AI assistant with access to tools that enable you to take actions and retrieve information to better assist users.\n",
    "\n",
    "## Tool Usage Guidelines\n",
    "\n",
    "**When to use tools:**\n",
    "- When you need information that is not in your training data\n",
    "- When you need to perform actions in external systems  \n",
    "- When you need real-time, dynamic, or user-specific data\n",
    "- When computational operations are required\n",
    "\n",
    "**Tool selection:**\n",
    "- Choose the most appropriate tool based on the user's specific request\n",
    "- If multiple tools could work, select the one that most directly addresses the need\n",
    "- Consider the order of operations for multi-step tasks\n",
    "\n",
    "**Parameter requirements:**\n",
    "- Provide all required parameters with accurate values\n",
    "- Use the parameter descriptions to understand expected formats and constraints\n",
    "- Ensure data types match the tool's requirements (strings, numbers, booleans, arrays)\n",
    "\n",
    "## Tool Call Format\n",
    "\n",
    "When you need to use a tool, output ONLY the tool call in this exact format:\n",
    "\n",
    "```tool_call\n",
    "{{\"name\": \"tool_name\", \"args\": {{\"param1\": \"value1\", \"param2\": \"value2\"}}}}\n",
    "```\n",
    "\n",
    "**Critical formatting rules:**\n",
    "- Use double quotes for all JSON strings\n",
    "- Ensure the JSON is valid and properly escaped\n",
    "- Include ALL required parameters\n",
    "- Use correct data types as specified in the tool definition\n",
    "- Do not include any additional text or explanation in the tool call\n",
    "\n",
    "## Response Behavior\n",
    "\n",
    "- If no tools are needed, respond directly to the user with helpful information\n",
    "- If tools are needed, make the tool call first, then provide context about what you're doing\n",
    "- After receiving tool results, provide a clear, user-friendly explanation of the outcome\n",
    "- If a tool call fails, explain the issue and suggest alternatives when possible\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "<tool_definitions>\n",
    "{tools}\n",
    "</tool_definitions>\n",
    "\n",
    "Remember: Your goal is to be maximally helpful to the user. Use tools when they add value, but don't use them unnecessarily. Always prioritize accuracy and user experience.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the prompt with a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```tool_call\n",
      "{\"name\": \"search_google_drive\", \"args\": {\"query\": \"latest quarterly report\"}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Can you help me find the latest quarterly report and share key insights with the team?\n",
    "\"\"\"\n",
    "\n",
    "messages = [TOOL_CALLING_SYSTEM_PROMPT.format(tools=str(TOOLS_SCHEMA)), USER_PROMPT]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=messages,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```tool_call\\n{\"name\": \"search_google_drive\", \"args\": {\"query\": \"Q3 earnings report\"}}\\n```'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
    "the #finance channel on Discord.\n",
    "\"\"\"\n",
    "\n",
    "messages = [TOOL_CALLING_SYSTEM_PROMPT.format(tools=str(TOOLS_SCHEMA)), USER_PROMPT]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=messages,\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step, is to parse the LLM response and call the tool using Python.\n",
    "\n",
    "First, we parse the LLM output to extract the JSON out of the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"search_google_drive\", \"args\": {\"query\": \"Q3 earnings report\"}}'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_tool_call(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the tool call from the response text.\n",
    "    \"\"\"\n",
    "    return response_text.split(\"```tool_call\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "\n",
    "tool_call_str = extract_tool_call(response.text)\n",
    "tool_call_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we parse the stringified JSON to a python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_google_drive', 'args': {'query': 'Q3 earnings report'}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = json.loads(tool_call_str)\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we retrieve the tool handler, which is a Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search_google_drive(query: str) -> str>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler = TOOLS_BY_NAME[tool_call[\"name\"]]\n",
    "tool_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we call the Python function using the arguments generated by the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler(**tool_call[\"args\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's tool calling in a nutshell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing tool calls with Gemini\n",
    "\n",
    "In production, most of the times, we don't implement tool calling from scratch, but leverage the interface of a specific API such as Gemini or OpenAI. Thus, let's see how we can adapt the example from above to Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_prompt(user_prompt) -> None:\n",
    "    print(\"=\" * 75)\n",
    "    print(f\"User Prompt: {user_prompt}\".strip())\n",
    "    print(\"=\" * 75)\n",
    "\n",
    "\n",
    "def print_function_call(response) -> None:\n",
    "    response_message_part = response.candidates[0].content.parts[0]\n",
    "\n",
    "    if hasattr(response_message_part, \"function_call\"):\n",
    "        function_call = response_message_part.function_call\n",
    "        tool_name = function_call.name\n",
    "        tool_args = function_call.args\n",
    "\n",
    "        print(\"=\" * 75)\n",
    "        print(f\"Function Call: {function_call}\")\n",
    "        print(f\"Function Name: {tool_name}\")\n",
    "        print(f\"Function Arguments: {tool_args}\")\n",
    "        print(\"=\" * 75)\n",
    "    else:\n",
    "        print(\"No function call found in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "User Prompt: \n",
      "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
      "the #finance channel on Discord.\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Function Call: id=None args={'query': 'Q3 earnings report'} name='search_google_drive'\n",
      "Function Name: search_google_drive\n",
      "Function Arguments: {'query': 'Q3 earnings report'}\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(**search_google_drive_declaration),\n",
    "            types.FunctionDeclaration(**send_discord_message_declaration),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=tools,\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "print_user_prompt(USER_PROMPT)\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=USER_PROMPT,\n",
    "    config=config,\n",
    ")\n",
    "print_function_call(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(id=None, args={'query': 'Q3 earnings report'}, name='search_google_drive')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message_part = response.candidates[0].content.parts[0]\n",
    "response_message_part.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search_google_drive(query: str) -> str>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler = TOOLS_BY_NAME[response_message_part.function_call.name]\n",
    "tool_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler(**response_message_part.function_call.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's aggregate everything into a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(function_call) -> str:\n",
    "    tool_name = function_call.name\n",
    "    tool_args = function_call.args\n",
    "\n",
    "    tool_handler = TOOLS_BY_NAME[tool_name]\n",
    "\n",
    "    return tool_handler(**tool_args)\n",
    "\n",
    "\n",
    "def print_tool_result(tool_result) -> None:\n",
    "    print(\"=\" * 75)\n",
    "    print(f\"Tool Result: {tool_result}\")\n",
    "    print(\"=\" * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Tool Result: {\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "print_tool_result(call_tool(response_message_part.function_call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Implementing tool calls with Gemini: Running tools in a loop\n",
    "\n",
    "Now, let's see what happens if we put tool calling in a loop. Let's create a scenario where we ask the agent to perform a multi-step task: find a report on Google Drive and then communicate its findings on Discord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "User Prompt: \n",
      "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
      "the #finance channel on Discord.\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Function Call: id=None args={'query': 'Q3 earnings report'} name='search_google_drive'\n",
      "Function Name: search_google_drive\n",
      "Function Arguments: {'query': 'Q3 earnings report'}\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Tool Result: {\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Function Call: id=None args={'channel_id': '#finance', 'message': 'The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.'} name='send_discord_message'\n",
      "Function Name: send_discord_message\n",
      "Function Arguments: {'channel_id': '#finance', 'message': 'The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.'}\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Tool Result: {\"status\": \"success\", \"channel\": \"#finance\", \"message_preview\": \"The Q3 earnings report shows a 20% increase in rev...\"}\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Function Call: id=None args={'query': 'Q3 earnings report'} name='search_google_drive'\n",
      "Function Name: search_google_drive\n",
      "Function Arguments: {'query': 'Q3 earnings report'}\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Tool Result: {\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "Function Call: id=None args={'message': 'The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.', 'channel_id': '#finance'} name='send_discord_message'\n",
      "Function Name: send_discord_message\n",
      "Function Arguments: {'message': 'The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.', 'channel_id': '#finance'}\n",
      "===========================================================================\n",
      "\n",
      "==== Final Agent Response ====\n",
      "parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'message': 'The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.', 'channel_id': '#finance'}, name='send_discord_message'), function_response=None, text=None)] role='model'\n"
     ]
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
    "the #finance channel on Discord.\n",
    "\"\"\"\n",
    "\n",
    "messages = [USER_PROMPT]\n",
    "\n",
    "print_user_prompt(USER_PROMPT)\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=messages,\n",
    "    config=config,\n",
    ")\n",
    "response_message_part = response.candidates[0].content.parts[0]\n",
    "print_function_call(response)\n",
    "\n",
    "messages.append(response.candidates[0].content)\n",
    "\n",
    "# Loop until a function call is still available or we reach the max number of iterations\n",
    "max_iterations = 3\n",
    "while hasattr(response_message_part, \"function_call\") and max_iterations > 0:\n",
    "    tool_result = call_tool(response_message_part.function_call)\n",
    "    print_tool_result(tool_result)\n",
    "\n",
    "    # Add the tool result to the messages creating the following structure:\n",
    "    # - user prompt\n",
    "    # - tool call\n",
    "    # - tool result\n",
    "    # - tool call\n",
    "    # - tool result\n",
    "    # ...\n",
    "    function_response_part = types.Part(\n",
    "        function_response=types.FunctionResponse(\n",
    "            name=response_message_part.function_call.name,\n",
    "            response=json.loads(tool_result),\n",
    "        )\n",
    "    )\n",
    "    messages.append(function_response_part)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_NAME,\n",
    "        contents=messages,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    response_message_part = response.candidates[0].content.parts[0]\n",
    "    messages.append(response.candidates[0].content)\n",
    "\n",
    "    print_function_call(response)\n",
    "\n",
    "    max_iterations -= 1\n",
    "\n",
    "# 4. Print the final, user-facing answer\n",
    "print(\"\\n==== Final Agent Response ====\")\n",
    "print(response.candidates[0].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the LLM loop got stuck between retrieving documents from Google Drive and sending them to Discord. To solve this problem, this is where the ReAct algorithm kicks in, which we will discuss in the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using a Pydantic Model as a Tool for Structured Outputs\n",
    "\n",
    "A more elegant and powerful pattern is to treat our Pydantic model *as a tool*. We can ask the model to \"call\" this Pydantic tool, and the arguments it generates will be our structured data.\n",
    "\n",
    "This combines the power of function calling with the robustness of Pydantic for structured data extraction. It's the recommended approach for complex data extraction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Function Call =====\n",
      "id=None args={'keywords': ['AI agents', 'ReAct framework', 'Large Language Models', 'LLMs', 'tool use', 'long-term planning', 'software development'], 'tags': ['Artificial Intelligence', 'Large Language Models', 'Autonomous Agents', 'Software Development', 'Future of Technology'], 'summary': 'This article discusses the recent advancements in AI, focusing on autonomous agents. It explores how Large Language Models (LLMs) are moving beyond simple text generation to perform complex, multi-step tasks.'} name='extract_metadata'\n",
      "\n",
      "==== Pydantic Validated Object ====\n",
      "summary='This article discusses the recent advancements in AI, focusing on autonomous agents. It explores how Large Language Models (LLMs) are moving beyond simple text generation to perform complex, multi-step tasks.' tags=['Artificial Intelligence', 'Large Language Models', 'Autonomous Agents', 'Software Development', 'Future of Technology'] keywords=['AI agents', 'ReAct framework', 'Large Language Models', 'LLMs', 'tool use', 'long-term planning', 'software development']\n"
     ]
    }
   ],
   "source": [
    "# The Pydantic class 'DocumentMetadata' is now our 'tool'\n",
    "extraction_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        types.FunctionDeclaration(\n",
    "            name=\"extract_metadata\",\n",
    "            description=\"Extracts structured metadata from a document.\",\n",
    "            parameters=DocumentMetadata.model_json_schema(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[extraction_tool],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME, contents=prompt, config=config\n",
    ")\n",
    "response_message_part = response.candidates[0].content.parts[0]\n",
    "\n",
    "if hasattr(response_message_part, \"function_call\"):\n",
    "    function_call = response_message_part.function_call\n",
    "    print(\"===== Function Call =====\")\n",
    "    print(function_call)\n",
    "\n",
    "    try:\n",
    "        document_metadata = DocumentMetadata(**function_call.args)\n",
    "        print(\"\\n==== Pydantic Validated Object ====\")\n",
    "        print(document_metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nValidation failed: {e}\")\n",
    "else:\n",
    "    print(\"The model did not call the extraction tool.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
