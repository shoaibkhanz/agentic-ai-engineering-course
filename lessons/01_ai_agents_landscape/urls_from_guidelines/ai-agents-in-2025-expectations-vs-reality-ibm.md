# AI agents in 2025: Expectations vs. reality

## AI agents in 2025: Expectations vs. reality

It’s impossible to take two steps across the tech media landscape without stumbling over an article hailing 2025 as the year of the [AI agent](https://www.ibm.com/think/topics/ai-agents). Agents, we’re told, will transform the way work is done, impacting every facet of our lives, personal and professional.

We’d barely surfaced from a landslide of NFT and crypto hype that characterized the early 2020s, and the metaverse bubble that followed, before media voices began singing the praises of [generative AI](https://www.ibm.com/think/topics/generative-ai) (gen AI) in the wake of releases such as OpenAI’s [GPT](https://www.ibm.com/think/topics/gpt) model family, Anthropic’s [Claude](https://www.ibm.com/think/topics/claude-ai) and Microsoft’s Copilot.

While the chorus hasn’t moved on entirely, the focus in 2025 has shifted from [large language models (LLMs)](https://www.ibm.com/think/topics/large-language-models) to advancements in the ostensibly autonomous [artificial intelligence (AI)](https://www.ibm.com/think/topics/artificial-intelligence) agents ushering in the future of work.

Despite a momentary surge in gen AI interest around [Deepseek](https://www.ibm.com/think/topics/deepseek)’s R1, which promised significant performance improvements over ChatGPT, the dominant innovation narrative in 2025 is the AI agent.

Media coverage highlights the promises of innovation, [automation](https://www.ibm.com/think/topics/automation) and efficiency agents will bring, but how much of the conversation is click-hungry hype?

The ad-supported media world thrives on clicks, and it’s reasonable to expect sensational, attention-grabbing headlines crafted to garner yours. But what can we realistically expect from [agentic AI](https://www.ibm.com/think/insights/agentic-ai) in 2025, and how will it affect our lives?

We spoke with several IBM experts to cut through the hype, with the goal of holding a more reasonable conversation about AI agents and what they’re going to do. Our team of informed insiders includes:

- [Maryam Ashoori, PhD](https://www.linkedin.com/in/mashoori): Director of Product Management, [IBM® watsonx.ai™](https://www.ibm.com/products/watsonx-ai)
- [Marina Danilevsky](https://www.linkedin.com/in/marina-danilevsky): Senior Research Scientist, Language Technologies
- [Vyoma Gajjar](https://www.linkedin.com/in/vyomagajjar): AI Technical Solutions Architect
- [Chris Hay](https://www.linkedin.com/in/chrishayuk): Distinguished Engineer

## What are AI agents?

An AI agent is a software program capable of acting autonomously to understand, plan and execute tasks. AI agents are powered by LLMs and can interface with tools, other models and other aspects of a system or network as needed to fulfill user goals.

We’re going beyond asking a chatbot to suggest a dinner recipe based on the available ingredients in the fridge. Agents are more than automated [customer experience](https://www.ibm.com/think/topics/customer-experience) emails that inform you it’ll be a few days until a real-world human can get to your inquiry.

[AI agents differ from traditional AI assistants](https://www.ibm.com/think/topics/ai-agents-vs-ai-assistants) that need a prompt each time they generate a response. In theory, a user gives an agent a high-level task, and the agent figures out how to complete it.

Current offerings are still in the early stages of approaching this idea. “What’s commonly referred to as ‘agents’ in the market is the addition of rudimentary planning and tool-calling (sometimes called function calling) capabilities to LLMs,” says Ashoori. “These enable the LLM to break down complex tasks into smaller steps that the LLM can perform.”

Hay is optimistic that more robust agents are on the way: “You wouldn’t need any further progression in models today to build [future AI agents](https://www.ibm.com/think/insights/ai-agents-evolve-rapidly),” he says.

With that out of the way, what’s the conversation about agents over the coming year, and how much of it can we take seriously?

## Narrative 1: 2025 is the year of the AI agent

“More and better agents” are on the way, predicts Time.[1](https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality#footnotes1) “Autonomous ‘agents’ and profitability are likely to dominate the artificial intelligence agenda,” reports Reuters. [2](https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality#footnotes2) “The age of agentic AI has arrived,” promises Forbes, in response to a claim from Nvidia’s Jensen Huang. [3](https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality#footnotes3)

Tech media is awash with assurances that our lives are on the verge of a total transformation. Autonomous agents are poised to streamline and alter our jobs, drive optimization and accompany us in our daily lives, handling our mundanities in real time and freeing us up for creative pursuits and other higher-level tasks.

### 2025 as the year of agentic exploration

“IBM and Morning Consult did a survey of 1,000 developers who are building AI applications for enterprise, and 99% of them said they are exploring or developing AI agents,” explains Ashoori. “So yes, the answer is that 2025 is going to be the year of the agent.” However, that declaration is not without nuance.

After establishing the current market conception of agents as LLMs with function calling, Ashoori draws a distinction between that idea and truly autonomous agents. “The true definition \[of an AI agent\] is an intelligent entity with reasoning and planning capabilities that can autonomously take action. Those reasoning and planning capabilities are up for discussion. It depends on how you define that.”

“I definitely see AI agents heading in this direction, but we’re not fully there yet,” says Gajjar. “Right now, we’re seeing early glimpses—AI agents can already analyze data, predict trends and automate workflows to some extent. But building AI agents that can autonomously handle complex decision-making will take more than just better algorithms. We’ll need big leaps in contextual reasoning and testing for edge cases,” she adds.

Danilevsky isn’t convinced that this is anything new. “I'm still struggling to truly believe that this is all that different from just orchestration,” she says. “You've renamed orchestration, but now it's called agents, because that's the cool word. But orchestration is something that we've been doing in programming forever.”

With regard to 2025 being the year of the agent, Danilevsky is skeptical. “It depends on what you say an agent is, what you think an agent is going to accomplish and what kind of value you think it will bring,” she says. “It's quite a statement to make when we haven't even yet figured out ROI (return on investment) on LLM technology more generally.”

And it’s not just the business side that has her hedging her bets. “There's the hype of imagining if this thing could think for you and make all these decisions and take actions on your computer. Realistically, that's terrifying.”

Danilevsky frames the disconnect as one of miscommunication. “\[Agents\] tend to be very ineffective because humans are very bad communicators. We still can't get chat agents to interpret what you want correctly all the time.”

Still, the forthcoming year holds a lot of promise as an era of experimentation. “I'm a big believer in \[2025 as the year of the agent\],” says Hay excitedly.

Every large tech company and hundreds of startups are now experimenting with agents. Salesforce, for example, has released their Agentforce platform, which enables users to create agents that are easily integrated within the Salesforce app ecosystem.

“The wave is coming and we're going to have a lot of agents. It's still a very nascent ecosystem, so I think a lot of people are going to build agents, and they're going to have a lot of fun.”

## Narrative 2: Agents can handle highly complex tasks on their own

This narrative assumes that today’s agents meet the theoretical definition outlined in the introduction to this piece. 2025’s agents will be fully autonomous AI programs that can scope out a project and complete it with all the necessary tools they need and with no help from human partners. But what’s missing from this narrative is nuance.

### Today’s models are more than enough

Hay believes that the groundwork has already been laid for such developments. “The big thing about agents is that they have the ability to plan,” he outlines. “They have the ability to reason, to use tools and perform tasks, and they need to do it at speed and scale.”

He cites 4 developments that, compared to the best models of 12 to 18 months ago, mean that the models of early 2025 can power the agents envisioned by the proponents of this narrative:

- Better, faster, smaller models
- Chain-of-thought (COT) training
- Increased context windows
- Function calling

“Now, most of these things are in play,” Hay continues. “You can have the AI call tools. It can plan. It can reason and come back with good answers. It can use inference-time compute. You’ll have better chains of thought and more memory to work with. It's going to run fast. It’s going to be cheap. That leads you to a structure where I think you can have agents. The models are improving and they're getting better, so that's only going to accelerate.”

### Realistic expectations are a must

Ashoori is careful to differentiate between what agents will be able to do later, and what they can do now. “There is the promise, and there is what the agent's capable of doing today,” she says. “I would say the answer depends on the use case. For simple use cases, the agents are capable of \[choosing the correct tool\], but for more sophisticated use cases, the technology has yet to mature.”

Danilevsky reframes the narrative as a contextual one. “If something is true one time, that doesn't mean it's true all the time. Are there a few things that agents can do? Sure. Does that mean you can agentize any flow that pops into your head? No.”

For Gajjar, the question is one of risk and governance. “We’re seeing AI agents evolve from content generators to autonomous problem-solvers. These systems must be rigorously stress-tested in sandbox environments to avoid cascading failures. Designing mechanisms for rollback actions and ensuring audit logs are integral to making these agents viable in high-stakes industries.”

But she is optimistic that we’ll meet these challenges. “I do think we’ll see progress this year in creating rollback mechanisms and audit trails. It’s not just about building smarter AI but also designing safety nets so we can trace and fix issues quickly when things go off track.”

And while Hay is hopeful about the potential for agentic development in 2025, he sees a problem in another area: “Most organizations aren't agent-ready. What's going to be interesting is exposing the [APIs](https://www.ibm.com/think/topics/api) that you have in your enterprises today. That's where the exciting work is going to be. And that's not about how good the models are going to be. That's going to be about how enterprise-ready you are.”

## Narrative 3: AI orchestrators will govern networks of AI agents

The “new normal” envisioned by this narrative sees teams of AI agents corralled under orchestrator uber-models that manage the overall project workflow.

Enterprises will use AI orchestration to coordinate multiple agents and other [machine learning](https://www.ibm.com/think/topics/machine-learning) (ML) models working in tandem and using specific expertise to complete tasks.

### Compliance is paramount to healthy AI adoption

Gajjar views this prediction not only as credible, but likely. “We’re at the very beginning of this shift, but it’s moving fast. AI orchestrators could easily become the backbone of enterprise AI systems this year—connecting multiple agents, optimizing [AI workflows](https://www.ibm.com/think/topics/ai-workflow) and handling multilingual and multimedia data,” she opines. However, she cautions against rushing in without appropriate safeguards in place.

“At the same time, scaling these systems will need strong compliance frameworks to keep things running smoothly without sacrificing accountability,” warns Gajjar. “2025 might be the year we go from experiments to large-scale adoption, and I can’t wait to see how companies balance speed with responsibility.”

It’s imperative that organizations dedicate themselves with equal fervor to data and AI governance and compliance as they do to adopting the latest innovations.

### Progress isn’t a straight line

“You are going to have an AI orchestrator, and they’re going to work with multiple agents,” outlines Hay. “A bigger model would be an orchestrator, and smaller models will be doing constrained tasks.”

However, as agents evolve and improve, Hay predicts a shift away from orchestrated workflows to single-agent systems. “As those individual agents get more capable, you're going to switch toward saying, ‘I've got this agent that can do everything end-to-end.’”

Hay foresees a back-and-forth evolution as models develop. “You're going to hit a limit on \[what single agents can do\], and then you're going to go back to multi-agent collaboration again. You're going to push and pull between multi-agent frameworks and a single godlike agent.” And while AI models will be the ones determining project workflows, Hay believes humans will always remain in the loop.

### Orchestration isn’t always the right solution

For Ashoori, the need for a meta-orchestrator isn’t quite a given and comes down to intended use cases. “It's an architecture decision,” she explains. “Each agent, by definition, should have the capability to figure out if they need to orchestrate with another agent, pull in a bunch of tools or if they need some complimentary data. You don't necessarily need a middle agent that sits on top and monitors everyone to tell them what to do.”

However, in some cases, you might. “You may need to figure out how to use a combination of specialized agents for your purpose,” supposes Ashoori. “In that case, you may decide to create your own agent that acts as the orchestrator.”

Danilevsky advises enterprises to first understand which workflows can and should be agentized for what degree of ROI, then develop an AI strategy from there. “Are there going to be some orchestration flows with some agents? Sure. But should everything in your organization be orchestrated with agentic flow? No, it won't work.”

## Narrative 4: Agents will augment human workers

A prevailing vision of agentic adoption over the next year is one which sees agents augmenting, but not necessarily replacing, human workers. They’ll serve as contributors to a streamlined workflow led by humans, say advocates.

However, fears of AI-related job loss are a constant in the ongoing conversation surrounding enterprise AI adoption. As agents become more capable, will business leaders encourage agent-human collaboration or seek to replace workers with AI tools?

### Agents should be a tool, not a replacement

Ashoori believes the best path forward lies in trusting employees to determine the optimal use of AI in their respective jobs. “We should empower employees to decide how they want to leverage agents, but not necessarily replacing them in every single situation,” she explains. Some job functions are ripe for offloading to an agent, while with others, human input can’t be replaced. “An agent might transcribe and summarize a meeting, but you're not going to send your agent to have this conversation with me.”

Danilevsky shares Ashoori’s view and notes that the adoption of agents in the workplace will not come without growing pains. “You're still going to have cases where as soon as something gets more complex, you're going to need a human.” While business leaders may be tempted to cut short-term costs by eliminating jobs, agent use “...is going to settle down much more into an augmented sort of role. You're supposed to constantly have a human, and the human is being helped, but the human makes the final decisions,” says Danilevsky, describing her human-in-the-loop (HITL) vision for AI.

Hay sees a pathway towards sustainable AI adoption at work. “If we do this right, AI is there to augment humans to do things better. If AI is done correctly, then it frees us up to do more interesting things.” But at the same time, he can imagine another version of the future where AI is prioritized too highly. “There is a real risk that when done badly and wrongly, that we end up with humans augmenting the AI as opposed to the other way around.”

Gajjar also cautions against leaning too heavily on AI. “I don’t see AI agents replacing jobs overnight, but they’ll definitely reshape how we work. Repetitive, low-value tasks are already being automated, which frees people up for more strategic and creative work. That said, companies need to be intentional about how they introduce AI. Governance frameworks—like those focused on fairness, transparency and accountability—are going to be key.”

### Open source AI leads to new opportunities

For Hay, one upside of open source AI models is how they open the door to a future AI agent marketplace and subsequent monetization for creators. “I think open source agents are the key,” says Hay. “Because of open source, anybody can build an agent, and it can do useful tasks. And you can create your own company.”

It’s also important to weigh potential growing pains and organizational restructuring against AI-driven benefits, especially in the Global South, believes Hay.

LLMs provide text-based output, which can reach users through SMS in areas without reliable internet connections. “The enablement that can occur in countries \[without strong internet access\] because AI can work in a low-bandwidth scenario and it's getting cheaper all the time—this is very exciting,” Hay says.

## Final thoughts: Governance and strategy are essential for successful AI agent implementation

Over the course of these conversations, 2 themes came up time and time again with all 4 of our experts. Aside from the 4 narratives we looked at, a sustainable route through the current AI explosion will require enterprises and business leaders to embrace 2 ideas:

1. AI governance underpins successful compliance and responsible use.
2. A robust AI strategy focused on economic value will lead businesses to sustainable AI adoption.

### The need for governance

“Companies need governance frameworks to monitor performance and ensure accountability as these agents integrate deeper into operations,” urges Gajjar. “This is where IBM’s Responsible AI approach really shines. It’s all about making sure AI works with people, not against them, and building systems that are trustworthy and auditable from day one.”

Ashoori paints a picture of a potential agentic AI mishap. “Using an agent today is basically grabbing an LLM and allowing it to take actions on your behalf. What if this action is connecting to a dataset and removing a bunch of sensitive records?”

“Technology doesn’t think. It can't be responsible,” states Danilevsky. In terms of risks such as accidental data leakage or deletion, “the scale of the risk is higher,” she says. “There's only so much that a human can do in so much time, whereas the technology can do things in a lot less time and in a way that we might not notice.”

And when that happens, one cannot simply point the finger at the AI and remove all blame from the people responsible for it. “A human being in that organization is going to be held responsible and accountable for those actions,” warns Hay.

“So the challenge here becomes transparency,” says Ashoori. “And traceability of actions for every single thing that the agents do. You need to know exactly what's happening and be able to track, trace it and control it.”

For Danilevsky, free experimentation is the path to sustainable development. “\[There is a lot of value\] in allowing people to actually play with the technology and build it and try to break it.” She also urges developers to be cautious when determining which models to use and what data they feed into those models. “\[Some providers will\] take all your data. So just be a little careful.”

### Why AI strategy matters

“The current AI boom is absolutely FOMO-driven, and it will calm down when the technology becomes more normalized,” predicts Danilevsky. “I think that people will start to understand better what kinds of things work and don't.” “The focus should also be on integrating AI agents into ecosystems where they can learn and adapt continuously, driving long-term efficiency gains,” adds Gajjar.

Danilevsky is quick to ground expectations and recenter the conversation on demonstrable business needs. “Enterprises need to be careful to not become the hammer in search of a nail,” she begins. “We had this when LLMs first came on the scene. People said, ‘Step one: we’re going to use LLMs. Step two: What should we use them for?’”

Hay encourages enterprises to get agent-ready ahead of time. “The value is going to be with those organizations that take their private data and organize that in such a way so that the agents are researching against your documents.” Every enterprise houses a wealth of valuable proprietary data, and transforming that data so that it can power agentic workflows supports positive ROI.

“With agents, enterprises have an option to leverage their proprietary data and existing enterprise workflows to differentiate and scale,” says Ashoori.  “Last year was the year of experimentation and exploration for enterprises. They need to scale that impact and maximize their ROI of generative AI. Agents are the ticket to making that happen.”

For more information on successful AI implementation in the enterprise, read Maryam Ashoori’s guide to [agentic AI cost analysis](https://www.linkedin.com/pulse/crunching-numbers-cost-analysis-ai-agents-enterprise-ashoori-phd-kp7ve). Also be sure to catch Vyoma Gajjar and Chris Hay expounding on their predictions for AI in 2025 on [IBM’s Mixture of Experts podcast](https://www.youtube.com/watch?v=hwNkFnR1U0I&list=PLOspHqNVtKADvnJYHm3HButDlWykOTzlP).

##### Footnotes

1 [5 Predictions for AI in 2025](https://time.com/7204665/ai-predictions-2025/), Tharin Pillay and Harry Booth, Time, 16 January 2025.

2 [Autonomous agents and profitability to dominate AI agenda in 2025, executives forecast](https://www.reuters.com/technology/artificial-intelligence/autonomous-agents-profitability-dominate-ai-agenda-2025-executives-forecast-2024-12-12/), Katie Paul, Reuters, 13 December 2024.

3 [2025: Agentic and Physical AI — A Multitrillion Dollar Economy Emerges](https://www.forbes.com/sites/timothypapandreou/2025/01/15/2025-agentic--physical-aia-multi-trillion-dollar-economy-emerges/), Timothy Papandreou, Forbes, 15 January 2025.