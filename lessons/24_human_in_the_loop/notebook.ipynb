{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 24: Human-in-the-Loop for Brown Writing Workflow\n",
    "\n",
    "In this lesson, we'll explore how to implement human-in-the-loop capabilities in the Brown writing workflow. We'll learn how to integrate human feedback into the article review and editing process, expose the workflows as MCP tools for seamless integration with AI assistants like Claude and Cursor, and create a collaborative writing experience where AI and human expertise combine.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "- Understand the importance of human feedback and human-in-the-loop in AI writing workflows\n",
    "- Learn how to implement the HumanFeedback entity and integrate it into the ArticleReviewer node\n",
    "- Explore two new editing workflows: edit article and edit selected text\n",
    "- Discover how to expose Brown as an MCP server with tools, prompts, and resources\n",
    "- See how to integrate Brown with MCP clients like Cursor for a coding-like writing experience\n",
    "\n",
    "> [!NOTE]\n",
    "> ðŸ’¡ Remember that you can also run `brown` as a standalone Python package by going to `lessons/writing_workflow/` and following the instructions from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we define some standard Magic Python commands to autoreload Python packages whenever they change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Python Environment\n",
    "\n",
    "To set up your Python virtual environment using `uv` and load it into the Notebook, follow the step-by-step instructions from the `Course Admin` lesson from the beginning of the course.\n",
    "\n",
    "**TL/DR:** Be sure the correct kernel pointing to your `uv` virtual environment is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API\n",
    "\n",
    "To run this lesson, you'll need several API keys configured:\n",
    "\n",
    "1. **Gemini API Key**, `GOOGLE_API_KEY` variable: Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from `/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import env\n",
    "\n",
    "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Key Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from utils import pretty_print\n",
    "\n",
    "nest_asyncio.apply()  # Allow nested async usage in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Required Files\n",
    "\n",
    "We need to download the configuration files and input data that Brown uses for article generation and editing.\n",
    "\n",
    "First, let's download the configs folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf configs\n",
    "!curl -L -o configs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/configs.zip\n",
    "!unzip configs.zip\n",
    "!rm -rf configs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the inputs folder containing profiles, examples, and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf inputs\n",
    "!curl -L -o inputs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/inputs.zip\n",
    "!unzip inputs.zip\n",
    "!rm -rf inputs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify what we downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_guideline.md   \u001b[1m\u001b[36minputs\u001b[m\u001b[m/                notebook_guideline.md\n",
      "\u001b[1m\u001b[36mconfigs\u001b[m\u001b[m/               notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define constants to reference these directories throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs directory exists: True\n",
      "Inputs directory exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIGS_DIR = Path(\"configs\")\n",
    "INPUTS_DIR = Path(\"inputs\")\n",
    "\n",
    "# Verify they exist\n",
    "print(f\"Configs directory exists: {CONFIGS_DIR.exists()}\")\n",
    "print(f\"Inputs directory exists: {INPUTS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples directory exists: True\n",
      "Examples directory exists: True\n",
      "Profiles directory exists: True\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_DIR = Path(\"inputs/tests/01_sample\")\n",
    "EXAMPLES_DIR = Path(\"inputs/examples/course_lessons\")\n",
    "PROFILES_DIR = Path(\"inputs/profiles\")\n",
    "\n",
    "print(f\"Samples directory exists: {SAMPLE_DIR.exists()}\")\n",
    "print(f\"Examples directory exists: {EXAMPLES_DIR.exists()}\")\n",
    "print(f\"Profiles directory exists: {PROFILES_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Importance of Human-in-the-Loop\n",
    "\n",
    "After generating an article using the writing workflow we explained in Lessons 22 and 23, you'll likely want to refine it further. Writing is highly subjective, and even the best AI-generated content benefits from human review and editing.\n",
    "\n",
    "The perfect balance between AI and human expertise is to use AI to generate and automate parts of your work, then have you, as the domain expert, review and refine it. Known as the AI generation - human validation loop. \n",
    "\n",
    "This is exactly what we've designed the Brown writing workflow to support.\n",
    "\n",
    "### The Human-in-the-Loop Design\n",
    "\n",
    "We designed Brown to easily introduce humans into the loop between generating the first version of an article and refining it through additional review and editing cycles with human feedback. This means:\n",
    "\n",
    "1. We can use a low number of review loops during initial article generation to reduce costs and latency\n",
    "2. After reviewing the generated article, we can dynamically run additional review and editing workflows with human feedback\n",
    "3. We can edit either the entire article or just selected sections based on your needs\n",
    "\n",
    "### Decoupling Workflows with MCP\n",
    "\n",
    "To enable this human-in-the-loop approach, we needed to decouple the article generation workflow from the editing workflows. We used MCP servers to achieve this separation, where:\n",
    "\n",
    "- The `generate_article` workflow is one independent MCP tool\n",
    "- The `edit_article` workflow is another independent MCP tool\n",
    "- The `edit_selected_text` workflow is a third independent MCP tool\n",
    "\n",
    "This architecture allows you to generate an article, review it, and then selectively apply additional editing workflows with your human feedback until you're satisfied with the results.\n",
    "\n",
    "Here's how the workflow looks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/images/l24_writing_workflow.png\" alt=\"Workflow\" height=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram shows how Brown as an MCP server exposes three main tools, with a human feedback loop that allows iterative refinement until you're satisfied with the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introducing Human Feedback into the Article Reviewer\n",
    "\n",
    "Let's see how we introduced human feedback into our Article Reviewer Node. We'll start by explaining the `HumanFeedback` entity, then show how it's integrated into the `ArticleReviewer` node, and finally demonstrate it with a working example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The HumanFeedback Entity\n",
    "\n",
    "The `HumanFeedback` entity is a simple but Pydantic model that encapsulates human feedback for the article review process.\n",
    "\n",
    "Source: `brown.entities.reviews`\n",
    "\n",
    "```python\n",
    "class HumanFeedback(BaseModel, ContextMixin):\n",
    "    content: str\n",
    "\n",
    "    def to_context(self) -> str:\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    {self.content}\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Human Feedback in ArticleReviewer\n",
    "\n",
    "Now let's see how the `ArticleReviewer` node integrates human feedback into the review process. We'll focus only on the relevant sections.\n",
    "\n",
    "Source: `brown.nodes.article_reviewer`\n",
    "\n",
    "1. **Initialization with Human Feedback**\n",
    "\n",
    "\n",
    "```python\n",
    "def __init__(\n",
    "    self,\n",
    "    to_review: Article | SelectedText,\n",
    "    article_guideline: ArticleGuideline,\n",
    "    model: Runnable,\n",
    "    article_profiles: ArticleProfiles,\n",
    "    human_feedback: HumanFeedback | None = None,\n",
    ") -> None:\n",
    "    self.to_review = to_review\n",
    "    self.article_guideline = article_guideline\n",
    "    self.article_profiles = article_profiles\n",
    "    self.human_feedback = human_feedback\n",
    "\n",
    "    super().__init__(model, toolkit=Toolkit(tools=[]))\n",
    "```\n",
    "\n",
    "The `ArticleReviewer` now accepts an optional `human_feedback` parameter. This allows the reviewer to work with or without human input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Human Feedback in the System Prompt**\n",
    "\n",
    "The system prompt includes a dedicated section for human feedback:\n",
    "\n",
    "\n",
    "```python\n",
    "system_prompt_template = \"\"\"\n",
    "You are Brown, an expert article writer, editor and reviewer specialized in reviewing technical, educative and informational articles.\n",
    "\n",
    "...\n",
    "\n",
    "## Human Feedback\n",
    "\n",
    "Along with the expected requirements, a human already reviewed the article and provided the following feedback:\n",
    "\n",
    "{human_feedback}\n",
    "\n",
    "If empty, completely ignore it, otherwise the feedback will ALWAYS be used in two ways:\n",
    "1. First you will use the <human_feedback> to guide your reviewing process against the requirements. This will help you understand \n",
    "on what rules to focus on as this directly highlights what the user wants to improve.\n",
    "2. Secondly you will extract one or more action points based on the <human_feedback>. Depending on how many ideas, topics or suggestions \n",
    "the <human_feedback> contains you will generate from 1 to N action points. Each <human_feedback> review will contain a single action point. \n",
    "3. As long the <human_feedback> is not empty, you will always return at least 1 action point, but you will return more action points \n",
    "if the feedback touches multiple ideas. \n",
    "\n",
    "Here is an example of a reviewed based on the human feedback:\n",
    "<example_of_human_feedback_action_point>\n",
    "Review(\n",
    "    profile=\"human_feedback\",\n",
    "    location=\"Article level\",\n",
    "    comment=\"Add all the points from the article guideline to the article.\"\n",
    ")\n",
    "</example_of_human_feedback_action_point>\n",
    "\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "This section instructs the LLM on how to use human feedback:\n",
    "- Use it to guide the review process and focus on specific rules\n",
    "- Extract action points from the feedback (1 to N depending on how many ideas are present)\n",
    "- Always return at least 1 action point if feedback is provided\n",
    "- Each action point becomes a review with `profile=\"human_feedback\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Injecting Human Feedback into the Prompt**\n",
    "\n",
    "When the reviewer runs, it injects the human feedback into the system prompt:\n",
    "\n",
    "```python\n",
    "async def ainvoke(self) -> ArticleReviews | SelectedTextReviews:\n",
    "    system_prompt = self.system_prompt_template.format(\n",
    "        human_feedback=self.human_feedback.to_context() if self.human_feedback else \"\",\n",
    "        article=self.article.to_context(),\n",
    "        article_guideline=self.article_guideline.to_context(),\n",
    "        character_template=self.article_profiles.character.to_context(),\n",
    "        article_template=self.article_profiles.article.to_context(),\n",
    "        structure_template=self.article_profiles.structure.to_context(),\n",
    "        mechanics_template=self.article_profiles.mechanics.to_context(),\n",
    "        terminology_template=self.article_profiles.terminology.to_context(),\n",
    "        tonality_template=self.article_profiles.tonality.to_context(),\n",
    "    )\n",
    "    ...\n",
    "```\n",
    "\n",
    "If `human_feedback` is provided, it's converted to XML context format and injected. Otherwise, an empty string is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Example: Using ArticleReviewer with Human Feedback\n",
    "\n",
    "Let's see a practical example of using the `ArticleReviewer` with human feedback. We'll load our sample article, article guideline, and profiles, then provide human feedback to guide the review process.\n",
    "\n",
    "First, let's import the necessary components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 20:24:17.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading environment file from `.env`\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.entities.reviews import HumanFeedback\n",
    "from brown.loaders import (\n",
    "    MarkdownArticleExampleLoader,\n",
    "    MarkdownArticleGuidelineLoader,\n",
    "    MarkdownArticleLoader,\n",
    "    MarkdownArticleProfilesLoader,\n",
    ")\n",
    "from brown.models import SupportedModels, get_model\n",
    "from brown.nodes.article_reviewer import ArticleReviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the sample inputs. We'll use the same article and guidelines from the test sample directory as we used in previous lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 1: Loading Context\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Guideline: 23,127 characters\n",
      "âœ“ Article: 20,638 characters\n",
      "âœ“ Profiles: 6 profiles loaded\n",
      "âœ“ Examples: 2 article examples\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\"STEP 1: Loading Context\", width=100)\n",
    "\n",
    "# Load guideline\n",
    "guideline_loader = MarkdownArticleGuidelineLoader(uri=Path(\"article_guideline.md\"))\n",
    "article_guideline = guideline_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load profiles\n",
    "profiles_input = {\n",
    "    \"article\": PROFILES_DIR / \"article_profile.md\",\n",
    "    \"character\": PROFILES_DIR / \"character_profiles\" / \"paul_iusztin.md\",\n",
    "    \"mechanics\": PROFILES_DIR / \"mechanics_profile.md\",\n",
    "    \"structure\": PROFILES_DIR / \"structure_profile.md\",\n",
    "    \"terminology\": PROFILES_DIR / \"terminology_profile.md\",\n",
    "    \"tonality\": PROFILES_DIR / \"tonality_profile.md\",\n",
    "}\n",
    "profiles_loader = MarkdownArticleProfilesLoader(uri=profiles_input)\n",
    "profiles = profiles_loader.load()\n",
    "\n",
    "# Load examples\n",
    "examples_loader = MarkdownArticleExampleLoader(uri=EXAMPLES_DIR)\n",
    "article_examples = examples_loader.load()\n",
    "\n",
    "article_loader = MarkdownArticleLoader(uri=\"article.md\")\n",
    "article = article_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "print(f\"âœ“ Guideline: {len(article_guideline.content):,} characters\")\n",
    "print(f\"âœ“ Article: {len(article.content):,} characters\")\n",
    "print(\"âœ“ Profiles: 6 profiles loaded\")\n",
    "print(f\"âœ“ Examples: {len(article_examples.examples)} article examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create human feedback and run the article reviewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running article review with human feedback...\n",
      "\n",
      "Generated 89 reviews\n"
     ]
    }
   ],
   "source": [
    "human_feedback = HumanFeedback(\n",
    "    content=\"\"\"Make the introduction more engaging, catchy and shorter. \n",
    "Also, expand on the definition of both workflows and agents from the first section\"\"\"\n",
    ")\n",
    "\n",
    "# Create the article reviewer\n",
    "model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_reviewer = ArticleReviewer(\n",
    "    to_review=article,\n",
    "    article_guideline=article_guideline,\n",
    "    model=model,\n",
    "    article_profiles=profiles,\n",
    "    human_feedback=human_feedback,\n",
    ")\n",
    "\n",
    "# Run the review\n",
    "print(\"Running article review with human feedback...\")\n",
    "reviews = await article_reviewer.ainvoke()\n",
    "print(f\"\\nGenerated {len(reviews.reviews)} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the reviews, especially focusing on the human feedback reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- Human Feedback Reviews --------------------------------------\u001b[0m\n",
      "  Found 2 reviews based on human feedback\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------- 1. Human Feedback Review -------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"profile\": \"human_feedback\",\n",
      "  \"location\": \"Article level\",\n",
      "  \"comment\": \"Make the introduction more engaging, catchy and shorter.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------- 2. Human Feedback Review -------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"profile\": \"human_feedback\",\n",
      "  \"location\": \"Understanding the Spectrum: From Workflows to Agents - Article level\",\n",
      "  \"comment\": \"Expand on the definition of both workflows and agents from the first section.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import pretty_print\n",
    "\n",
    "# Print human feedback reviews\n",
    "human_feedback_reviews = [r for r in reviews.reviews if r.profile == \"human_feedback\"]\n",
    "pretty_print.wrapped(\n",
    "    f\"Found {len(human_feedback_reviews)} reviews based on human feedback\", title=\"Human Feedback Reviews\"\n",
    ")\n",
    "\n",
    "for i, review in enumerate(human_feedback_reviews, 1):\n",
    "    pretty_print.wrapped(\n",
    "        {\"profile\": review.profile, \"location\": review.location, \"comment\": review.comment},\n",
    "        title=f\"{i}. Human Feedback Review\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see all the other reviews from the profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m--------------------------------------- All Reviews Summary ---------------------------------------\u001b[0m\n",
      "  Generated reviews from 5 different profile types: article_guideline, human_feedback, mechanics_profile, structure_profile, terminology_profile\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  ARTICLE_GUIDELINE: 8 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The introduction is longer than the specified 300 words. It currently has ~300 words without the tit...\n",
      "  2. [Introduction: The Critical Decision Every AI Engineer Faces - Fourth paragraph] The introduction does not include a quick walkthrough of what will be learned by the end of the less...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  HUMAN_FEEDBACK: 2 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Article level] Make the introduction more engaging, catchy and shorter....\n",
      "  2. [Understanding the Spectrum: From Workflows to Agents - Article level] Expand on the definition of both workflows and agents from the first section....\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  MECHANICS_PROFILE: 18 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The sentence 'Should you create a predictable, step-by-step workflow where you control every action,...\n",
      "  2. [Understanding the Spectrum: From Workflows to Agents - Second paragraph] The sentence 'Think of it like a factory assembly line, where each station performs a specific, repe...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STRUCTURE_PROFILE: 33 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The first paragraph of the introduction is too long, exceeding the maximum of 80 words. It has 102 w...\n",
      "  2. [Introduction: The Critical Decision Every AI Engineer Faces - Second paragraph] The second paragraph of the introduction is too long, exceeding the maximum of 80 words. It has 81 w...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  TERMINOLOGY_PROFILE: 28 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The phrase 'critical architectural decision' is on the AI slop banned list ('critical decision'). It...\n",
      "  2. [Introduction: The Critical Decision Every AI Engineer Faces - Third paragraph] The phrase 'critical decision with confidence' is on the AI slop banned list. It should be rephrased...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_types = set(r.profile for r in reviews.reviews)\n",
    "\n",
    "pretty_print.wrapped(\n",
    "    f\"Generated reviews from {len(profile_types)} different profile types: {', '.join(sorted(profile_types))}\",\n",
    "    title=\"All Reviews Summary\",\n",
    ")\n",
    "print()\n",
    "\n",
    "for profile_type in sorted(profile_types):\n",
    "    profile_reviews = [r for r in reviews.reviews if r.profile == profile_type]\n",
    "    pretty_print.wrapped(f\"{profile_type.upper()}: {len(profile_reviews)} reviews\")\n",
    "    for i, review in enumerate(profile_reviews[:2], 1):  # Show first 2 of each type\n",
    "        print(f\"  {i}. [{review.location}] {review.comment[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the reviewer generated reviews from multiple sources:\n",
    "- Human feedback reviews that directly address your specific requests\n",
    "- Profile-based reviews (article, structure, mechanics, terminology, tonality) that ensure adherence to the style guidelines\n",
    "\n",
    "The human feedback reviews always have `profile=\"human_feedback\"` and create action points based on your feedback. These reviews will be used by the article writer to edit the article according to your instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Edit Article Workflow\n",
    "\n",
    "Now that we understand how human feedback integrates with the article reviewer, let's explore the `edit_article` workflow. This workflow reviews and edits an existing article based on human feedback and the expected requirements.\n",
    "\n",
    "The edit article workflow contains only one loop of the same reviewing-editing logic we already use within the generate article workflow. \n",
    "\n",
    "Also, the edit article workflow follows the same clean architecture pattern we've used throughout Brown. It leverages the app layer to orchestrate nodes and entities, keeping the code modular and maintainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Building the Edit Article Workflow\n",
    "\n",
    "The workflow is built using LangGraph's functional API. Here's how it's structured:\n",
    "\n",
    "Source: `brown.workflows.edit_article`\n",
    "\n",
    "\n",
    "```python\n",
    "def build_edit_article_workflow(checkpointer: BaseCheckpointSaver):\n",
    "    \"\"\"Create an edit article workflow with checkpointer.\n",
    "\n",
    "    Args:\n",
    "        checkpointer: Checkpointer to use for workflow persistence.\n",
    "\n",
    "    Returns:\n",
    "        Configured workflow entrypoint\n",
    "    \"\"\"\n",
    "\n",
    "    return entrypoint(checkpointer=checkpointer)(_edit_article_workflow)\n",
    "```\n",
    "\n",
    "The `build_edit_article_workflow` function is a factory that creates the workflow with a checkpointer for persistence. It uses LangGraph's `@entrypoint` decorator to wrap the main workflow function.\n",
    "\n",
    "The workflow expects an `EditArticleInput` typed dictionary:\n",
    "\n",
    "```python\n",
    "class EditArticleInput(TypedDict):\n",
    "    dir_path: Path\n",
    "    human_feedback: str\n",
    "```\n",
    "\n",
    "This input specifies:\n",
    "- `dir_path`: The directory containing the article and all supporting files (guideline, profiles, research, etc.)\n",
    "- `human_feedback`: The human feedback string to guide the editing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Edit Article Workflow Logic\n",
    "\n",
    "The main workflow function orchestrates the entire editing process:\n",
    "\n",
    "```python\n",
    "async def _edit_article_workflow(inputs: EditArticleInput, config: RunnableConfig) -> str:\n",
    "    writer = get_stream_writer()\n",
    "\n",
    "    # Progress: Loading context\n",
    "    writer(WorkflowProgress(progress=0, message=\"Loading context\").model_dump(mode=\"json\"))\n",
    "    context = {}\n",
    "    loaders = build_loaders(app_config)\n",
    "    for context_name, loader in loaders.items():\n",
    "        loader = cast(Loader, loader)\n",
    "        context[context_name] = loader.load(working_uri=inputs[\"dir_path\"])\n",
    "\n",
    "    human_feedback = HumanFeedback(content=inputs[\"human_feedback\"])\n",
    "    writer(WorkflowProgress(progress=5, message=\"Loaded context\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Reviewing\n",
    "    writer(WorkflowProgress(progress=20, message=\"Reviewing article\").model_dump(mode=\"json\"))\n",
    "    reviews = await generate_reviews(context[\"article\"], human_feedback, context[\"article_guideline\"], context[\"profiles\"])\n",
    "    writer(WorkflowProgress(progress=40, message=\"Generated reviews\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Editing\n",
    "    writer(WorkflowProgress(progress=60, message=\"Editing article\").model_dump(mode=\"json\"))\n",
    "    article = await edit_based_on_reviews(\n",
    "        context[\"article_guideline\"], context[\"research\"], context[\"profiles\"], context[\"examples\"], reviews\n",
    "    )\n",
    "    writer(WorkflowProgress(progress=80, message=\"Edited article\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Complete\n",
    "    writer(WorkflowProgress(progress=100, message=\"Article editing completed\").model_dump(mode=\"json\"))\n",
    "\n",
    "    return f\"\"\"\n",
    "Here is the edited article:\n",
    "{article.to_context()}\n",
    "\n",
    "Here is what you have to do with the edited article:\n",
    "- print the edited article to the console for the user to see\n",
    "- give a quick summary of the changes you made\n",
    "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
    "- in case you haven't changed anything, just say that you haven't changed anything\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "The workflow follows these steps:\n",
    "1. **Load context**: Use the loader builders to load the article, guideline, profiles, research, and examples from the directory\n",
    "2. **Create human feedback**: Convert the feedback string into a `HumanFeedback` entity\n",
    "3. **Generate reviews**: Run the article reviewer with human feedback to generate reviews\n",
    "4. **Edit based on reviews**: Run the article writer with the reviews to produce an edited article\n",
    "5. **Return instructions**: Return the edited article along with instructions for the MCP client on what to do next\n",
    "\n",
    "Notice how steps 3 and 4 are identical to the ones from the writing workflow you learned in lesson 23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Generating Reviews\n",
    "\n",
    "The `generate_reviews` task creates reviews by running the `ArticleReviewer` node:\n",
    "\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_reviews(\n",
    "    article: Article,\n",
    "    human_feedback: HumanFeedback,\n",
    "    article_guideline: ArticleGuideline,\n",
    "    article_profiles: ArticleProfiles,\n",
    ") -> ArticleReviews:\n",
    "    model, _ = build_model(app_config, node=\"review_article\")\n",
    "    article_reviewer = ArticleReviewer(\n",
    "        to_review=article,\n",
    "        article_guideline=article_guideline,\n",
    "        article_profiles=article_profiles,\n",
    "        human_feedback=human_feedback,\n",
    "        model=model,\n",
    "    )\n",
    "    reviews = await article_reviewer.ainvoke()\n",
    "\n",
    "    return cast(ArticleReviews, reviews)\n",
    "```\n",
    "\n",
    "This task:\n",
    "- Builds the model from the app config for the \"review_article\" node\n",
    "- Creates an `ArticleReviewer` with the article, guideline, profiles, and human feedback\n",
    "- Uses LangGraph's `@task` decorator with a retry policy for resilience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Editing Based on Reviews\n",
    "\n",
    "The `edit_based_on_reviews` task creates an edited article using the `ArticleWriter` node:\n",
    "\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def edit_based_on_reviews(\n",
    "    article_guideline: ArticleGuideline,\n",
    "    research: Research,\n",
    "    article_profiles: ArticleProfiles,\n",
    "    article_examples: ArticleExamples,\n",
    "    reviews: ArticleReviews,\n",
    ") -> Article:\n",
    "    model, _ = build_model(app_config, node=\"edit_article\")\n",
    "    article_writer = ArticleWriter(\n",
    "        article_guideline=article_guideline,\n",
    "        research=research,\n",
    "        article_profiles=article_profiles,\n",
    "        media_items=MediaItems.build(),\n",
    "        article_examples=article_examples,\n",
    "        reviews=reviews,\n",
    "        model=model,\n",
    "    )\n",
    "    article = await article_writer.ainvoke()\n",
    "\n",
    "    return cast(Article, article)\n",
    "```\n",
    "\n",
    "This task:\n",
    "- Builds the model from the app config for the \"edit_article\" node\n",
    "- Creates an `ArticleWriter` with all necessary context and the reviews to address\n",
    "- Also uses the `@task` decorator with retry policy\n",
    "\n",
    "Notice how the `ArticleWriter` works in \"editing mode\" when provided with `reviews`. It uses the same writer node from article generation, but the reviews guide it to make specific changes rather than writing from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 The Power of Human Feedback\n",
    "\n",
    "The edit article workflow demonstrates a key advantage of our architecture:\n",
    "\n",
    "**We can use a low number of review loops during initial article generation, and further run them dynamically with a human in the loop when necessary, with more human guidance.**\n",
    "\n",
    "This means:\n",
    "- Initial generation is faster and cheaper with fewer automatic review iterations\n",
    "- We don't assume how many iterations we need to have an ideal output, but let you decide\n",
    "- The workflow runs additional review and editing cycles guided by your feedback\n",
    "- You can repeat this process until satisfied with the results\n",
    "\n",
    "This approach balances efficiency with quality, using AI to handle the heavy lifting while keeping you in control of the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Edit Selected Text Workflow\n",
    "\n",
    "While the edit article workflow handles entire article edits, you'll often want to refine just a specific section. The `edit_selected_text` workflow enables precise, focused edits on selected text portions.\n",
    "\n",
    "The workflow structure is almost identical to `edit_article`, thanks to our clean architecture. The main difference is that it operates on a `SelectedText` entity instead of the full `Article`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Building the Edit Selected Text Workflow\n",
    "\n",
    "The workflow builder follows the same pattern:\n",
    "\n",
    "Source: `brown.workflows.edit_selected_text`\n",
    "\n",
    "\n",
    "```python\n",
    "def build_edit_selected_text_workflow(checkpointer: BaseCheckpointSaver):\n",
    "    \"\"\"Create an edit selected text workflow with checkpointer.\n",
    "\n",
    "    Args:\n",
    "        checkpointer: Checkpointer to use for workflow persistence.\n",
    "\n",
    "    Returns:\n",
    "        Configured workflow entrypoint\n",
    "    \"\"\"\n",
    "\n",
    "    return entrypoint(checkpointer=checkpointer)(_edit_selected_text_workflow)\n",
    "```\n",
    "\n",
    "The workflow expects an `EditSelectedTextInput` typed dictionary:\n",
    "\n",
    "```python\n",
    "class EditSelectedTextInput(TypedDict):\n",
    "    dir_path: Path\n",
    "    human_feedback: str\n",
    "    selected_text: str\n",
    "    number_line_before_selected_text: int\n",
    "    number_line_after_selected_text: int\n",
    "```\n",
    "\n",
    "This input specifies:\n",
    "- `dir_path`: The directory containing the article and supporting files\n",
    "- `human_feedback`: Human feedback to guide the editing\n",
    "- `selected_text`: The specific text portion to edit\n",
    "- `number_line_before_selected_text`: The starting line number in the article\n",
    "- `number_line_after_selected_text`: The ending line number in the article\n",
    "\n",
    "The line numbers help the workflow locate the selected text within the larger article context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 The Edit Selected Text Workflow Logic\n",
    "\n",
    "The main workflow function is structurally similar to `edit_article`:\n",
    "\n",
    "```python\n",
    "async def _edit_selected_text_workflow(inputs: EditSelectedTextInput, config: RunnableConfig) -> str:\n",
    "    writer = get_stream_writer()\n",
    "\n",
    "    # Progress: Loading context\n",
    "    writer(WorkflowProgress(progress=0, message=\"Loading context\").model_dump(mode=\"json\"))\n",
    "    context = {}\n",
    "    loaders = build_loaders(app_config)\n",
    "    for context_name, loader in loaders.items():\n",
    "        loader = cast(Loader, loader)\n",
    "        context[context_name] = loader.load(working_uri=inputs[\"dir_path\"])\n",
    "\n",
    "    selected_text = SelectedText(\n",
    "        article=context[\"article\"],\n",
    "        content=inputs[\"selected_text\"],\n",
    "        first_line_number=inputs[\"number_line_before_selected_text\"],\n",
    "        last_line_number=inputs[\"number_line_after_selected_text\"],\n",
    "    )\n",
    "    human_feedback = HumanFeedback(content=inputs[\"human_feedback\"])\n",
    "    writer(WorkflowProgress(progress=5, message=\"Loaded context\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Reviewing\n",
    "    writer(WorkflowProgress(progress=20, message=\"Reviewing selected text\").model_dump(mode=\"json\"))\n",
    "    reviews = await generate_reviews(selected_text, human_feedback, context[\"article_guideline\"], context[\"profiles\"])\n",
    "    writer(WorkflowProgress(progress=40, message=\"Generated reviews\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Editing\n",
    "    writer(WorkflowProgress(progress=60, message=\"Editing selected text\").model_dump(mode=\"json\"))\n",
    "    selected_text = await edit_based_on_reviews(\n",
    "        context[\"article_guideline\"], context[\"research\"], context[\"profiles\"], context[\"examples\"], reviews\n",
    "    )\n",
    "    writer(WorkflowProgress(progress=80, message=\"Edited selected text\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Complete\n",
    "    writer(WorkflowProgress(progress=100, message=\"Selected text editing completed\").model_dump(mode=\"json\"))\n",
    "\n",
    "    return f\"\"\"\n",
    "Here is the edited selected text:\n",
    "{selected_text.to_context()}\n",
    "\n",
    "Here is what you have to do with edited selected text:\n",
    "- print the edited selected text to the console for the user to see\n",
    "- give a quick summary of the changes you made\n",
    "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
    "- in case you haven't changed anything, just say that you haven't changed anything\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "The workflow follows these steps:\n",
    "1. **Load context**: Load the full article and supporting files\n",
    "2. **Create selected text entity**: Build a `SelectedText` entity that contains the selected portion, the full article for context, and line numbers\n",
    "3. **Create human feedback**: Convert the feedback string to a `HumanFeedback` entity\n",
    "4. **Generate reviews**: Review the selected text with human feedback\n",
    "5. **Edit based on reviews**: Edit the selected text based on the reviews\n",
    "6. **Return instructions**: Return the edited selected text with instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Generating Reviews for Selected Text\n",
    "\n",
    "The `generate_reviews` task for selected text is nearly identical to the article version:\n",
    "\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_reviews(\n",
    "    selected_text: SelectedText,\n",
    "    human_feedback: HumanFeedback,\n",
    "    article_guideline: ArticleGuideline,\n",
    "    article_profiles: ArticleProfiles,\n",
    ") -> SelectedTextReviews:\n",
    "    model, _ = build_model(app_config, node=\"review_selected_text\")\n",
    "    selected_text_reviewer = ArticleReviewer(\n",
    "        to_review=selected_text,\n",
    "        human_feedback=human_feedback,\n",
    "        article_guideline=article_guideline,\n",
    "        article_profiles=article_profiles,\n",
    "        model=model,\n",
    "    )\n",
    "    reviews = await selected_text_reviewer.ainvoke()\n",
    "\n",
    "    return cast(SelectedTextReviews, reviews)\n",
    "```\n",
    "\n",
    "The key difference is:\n",
    "- It takes a `SelectedText` instead of `Article`\n",
    "- It returns `SelectedTextReviews` instead of `ArticleReviews`\n",
    "- It uses the \"review_selected_text\" node config\n",
    "\n",
    "The `ArticleReviewer` node is smart enough to handle both cases. When given a `SelectedText`, it focuses reviews on that portion while using the full article as context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Editing Selected Text Based on Reviews\n",
    "\n",
    "The `edit_based_on_reviews` task for selected text also follows the same pattern:\n",
    "\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def edit_based_on_reviews(\n",
    "    article_guideline: ArticleGuideline,\n",
    "    research: Research,\n",
    "    article_profiles: ArticleProfiles,\n",
    "    article_examples: ArticleExamples,\n",
    "    reviews: SelectedTextReviews,\n",
    ") -> SelectedText:\n",
    "    model, _ = build_model(app_config, node=\"edit_selected_text\")\n",
    "    article_writer = ArticleWriter(\n",
    "        article_guideline=article_guideline,\n",
    "        research=research,\n",
    "        article_profiles=article_profiles,\n",
    "        media_items=MediaItems.build(),\n",
    "        article_examples=article_examples,\n",
    "        reviews=reviews,\n",
    "        model=model,\n",
    "    )\n",
    "    edited_selected_text = cast(SelectedText, await article_writer.ainvoke())\n",
    "\n",
    "    return edited_selected_text\n",
    "```\n",
    "\n",
    "This task:\n",
    "- Takes `SelectedTextReviews` instead of `ArticleReviews`\n",
    "- Returns `SelectedText` instead of `Article`\n",
    "- Uses the \"edit_selected_text\" node config\n",
    "\n",
    "Again, the `ArticleWriter` node handles both article and selected text editing seamlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Why Edit Selected Text?\n",
    "\n",
    "The edit selected text workflow is crucial because:\n",
    "\n",
    "**Most often we don't want to edit the whole article, but just a small section, or apply the human feedback just to a small section.**\n",
    "\n",
    "This workflow enables:\n",
    "- Faster and cheaper edits by focusing on specific sections\n",
    "- More precise changes without affecting other parts of the article\n",
    "- Iterative refinement of individual paragraphs or sections\n",
    "- Better control over the editing process\n",
    "\n",
    "Combined with the edit article workflow, you have complete flexibility to refine content at any granularity you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exposing Brown as an MCP Server\n",
    "\n",
    "Now we'll see how Brown exposes all its workflows as an MCP server. This allows external applications like Claude Desktop and Cursor to use Brown's capabilities through the Model Context Protocol.\n",
    "\n",
    "All the MCP code lives in the `brown.mcp` module, keeping the serving layer completely separate from the domain, app, and infrastructure layers. This separation allows us to potentially serve Brown through different interfaces (CLI, FastAPI, etc.) without changing the core logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 MCP Server and Tools\n",
    "\n",
    "The MCP server is built using FastMCP (the same as the Nova Deep Research Agent, the first capstone project) and exposes three main tools:\n",
    "\n",
    "Source: `brown.mcp.server`\n",
    "\n",
    "```python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Brown MCP Server\")\n",
    "\n",
    "@mcp.tool\n",
    "async def generate_article(dir_path: Path, ctx: Context) -> str:\n",
    "    \"\"\"Generate an article from scratch using Brown's article generation workflow.\n",
    "    \n",
    "    Args:\n",
    "        dir_path: Path to the directory containing article resources\n",
    "        ctx: MCP context for streaming progress updates\n",
    "        \n",
    "    Returns:\n",
    "        A string containing a success confirmation message\n",
    "    \"\"\"\n",
    "    async with build_short_term_memory(app_config) as checkpointer:\n",
    "        generate_article_workflow = build_generate_article_workflow(checkpointer=checkpointer)\n",
    "        \n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        async for chunk in generate_article_workflow.astream({\"dir_path\": dir_path}, config=config, stream_mode=[\"custom\", \"values\"]):\n",
    "            _, chunk_data = chunk\n",
    "            await parse_message(chunk_data, ctx)\n",
    "    \n",
    "    return \"Article generation completed successfully!\"\n",
    "\n",
    "@mcp.tool\n",
    "async def edit_article(\n",
    "    article_path: str,\n",
    "    human_feedback: str,\n",
    "    ctx: Context,\n",
    ") -> str:\n",
    "    \"\"\"Edit an entire article based on human feedback.\n",
    "    \n",
    "    Args:\n",
    "        article_path: Path to the article that has to be edited\n",
    "        human_feedback: User's feedback or instructions for editing\n",
    "        ctx: MCP context for streaming progress updates\n",
    "        \n",
    "    Returns:\n",
    "        The fully edited article content plus instructions\n",
    "    \"\"\"\n",
    "    async with build_short_term_memory(app_config) as checkpointer:\n",
    "        edit_article_workflow = build_edit_article_workflow(checkpointer=checkpointer)\n",
    "        \n",
    "        dir_path = Path(article_path).parent\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        final_result = None\n",
    "        async for chunk in edit_article_workflow.astream(\n",
    "            {\"dir_path\": Path(dir_path), \"human_feedback\": human_feedback},\n",
    "            config=config,\n",
    "            stream_mode=[\"custom\", \"values\"],\n",
    "        ):\n",
    "            chunk_type, chunk_data = chunk\n",
    "            await parse_message(chunk_data, ctx)\n",
    "            \n",
    "            if chunk_type == \"values\":\n",
    "                final_result = chunk_data\n",
    "        \n",
    "    return final_result or \"Article editing completed successfully!\"\n",
    "\n",
    "@mcp.tool\n",
    "async def edit_selected_text(\n",
    "    article_path: str,\n",
    "    human_feedback: str,\n",
    "    selected_text: str,\n",
    "    first_line_number: int,\n",
    "    last_line_number: int,\n",
    "    ctx: Context,\n",
    ") -> str:\n",
    "    \"\"\"Edit a selected section of an article based on human feedback.\n",
    "    \n",
    "    Args:\n",
    "        article_path: Path to the article containing the selected text\n",
    "        human_feedback: User's feedback or instructions\n",
    "        selected_text: The specific text selected from the article\n",
    "        first_line_number: Line number where the selected text starts\n",
    "        last_line_number: Line number where the selected text ends\n",
    "        ctx: MCP context for streaming progress updates\n",
    "        \n",
    "    Returns:\n",
    "        The fully edited selected text plus instructions\n",
    "    \"\"\"\n",
    "    async with build_short_term_memory(app_config) as checkpointer:\n",
    "        edit_selected_text_workflow = build_edit_selected_text_workflow(checkpointer=checkpointer)\n",
    "        \n",
    "        dir_path = Path(article_path).parent\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        final_result = None\n",
    "        async for chunk in edit_selected_text_workflow.astream(\n",
    "            {\n",
    "                \"dir_path\": Path(dir_path),\n",
    "                \"human_feedback\": human_feedback,\n",
    "                \"selected_text\": selected_text,\n",
    "                \"number_line_before_selected_text\": first_line_number,\n",
    "                \"number_line_after_selected_text\": last_line_number,\n",
    "            },\n",
    "            config=config,\n",
    "            stream_mode=[\"custom\", \"values\"],\n",
    "        ):\n",
    "            chunk_type, chunk_data = chunk\n",
    "            await parse_message(chunk_data, ctx)\n",
    "            \n",
    "            if chunk_type == \"values\":\n",
    "                final_result = chunk_data\n",
    "        \n",
    "    return final_result or \"Selected text editing completed successfully!\"\n",
    "```\n",
    "\n",
    "**Each tool:**\n",
    "\n",
    "- Builds the appropriate workflow with an in memory checkpointer, similar to how we ran the workflows so far in these lessons\n",
    "- Creates a unique thread ID for each workflow execution\n",
    "- Most importantly, has detailed pydocs and signatures that will be used by the MCP client to understand what tool to call and how to call it. \n",
    "\n",
    "- Streams progress updates to the MCP client via the `ctx` (context) parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running one of these tools, let's take a look at how we report the progress from each tool through `parse_message` function:\n",
    "\n",
    "```python\n",
    "async def parse_message(chunk_data: dict, ctx: Context, prefix: str = \"\") -> None:\n",
    "    \"\"\"Parse and report workflow streaming messages to the MCP client.\n",
    "\n",
    "    Args:\n",
    "        chunk_data: The streaming data from the workflow, can be a string message\n",
    "                   or a dictionary containing progress information.\n",
    "        ctx: MCP context for sending messages and progress updates to the client.\n",
    "        prefix: Optional prefix to add to all messages for context identification.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If chunk_data is not a supported type (str or dict).\n",
    "    \"\"\"\n",
    "\n",
    "    if prefix:\n",
    "        prefix = f\"{prefix}: \"\n",
    "\n",
    "    if isinstance(chunk_data, str):\n",
    "        await ctx.info(f\"{prefix}{chunk_data}\")\n",
    "    elif isinstance(chunk_data, dict):\n",
    "        message = WorkflowProgress(**chunk_data)\n",
    "        await ctx.info(f\"{prefix}{message.progress}%: {message.message}\")\n",
    "        await ctx.report_progress(progress=message.progress, total=100, message=f\"{prefix}{message.message}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported chunk data type: {type(chunk_data)}\")\n",
    "```\n",
    "\n",
    "Now, let's see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Running the Edit Selected Text Tool\n",
    "\n",
    "Let's see a practical example of using the `edit_selected_text` tool. We'll use the in-memory MCP client to call the tool directly.\n",
    "\n",
    "First, let's import the MCP server and create an in-memory client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-25 20:24:52.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.mcp.server\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mInitializing Brown MCP Server...\u001b[0m\n",
      "\u001b[32m2025-11-25 20:24:52.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.mcp.server\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mBrown MCP Server initialized successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.mcp.server import mcp\n",
    "from fastmcp import Client\n",
    "\n",
    "# Create an in-memory client\n",
    "mcp_client = Client(mcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the `edit_selected_text` tool on a specific set of paragraphs. We'll edit the \"Understanding the Spectrum: From Workflows to Agents\" section of our sample article.\n",
    "\n",
    "First, let's read the article to get the text we want to edit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- Selected text to edit --------------------------------------\u001b[0m\n",
      "  ## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "Before we can choose between workflows and agents, we need a clear understanding of what they are. Rather than focusing on the technical specifics, let's look at their core properties and how they function in practice.\n",
      "\n",
      "An LLM workflow is a sequence of tasks that involves LLM calls or other operations, such as reading from a database or writing to a file system. It is largely predefined and orchestrated by developer-written code. The steps are defined in advance, resulting in deterministic or rule-based paths with predictable execution and explicit control flow. Think of it like a factory assembly line, where each station performs a specific, repeatable task in a set order.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Input\"] --> B[\"tool_calling_llm\"]\n",
      "    B --> C[\"Tools\"]\n",
      "    C --> D[\"End\"]\n",
      "```\n",
      "Image 1: A simple LLM workflow illustrating a sequence of predefined tasks, where an input leads to a tool-calling LLM, which interacts with tools before the workflow ends.\n",
      "\n",
      "On the other end of the spectrum, we have AI agents. These are systems where an LLM plays a central role in dynamically deciding the sequence of steps, reasoning, and actions to achieve a goal. The steps are not defined in advance but are planned based on the task and the current state of the environment. This makes them adaptive and capable of handling novelty. You can think of an agent as a skilled human expert tackling an unfamiliar problem, adapting their approach with each new piece of information.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent: Initial Request/State\"]\n",
      "    B --> C{\"Assistant: Analyze & Plan\"}\n",
      "    C --> D{\"Decision: Tool Required?\"}\n",
      "    D -->|\"Yes\"| E[\"Use Tool\"]\n",
      "    E --> F[\"Agent: Process Tool Output\"]\n",
      "    F --> C\n",
      "    D -->|\"No\"| G{\"Decision: Task Completed?\"}\n",
      "    G -->|\"No\"| C\n",
      "    G -->|\"Yes\"| H[\"End\"]\n",
      "```\n",
      "Image 2: A simple agentic system illustrating dynamic decision-making and tool usage with an assistant orchestrating the loop.\n",
      "\n",
      "Both workflows and agents require an orchestration layer, but its role differs significantly. In a workflow, the orchestrator executes a predefined plan, like a conductor following a musical score. In an agentic system, the orchestrator facilitates the LLM's dynamic planning and execution, acting more like a jazz ensemble leader who guides improvisation. We will explore advanced workflow patterns like chaining, routing, and the orchestrator-worker model in future lessons, as well as the core components of agents like tools, memory, and the ReAct framework.\n",
      "\n",
      "## Choosing Your Path\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "article = MarkdownArticleLoader(uri=\"article.md\").load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "start_line = 11\n",
    "end_line = 44\n",
    "selected_text = \"\\n\".join(article.content.split(\"\\n\")[start_line:end_line])\n",
    "pretty_print.wrapped(selected_text, title=\"Selected text to edit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the tool with human feedback:\n",
    "\n",
    "**Note how we get all these beautiful progress messages while we call the edit selected text workflow!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/25/25 20:24:52] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: Editing selected text from file                 <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         inputs/tests/01_sample/article.md                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/25/25 20:24:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: Editing selected text from file                 \u001b]8;id=936674;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=168454;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         inputs/tests/01_sample/article.md                                       \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: Using directory `inputs/tests/01_sample` as     <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         context                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: Using directory `inputs/tests/01_sample` as     \u001b]8;id=808858;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=774802;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         context                                                                 \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Editing selected text from file </span>     <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">inputs/tests/01_sample/article.md'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'Editing selected text from file \u001b[0m     \u001b]8;id=511224;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=865737;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32minputs/tests/01_sample/article.md'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                       \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Using directory </span>                     <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">`inputs/tests/01_sample` as context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'Using directory \u001b[0m                     \u001b]8;id=107570;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=62273;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m`inputs/tests/01_sample` as context'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"Default Project\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=019abc42-e730-7add-9e7c-6ef64d6fb18f&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>%: Loading context                             <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m0\u001b[0m%: Loading context                             \u001b]8;id=40053;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=897098;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0%: Loading context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span> <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'0%: Loading context'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m \u001b]8;id=361090;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=928863;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>%: Loaded context                              <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m5\u001b[0m%: Loaded context                              \u001b]8;id=983913;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=289115;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5%: Loaded context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>  <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'5%: Loaded context'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m  \u001b]8;id=319814;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=627016;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>%: Reviewing selected text                    <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m20\u001b[0m%: Reviewing selected text                    \u001b]8;id=292240;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=875288;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20%: Reviewing selected text'</span>,       <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'20%: Reviewing selected text'\u001b[0m,       \u001b]8;id=55171;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149606;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                           \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/25/25 20:25:19] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>%: Generated reviews                          <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/25/25 20:25:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m40\u001b[0m%: Generated reviews                          \u001b]8;id=652720;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130799;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'40%: Generated reviews'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>:    <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'40%: Generated reviews'\u001b[0m, \u001b[32m'extra'\u001b[0m:    \u001b]8;id=328958;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=924265;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                                    \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>%: Editing selected text                      <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m60\u001b[0m%: Editing selected text                      \u001b]8;id=736495;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=73490;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/25/25 20:25:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'60%: Editing selected text'</span>,         <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/25/25 20:25:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'60%: Editing selected text'\u001b[0m,         \u001b]8;id=352068;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=184308;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                           \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/25/25 20:25:39] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>%: Edited selected text                       <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/25/25 20:25:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m80\u001b[0m%: Edited selected text                       \u001b]8;id=60711;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=206370;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'80%: Edited selected text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'80%: Edited selected text'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b]8;id=535185;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=434151;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                                    \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>%: Selected text editing completed           <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m100\u001b[0m%: Selected text editing completed           \u001b]8;id=745933;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=206155;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'100%: Selected text editing </span>         <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">completed'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'100%: Selected text editing \u001b[0m         \u001b]8;id=924652;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=996493;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mcompleted'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client:                                                 <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Here is the edited selected text:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">selected_text</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    </span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;content&gt;```</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">## Understanding the Spectrum: From Workflows to Agents</span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Before you can choose between workflows and agents, you need a clear </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">understanding of what they are. Rather than focusing on the technical </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">specifics, let's look at their core properties and how they function in</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">practice.</span>                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">An LLM workflow is a sequence of tasks that involves LLM calls or other</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">operations, such as reading from a database or writing to a file </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">system. It is largely predefined and orchestrated by developer-written </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">code. These systems often leverage patterns like chaining, routing, and</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">orchestrator-worker models to manage complexity.</span>                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">The steps in a workflow are defined in advance, resulting in </span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">deterministic or rule-based paths with predictable execution and </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">explicit control flow. As illustrated in Image </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">, you can think of it </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">like a factory assembly line, where each station performs a specific, </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">repeatable task in a set order.</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```mermaid</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">graph TD</span>                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    A</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">User Query</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> --&gt; B</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #000000; text-decoration-color: #000000\">LLM Call: Classify Query</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    B --&gt;|Refund Request| C</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">LLM Call: Process Refund</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    B --&gt;|General Inquiry| D</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">LLM Call: Generate General Response</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    C --&gt; E</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">End</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    D --&gt; E</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Image </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">: A simple LLM workflow illustrating a sequence of predefined </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">tasks, where an input leads to a classification LLM, which then routes </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">to specific LLM calls before the workflow ends.</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">On the other end of the spectrum, we have AI agents. These are systems </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">where an LLM plays a central role in dynamically deciding the sequence </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">of steps, reasoning, and actions to achieve a goal. They often </span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">incorporate tools, memory, and follow frameworks like ReAct to achieve </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">their goals.</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">The steps are not defined in advance but are planned based on the task </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">and the current state of the environment. This makes them adaptive and </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">capable of handling novelty. As shown in Image </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000\">, you can think of an </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">agent as a skilled human expert addressing an unfamiliar problem, </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">adapting their approach with each new piece of information.</span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```mermaid</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">graph TD</span>                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    A</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Start\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> --&gt; B</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Agent: Initial Request/State\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    B --&gt; C</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Assistant: Analyze &amp; Plan\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    C --&gt; D</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Decision: Tool Required?\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    D --&gt;|</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"color: #000000; text-decoration-color: #000000\">| E</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Use Tool\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    E --&gt; F</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Agent: Process Tool Output\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    F --&gt; C</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    D --&gt;|</span><span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"color: #000000; text-decoration-color: #000000\">| G</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Decision: Task Completed?\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    G --&gt;|</span><span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"color: #000000; text-decoration-color: #000000\">| C</span>                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    G --&gt;|</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"color: #000000; text-decoration-color: #000000\">| H</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"End\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Image </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000\">: A simple agentic system illustrating dynamic decision-making </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">and tool usage with an assistant orchestrating the loop.</span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Both workflows and agents require an orchestration layer, but its role </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">differs considerably. In a workflow, the orchestrator executes a </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">predefined plan, much like a conductor following a musical score. This </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">ensures consistent and predictable outcomes.</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">In an agentic system, the orchestrator facilitates the LLM's dynamic </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">planning and execution, acting more like a jazz ensemble leader who </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">guides improvisation. This allows for greater flexibility and </span>          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">adaptation to unforeseen circumstances. We will explore advanced </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">workflow patterns like chaining, routing, and the orchestrator-worker </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">model in future lessons, as well as the core components of agents like </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">tools, memory, and the ReAct framework.</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">## Choosing Your Path</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">content</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;first_line_number&gt;</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">first_line_number</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;last_line_number&gt;</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">last_line_number</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">selected_text</span><span style=\"font-weight: bold\">&gt;</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Here is what you have to do with edited selected text:                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - print the edited selected text to the console for the user to see     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - give a quick summary of the changes you made                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - always apply the changes to the source file without waiting for the   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         user to explicitly ask you to do so                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - in case you haven't changed anything, just say that you haven't       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         changed anything                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client:                                                 \u001b]8;id=850537;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=363456;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Here is the edited selected text:                                       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m<\u001b[0m\u001b[1;95mselected_text\u001b[0m\u001b[39m>\u001b[0m                                                         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    \u001b[0m                                                                    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <content>```\u001b[0m                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m## Understanding the Spectrum: From Workflows to Agents\u001b[0m                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mBefore you can choose between workflows and agents, you need a clear \u001b[0m   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39munderstanding of what they are. Rather than focusing on the technical \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mspecifics, let's look at their core properties and how they function in\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mpractice.\u001b[0m                                                               \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mAn LLM workflow is a sequence of tasks that involves LLM calls or other\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39moperations, such as reading from a database or writing to a file \u001b[0m       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39msystem. It is largely predefined and orchestrated by developer-written \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mcode. These systems often leverage patterns like chaining, routing, and\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39morchestrator-worker models to manage complexity.\u001b[0m                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mThe steps in a workflow are defined in advance, resulting in \u001b[0m           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mdeterministic or rule-based paths with predictable execution and \u001b[0m       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mexplicit control flow. As illustrated in Image \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m, you can think of it \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mlike a factory assembly line, where each station performs a specific, \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mrepeatable task in a set order.\u001b[0m                                         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```mermaid\u001b[0m                                                              \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mgraph TD\u001b[0m                                                                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    A\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mUser Query\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m --> B\u001b[0m\u001b[1;39m{\u001b[0m\u001b[39mLLM Call: Classify Query\u001b[0m\u001b[1;39m}\u001b[0m                       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    B -->|Refund Request| C\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mLLM Call: Process Refund\u001b[0m\u001b[1;39m]\u001b[0m                   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    B -->|General Inquiry| D\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mLLM Call: Generate General Response\u001b[0m\u001b[1;39m]\u001b[0m       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    C --> E\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mEnd\u001b[0m\u001b[1;39m]\u001b[0m                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    D --> E\u001b[0m                                                             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```\u001b[0m                                                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mImage \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m: A simple LLM workflow illustrating a sequence of predefined \u001b[0m   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mtasks, where an input leads to a classification LLM, which then routes \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mto specific LLM calls before the workflow ends.\u001b[0m                         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mOn the other end of the spectrum, we have AI agents. These are systems \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mwhere an LLM plays a central role in dynamically deciding the sequence \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mof steps, reasoning, and actions to achieve a goal. They often \u001b[0m         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mincorporate tools, memory, and follow frameworks like ReAct to achieve \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mtheir goals.\u001b[0m                                                            \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mThe steps are not defined in advance but are planned based on the task \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mand the current state of the environment. This makes them adaptive and \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mcapable of handling novelty. As shown in Image \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m, you can think of an \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39magent as a skilled human expert addressing an unfamiliar problem, \u001b[0m      \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39madapting their approach with each new piece of information.\u001b[0m             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```mermaid\u001b[0m                                                              \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mgraph TD\u001b[0m                                                                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    A\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Start\"\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m --> B\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Agent: Initial Request/State\"\u001b[0m\u001b[1;39m]\u001b[0m                    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    B --> C\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m\"Assistant: Analyze & Plan\"\u001b[0m\u001b[1;39m}\u001b[0m                                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    C --> D\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m\"Decision: Tool Required?\"\u001b[0m\u001b[1;39m}\u001b[0m                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    D -->|\u001b[0m\u001b[32m\"Yes\"\u001b[0m\u001b[39m| E\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Use Tool\"\u001b[0m\u001b[1;39m]\u001b[0m                                          \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    E --> F\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Agent: Process Tool Output\"\u001b[0m\u001b[1;39m]\u001b[0m                               \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    F --> C\u001b[0m                                                             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    D -->|\u001b[0m\u001b[32m\"No\"\u001b[0m\u001b[39m| G\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m\"Decision: Task Completed?\"\u001b[0m\u001b[1;39m}\u001b[0m                          \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    G -->|\u001b[0m\u001b[32m\"No\"\u001b[0m\u001b[39m| C\u001b[0m                                                       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    G -->|\u001b[0m\u001b[32m\"Yes\"\u001b[0m\u001b[39m| H\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"End\"\u001b[0m\u001b[1;39m]\u001b[0m                                               \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```\u001b[0m                                                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mImage \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m: A simple agentic system illustrating dynamic decision-making \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mand tool usage with an assistant orchestrating the loop.\u001b[0m                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mBoth workflows and agents require an orchestration layer, but its role \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mdiffers considerably. In a workflow, the orchestrator executes a \u001b[0m       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mpredefined plan, much like a conductor following a musical score. This \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mensures consistent and predictable outcomes.\u001b[0m                            \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mIn an agentic system, the orchestrator facilitates the LLM's dynamic \u001b[0m   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mplanning and execution, acting more like a jazz ensemble leader who \u001b[0m    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mguides improvisation. This allows for greater flexibility and \u001b[0m          \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39madaptation to unforeseen circumstances. We will explore advanced \u001b[0m       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mworkflow patterns like chaining, routing, and the orchestrator-worker \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mmodel in future lessons, as well as the core components of agents like \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mtools, memory, and the ReAct framework.\u001b[0m                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m## Choosing Your Path\u001b[0m                                                   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mcontent\u001b[0m\u001b[39m>\u001b[0m                                                           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <first_line_number>\u001b[0m\u001b[1;36m11\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mfirst_line_number\u001b[0m\u001b[39m>\u001b[0m                           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <last_line_number>\u001b[0m\u001b[1;36m44\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mlast_line_number\u001b[0m\u001b[39m>\u001b[0m                             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mselected_text\u001b[0m\u001b[1m>\u001b[0m                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Here is what you have to do with edited selected text:                  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - print the edited selected text to the console for the user to see     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - give a quick summary of the changes you made                          \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - always apply the changes to the source file without waiting for the   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         user to explicitly ask you to do so                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - in case you haven't changed anything, just say that you haven't       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         changed anything                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\nHere is the edited selected </span>       <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">text:\\n\\n&lt;selected_text&gt;\\n    \\n    &lt;content&gt;```\\n## Understanding the </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Spectrum: From Workflows to Agents\\n\\nBefore you can choose between </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">workflows and agents, you need a clear understanding of what they are. </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Rather than focusing on the technical specifics, let\\'s look at their </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">core properties and how they function in practice.\\n\\nAn LLM workflow is</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">a sequence of tasks that involves LLM calls or other operations, such as</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">reading from a database or writing to a file system. It is largely </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">predefined and orchestrated by developer-written code. These systems </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">often leverage patterns like chaining, routing, and orchestrator-worker </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">models to manage complexity.\\n\\nThe steps in a workflow are defined in </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">advance, resulting in deterministic or rule-based paths with predictable</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">execution and explicit control flow. As illustrated in Image 1, you can </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">think of it like a factory assembly line, where each station performs a </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">specific, repeatable task in a set order.\\n\\n```mermaid\\ngraph TD\\n    </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">A[User Query] --&gt; B{LLM Call: Classify Query}\\n    B --&gt;|Refund Request|</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">C[LLM Call: Process Refund]\\n    B --&gt;|General Inquiry| D[LLM Call: </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Generate General Response]\\n    C --&gt; E[End]\\n    D --&gt; E\\n```\\nImage 1:</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">A simple LLM workflow illustrating a sequence of predefined tasks, where</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">an input leads to a classification LLM, which then routes to specific </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">LLM calls before the workflow ends.\\n\\nOn the other end of the spectrum,</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">we have AI agents. These are systems where an LLM plays a central role </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">in dynamically deciding the sequence of steps, reasoning, and actions to</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">achieve a goal. They often incorporate tools, memory, and follow </span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">frameworks like ReAct to achieve their goals.\\n\\nThe steps are not </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">defined in advance but are planned based on the task and the current </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">state of the environment. This makes them adaptive and capable of </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">handling novelty. As shown in Image 2, you can think of an agent as a </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">skilled human expert addressing an unfamiliar problem, adapting their </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">approach with each new piece of information.\\n\\n```mermaid\\ngraph TD\\n  </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">A[\"Start\"] --&gt; B[\"Agent: Initial Request/State\"]\\n    B --&gt; </span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">C{\"Assistant: Analyze &amp; Plan\"}\\n    C --&gt; D{\"Decision: Tool </span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Required?\"}\\n    D --&gt;|\"Yes\"| E[\"Use Tool\"]\\n    E --&gt; F[\"Agent: Process</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Tool Output\"]\\n    F --&gt; C\\n    D --&gt;|\"No\"| G{\"Decision: Task </span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Completed?\"}\\n    G --&gt;|\"No\"| C\\n    G --&gt;|\"Yes\"| H[\"End\"]\\n```\\nImage </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">2: A simple agentic system illustrating dynamic decision-making and tool</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">usage with an assistant orchestrating the loop.\\n\\nBoth workflows and </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">agents require an orchestration layer, but its role differs </span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">considerably. In a workflow, the orchestrator executes a predefined </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">plan, much like a conductor following a musical score. This ensures </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">consistent and predictable outcomes.\\n\\nIn an agentic system, the </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">orchestrator facilitates the LLM\\'s dynamic planning and execution, </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">acting more like a jazz ensemble leader who guides improvisation. This </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">allows for greater flexibility and adaptation to unforeseen </span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">circumstances. We will explore advanced workflow patterns like chaining,</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">routing, and the orchestrator-worker model in future lessons, as well as</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">the core components of agents like tools, memory, and the ReAct </span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">framework.\\n\\n## Choosing Your Path\\n```&lt;/content&gt;\\n    </span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">&lt;first_line_number&gt;11&lt;/first_line_number&gt;\\n    </span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">&lt;last_line_number&gt;44&lt;/last_line_number&gt;\\n&lt;/selected_text&gt;\\n\\n\\nHere is </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">what you have to do with edited selected text:\\n- print the edited </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">selected text to the console for the user to see\\n- give a quick summary</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">of the changes you made\\n- always apply the changes to the source file </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">without waiting for the user to explicitly ask you to do so\\n- in case </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">you haven\\'t changed anything, just say that you haven\\'t changed </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">anything\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'\\nHere is the edited selected \u001b[0m       \u001b]8;id=724497;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=16032;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mtext:\\n\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mselected_text\u001b[0m\u001b[32m>\\n    \\n    <content>```\\n## Understanding the \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mSpectrum: From Workflows to Agents\\n\\nBefore you can choose between \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mworkflows and agents, you need a clear understanding of what they are. \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mRather than focusing on the technical specifics, let\\'s look at their \u001b[0m   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mcore properties and how they function in practice.\\n\\nAn LLM workflow is\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32ma sequence of tasks that involves LLM calls or other operations, such as\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mreading from a database or writing to a file system. It is largely \u001b[0m      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mpredefined and orchestrated by developer-written code. These systems \u001b[0m    \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32moften leverage patterns like chaining, routing, and orchestrator-worker \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mmodels to manage complexity.\\n\\nThe steps in a workflow are defined in \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32madvance, resulting in deterministic or rule-based paths with predictable\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mexecution and explicit control flow. As illustrated in Image 1, you can \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mthink of it like a factory assembly line, where each station performs a \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mspecific, repeatable task in a set order.\\n\\n```mermaid\\ngraph TD\\n    \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mA\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser Query\u001b[0m\u001b[32m]\u001b[0m\u001b[32m --> B\u001b[0m\u001b[32m{\u001b[0m\u001b[32mLLM Call: Classify Query\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n    B -->|Refund Request|\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mC\u001b[0m\u001b[32m[\u001b[0m\u001b[32mLLM Call: Process Refund\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    B -->|General Inquiry| D\u001b[0m\u001b[32m[\u001b[0m\u001b[32mLLM Call: \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mGenerate General Response\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    C --> E\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEnd\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    D --> E\\n```\\nImage 1:\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mA simple LLM workflow illustrating a sequence of predefined tasks, where\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32man input leads to a classification LLM, which then routes to specific \u001b[0m   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mLLM calls before the workflow ends.\\n\\nOn the other end of the spectrum,\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mwe have AI agents. These are systems where an LLM plays a central role \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32min dynamically deciding the sequence of steps, reasoning, and actions to\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32machieve a goal. They often incorporate tools, memory, and follow \u001b[0m        \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mframeworks like ReAct to achieve their goals.\\n\\nThe steps are not \u001b[0m      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mdefined in advance but are planned based on the task and the current \u001b[0m    \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mstate of the environment. This makes them adaptive and capable of \u001b[0m       \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mhandling novelty. As shown in Image 2, you can think of an agent as a \u001b[0m   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mskilled human expert addressing an unfamiliar problem, adapting their \u001b[0m   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mapproach with each new piece of information.\\n\\n```mermaid\\ngraph TD\\n  \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mA\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Start\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m --> B\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Agent: Initial Request/State\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    B --> \u001b[0m             \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mC\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"Assistant: Analyze & Plan\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n    C --> D\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"Decision: Tool \u001b[0m             \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mRequired?\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n    D -->|\"Yes\"| E\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Use Tool\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    E --> F\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Agent: Process\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mTool Output\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    F --> C\\n    D -->|\"No\"| G\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"Decision: Task \u001b[0m           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mCompleted?\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n    G -->|\"No\"| C\\n    G -->|\"Yes\"| H\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"End\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n```\\nImage \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m2: A simple agentic system illustrating dynamic decision-making and tool\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32musage with an assistant orchestrating the loop.\\n\\nBoth workflows and \u001b[0m   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32magents require an orchestration layer, but its role differs \u001b[0m             \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mconsiderably. In a workflow, the orchestrator executes a predefined \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mplan, much like a conductor following a musical score. This ensures \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mconsistent and predictable outcomes.\\n\\nIn an agentic system, the \u001b[0m       \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32morchestrator facilitates the LLM\\'s dynamic planning and execution, \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32macting more like a jazz ensemble leader who guides improvisation. This \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mallows for greater flexibility and adaptation to unforeseen \u001b[0m             \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mcircumstances. We will explore advanced workflow patterns like chaining,\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mrouting, and the orchestrator-worker model in future lessons, as well as\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mthe core components of agents like tools, memory, and the ReAct \u001b[0m         \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mframework.\\n\\n## Choosing Your Path\\n```</content>\\n    \u001b[0m                 \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m<first_line_number>11</first_line_number>\\n    \u001b[0m                          \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m<last_line_number>44</last_line_number>\\n</selected_text\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n\\n\\nHere is \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mwhat you have to do with edited selected text:\\n- print the edited \u001b[0m      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mselected text to the console for the user to see\\n- give a quick summary\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mof the changes you made\\n- always apply the changes to the source file \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mwithout waiting for the user to explicitly ask you to do so\\n- in case \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32myou haven\\'t changed anything, just say that you haven\\'t changed \u001b[0m       \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32manything\\n'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                              \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------ Edit Selected Text Result ------------------------------------\u001b[0m\n",
      "  \n",
      "Here is the edited selected text:\n",
      "\n",
      "<selected_text>\n",
      "    \n",
      "    <content>```\n",
      "## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "Before you can choose between workflows and agents, you need a clear understanding of what they are. Rather than focusing on the technical specifics, let's look at their core properties and how they function in practice.\n",
      "\n",
      "An LLM workflow is a sequence of tasks that involves LLM calls or other operations, such as reading from a database or writing to a file system. It is largely predefined and orchestrated by developer-written code. These systems often leverage patterns like chaining, routing, and orchestrator-worker models to manage complexity.\n",
      "\n",
      "The steps in a workflow are defined in advance, resulting in deterministic or rule-based paths with predictable execution and explicit control flow. As illustrated in Image 1, you can think of it like a factory assembly line, where each station performs a specific, repeatable task in a set order.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[User Query] --> B{LLM Call: Classify Query}\n",
      "    B -->|Refund Request| C[LLM Call: Process Refund]\n",
      "    B -->|General Inquiry| D[LLM Call: Generate General Response]\n",
      "    C --> E[End]\n",
      "    D --> E\n",
      "```\n",
      "Image 1: A simple LLM workflow illustrating a sequence of predefined tasks, where an input leads to a classification LLM, which then routes to specific LLM calls before the workflow ends.\n",
      "\n",
      "On the other end of the spectrum, we have AI agents. These are systems where an LLM plays a central role in dynamically deciding the sequence of steps, reasoning, and actions to achieve a goal. They often incorporate tools, memory, and follow frameworks like ReAct to achieve their goals.\n",
      "\n",
      "The steps are not defined in advance but are planned based on the task and the current state of the environment. This makes them adaptive and capable of handling novelty. As shown in Image 2, you can think of an agent as a skilled human expert addressing an unfamiliar problem, adapting their approach with each new piece of information.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent: Initial Request/State\"]\n",
      "    B --> C{\"Assistant: Analyze & Plan\"}\n",
      "    C --> D{\"Decision: Tool Required?\"}\n",
      "    D -->|\"Yes\"| E[\"Use Tool\"]\n",
      "    E --> F[\"Agent: Process Tool Output\"]\n",
      "    F --> C\n",
      "    D -->|\"No\"| G{\"Decision: Task Completed?\"}\n",
      "    G -->|\"No\"| C\n",
      "    G -->|\"Yes\"| H[\"End\"]\n",
      "```\n",
      "Image 2: A simple agentic system illustrating dynamic decision-making and tool usage with an assistant orchestrating the loop.\n",
      "\n",
      "Both workflows and agents require an orchestration layer, but its role differs considerably. In a workflow, the orchestrator executes a predefined plan, much like a conductor following a musical score. This ensures consistent and predictable outcomes.\n",
      "\n",
      "In an agentic system, the orchestrator facilitates the LLM's dynamic planning and execution, acting more like a jazz ensemble leader who guides improvisation. This allows for greater flexibility and adaptation to unforeseen circumstances. We will explore advanced workflow patterns like chaining, routing, and the orchestrator-worker model in future lessons, as well as the core components of agents like tools, memory, and the ReAct framework.\n",
      "\n",
      "## Choosing Your Path\n",
      "```</content>\n",
      "    <first_line_number>11</first_line_number>\n",
      "    <last_line_number>44</last_line_number>\n",
      "</selected_text>\n",
      "\n",
      "\n",
      "Here is what you have to do with edited selected text:\n",
      "- print the edited selected text to the console for the user to see\n",
      "- give a quick summary of the changes you made\n",
      "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
      "- in case you haven't changed anything, just say that you haven't changed anything\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "human_feedback = \"\"\"Improve the first mermaid diagram. Also, expand on the definition of \n",
    "both workflows and agents as I feel it's too shallow\"\"\"\n",
    "\n",
    "async with mcp_client:\n",
    "    result = await mcp_client.call_tool(\n",
    "        \"edit_selected_text\",\n",
    "        {\n",
    "            \"article_path\": str(SAMPLE_DIR / \"article.md\"),\n",
    "            \"human_feedback\": human_feedback,\n",
    "            \"selected_text\": selected_text,\n",
    "            \"first_line_number\": start_line,\n",
    "            \"last_line_number\": end_line,\n",
    "        },\n",
    "    )\n",
    "    pretty_print.wrapped(\n",
    "        result.data,\n",
    "        title=\"Edit Selected Text Result\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ **Important Observation**\n",
    "\n",
    "Now the question is how do we apply these changes to the original article?\n",
    "\n",
    "Note the text after the `selected_text` XML block we have the following instructions:\n",
    "```text\n",
    "Here is what you have to do with edited selected text:\n",
    "- print the edited selected text to the console for the user to see\n",
    "- give a quick summary of the changes you made\n",
    "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
    "- in case you haven't changed anything, just say that you haven't changed anything\n",
    "```\n",
    "\n",
    "This instructs the tool consumer, which is the MCP client, such as Cursor, what to do with the new version of the selected text. In this use case, using these instructions, we instruct the MCP Client to always apply these changes to the original article. Otherwise, the edited selected text will be showed within the tool output, but never applied as a patch to the original article.\n",
    "\n",
    "When using this with tools such as Cursor, it will show you the `diff` experience where you have to manually accept the new changes, improving even more the whole human in the loop experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 MCP Prompts\n",
    "\n",
    "MCP prompts provide pre-configured templates that MCP clients can use to easily trigger a tool or a composition of tools (remember the example from Nova the deep research agent). Brown exposes three prompts corresponding to the three tools as an easy way to interface with its functionality:\n",
    "\n",
    "\n",
    "```python\n",
    "@mcp.prompt\n",
    "def generate_article_prompt(dir_path: Path) -> str:\n",
    "    \"\"\"Retrieve a prompt that will trigger the article generation workflow.\"\"\"\n",
    "    return f\"\"\"\n",
    "Using Brown hosted as an MCP server, generate an article using all the necessary resources from \n",
    "the following directory: `{dir_path}`. Don't check if any expected files are missing, just trigger \n",
    "the \"generate_article\" tool of the Brown MCP Server, which will take care of everything.\n",
    "\"\"\"\n",
    "\n",
    "@mcp.prompt\n",
    "def edit_article_prompt(human_feedback: str = \"\") -> str:\n",
    "    \"\"\"Retrieve a prompt that will trigger the article editing workflow.\"\"\"\n",
    "    return f\"\"\"\n",
    "Using Brown hosted as an MCP server, edit an entire article based on human feedback \n",
    "and other expected requirements. Don't check if any expected files are missing, \n",
    "just trigger the \"edit_article\" tool of the Brown MCP Server, which will take care \n",
    "of everything.\n",
    "\n",
    "Human feedback:\n",
    "<human_feedback>\n",
    "{human_feedback}\n",
    "</human_feedback>\n",
    "\n",
    "If the <human_feedback> is empty, you will infer it from the previous messages. If there are no other messages \n",
    "to infer from, use an empty string. Don't ever fill it in with things such as \"Please provide more details\" or\n",
    "fill it in with generic stuff.\n",
    "\"\"\"\n",
    "\n",
    "@mcp.prompt\n",
    "def edit_selected_text_prompt(human_feedback: str = \"\") -> str:\n",
    "    \"\"\"Retrieve a prompt that will trigger the selected text editing workflow.\"\"\"\n",
    "    return f\"\"\"\n",
    "Using Brown hosted as an MCP server, edit the selected text from the article based on human feedback and \n",
    "other expected requirements. Don't check if any expected files are missing, just trigger the \"edit_selected_text\" \n",
    "tool of the Brown MCP Server, which will take care of everything.\n",
    "\n",
    "Human feedback:\n",
    "<human_feedback>\n",
    "{human_feedback}\n",
    "</human_feedback>\n",
    "\n",
    "If the <human_feedback> is empty, you will infer it from the previous messages. If there are no other messages \n",
    "to infer from, use an empty string. Don't ever fill it in with things such as \"Please provide more details\" or\n",
    "fill it in with generic stuff.\n",
    "\"\"\"\n",
    "```\n",
    "These prompts make it easy for users to trigger the MCP's server tool without reading any documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we can access the prompts, starting with the one for generating articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ `user` Message ------------------------------------------\u001b[0m\n",
      "  Role: user\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Content: \n",
      "Using Brown hosted as an MCP server, generate an article using all the necessary resources from \n",
      "the following directory: `inputs/tests/01_sample`. Don't check if any expected files are missing, just trigger \n",
      "the \"generate_article\" tool of the Brown MCP Server, which will take care of everything.\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    result = await mcp_client.get_prompt(\n",
    "        \"generate_article_prompt\",\n",
    "        {\n",
    "            \"dir_path\": SAMPLE_DIR,\n",
    "        },\n",
    "    )\n",
    "    for message in result.messages:\n",
    "        pretty_print.wrapped(\n",
    "            [\n",
    "                f\"Role: {message.role}\",\n",
    "                f\"Content: {str(message.content.text)}\",\n",
    "            ],\n",
    "            title=f\"`{message.role}` Message\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look how the one for editing a piece of selected text looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ `user` Message ------------------------------------------\u001b[0m\n",
      "  Role: user\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Content: \n",
      "Using Brown hosted as an MCP server, edit the selected text from the article based on human feedback and \n",
      "other expected requirements. Don't check if any expected files are missing, just trigger the \"edit_selected_text\" \n",
      "tool of the Brown MCP Server, which will take care of everything.\n",
      "\n",
      "Human feedback:\n",
      "<human_feedback>\n",
      "Improve the first mermaid diagram. Also, expand on the definition of \n",
      "both workflows and agents as I feel it's too shallow\n",
      "</human_feedback>\n",
      "\n",
      "If the <human_feedback> is empty, you will infer it from the previous messages. If there are no other messages \n",
      "to infer from, use an empty string. Don't ever fill it in with things such as \"Please provide more details\" or\n",
      "fill it in with generic stuff.\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    result = await mcp_client.get_prompt(\n",
    "        \"edit_selected_text_prompt\",\n",
    "        {\n",
    "            \"human_feedback\": human_feedback,\n",
    "        },\n",
    "    )\n",
    "    for message in result.messages:\n",
    "        pretty_print.wrapped(\n",
    "            [\n",
    "                f\"Role: {message.role}\",\n",
    "                f\"Content: {str(message.content.text)}\",\n",
    "            ],\n",
    "            title=f\"`{message.role}` Message\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `edit_article_prompt` is almost identical to `edit_selected_text_prompt`. Thus, we will skip it.\n",
    "\n",
    "Still, the real beauty of using prompts through MCP Servers is when we actually plug in the server into a client such as Cursor that has access to a chatbot that can pick up on the instructions from the retrieved prompts and follows the instructions from it such as calling the generate article tool.\n",
    "\n",
    "This makes prompts an amazing way to interface with MCP Server, for example describing workflows that use the MCP Server tools in various ways, and passing them directly to the client, without letting the consumer worry about how to use them.\n",
    "\n",
    "We will illustrate this in the video attached to this lesson where we will show how this works in Cursor, but a similar behavior applies in other MCP clients, such as Claude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 MCP Resources\n",
    "\n",
    "MCP resources provide read-only access to configuration and state information. Brown exposes resources for accessing the app configuration and profiles:\n",
    "\n",
    "```python\n",
    "@mcp.resource(\"resource://config/app\", mime_type=\"application/json\")\n",
    "def get_app_config() -> dict:\n",
    "    \"\"\"Get the application configuration for Brown Agent as an MCP resource.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The application configuration including:\n",
    "            - Model configurations for each workflow node\n",
    "            - File paths for profiles, examples, and context files\n",
    "            - Number of review iterations and workflow settings\n",
    "            - Temperature and other model parameters\n",
    "    \"\"\"\n",
    "    return app_config.model_dump(mode=\"json\")\n",
    "\n",
    "@mcp.resource(\"resource://profiles/character\")\n",
    "def get_character_profile() -> str:\n",
    "    \"\"\"Get the character profile resource for Brown Agent.\n",
    "    \n",
    "    Returns:\n",
    "        str: The character profile content in markdown format\n",
    "    \"\"\"\n",
    "    return __get_profile(\"character\")\n",
    "```\n",
    "\n",
    "Resources allow MCP clients to understand how Brown is configured without modifying any state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the resources to see the MCP server configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------ `get_app_config` Resource ------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"uri\": \"resource://config/app\",\n",
      "  \"name\": \"get_app_config\",\n",
      "  \"description\": \"Get the application configuration for Brown Agent as an MCP resource.\\n\\nThis resource provides access to the complete Brown Agent configuration,\\nincluding model settings, file paths, and workflow parameters. The configuration\\nis loaded from YAML files and converted to a JSON-serializable format.\\n\\nReturns:\\n    dict: The application configuration as a JSON-serializable dictionary containing:\\n        - Model configurations for each workflow node (write_article, review_article, etc.)\\n        - File paths for profiles, examples, and context files\\n        - Number of review iterations and workflow settings\\n        - Temperature and other model parameters\\n        - Tool configurations and model assignments\",\n",
      "  \"mime_type\": \"application/json\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------- `get_character_profile` Resource ---------------------------------\u001b[0m\n",
      "  {\n",
      "  \"uri\": \"resource://profiles/character\",\n",
      "  \"name\": \"get_character_profile\",\n",
      "  \"description\": \"Get the character profile resource for Brown Agent as an MCP resource.\\n\\nThis resource provides access to the character-specific writing persona\\nthat the Brown Agent uses for consistent article generation and editing.\\nThe character profile defines the voice, perspective, and personal style\\nthat should be reflected in the generated content.\\n\\nThe profile is loaded using the same builders pattern as the workflows,\\nensuring consistency across the Brown Agent system.\\n\\nReturns:\\n    str: The character profile content in markdown format, loaded from\\n         the configured character profile file.\\n\\nRaises:\\n    ValueError: If the character profile cannot be loaded or is not found.\\n\\nExample:\\n    The character profile typically includes information about:\\n    - Writing voice and tone preferences\\n    - Personal background and expertise areas\\n    - Preferred terminology and expressions\\n    - Communication style and approach\",\n",
      "  \"mime_type\": \"text/plain\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    resources = await mcp_client.list_resources()\n",
    "\n",
    "    for resource in resources:\n",
    "        resource_dict = {\n",
    "            \"uri\": str(resource.uri),\n",
    "            \"name\": resource.name,\n",
    "            \"description\": resource.description,\n",
    "            \"mime_type\": resource.mimeType,\n",
    "        }\n",
    "        if hasattr(resource, \"_meta\") and resource._meta:\n",
    "            fastmcp_meta = resource._meta.get(\"_fastmcp\", {})\n",
    "            resource_dict[\"tags\"] = fastmcp_meta.get(\"tags\", [])\n",
    "\n",
    "        pretty_print.wrapped(\n",
    "            resource_dict,\n",
    "            title=f\"`{resource.name}` Resource\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look into each resource independently starting with the app configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------------- App Configuration ----------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"context\": {\n",
      "    \"article_guideline_loader\": \"markdown\",\n",
      "    \"article_guideline_uri\": \"article_guideline.md\",\n",
      "    \"research_loader\": \"markdown\",\n",
      "    \"research_uri\": \"research.md\",\n",
      "    \"article_loader\": \"markdown\",\n",
      "    \"article_renderer\": \"markdown\",\n",
      "    \"article_uri\": \"article.md\",\n",
      "    \"profiles_loader\": \"markdown\",\n",
      "    \"profiles_uri\": \"inputs/profiles\",\n",
      "    \"character_profile\": \"paul_iusztin.md\",\n",
      "    \"examples_loader\": \"markdown\",\n",
      "    \"examples_uri\": \"inputs/examples/course_lessons\"\n",
      "  },\n",
      "  \"memory\": {\n",
      "    \"checkpointer\": \"in_memory\"\n",
      "  },\n",
      "  \"num_reviews\": 2,\n",
      "  \"nodes\": {\n",
      "    \"generate_media_items\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {\n",
      "        \"mermaid_diagram_generator\": {\n",
      "          \"name\": \"mermaid_diagram_generator\",\n",
      "          \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "          \"config\": {\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_k\": null,\n",
      "            \"n\": 1,\n",
      "            \"response_modalities\": null,\n",
      "            \"include_thoughts\": false,\n",
      "            \"thinking_budget\": null,\n",
      "            \"max_output_tokens\": null,\n",
      "            \"max_retries\": 6,\n",
      "            \"mocked_response\": null\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"write_article\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.7,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"review_article\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"edit_article\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.1,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"review_selected_text\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"edit_selected_text\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.1,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "async with mcp_client:\n",
    "    content = await mcp_client.read_resource(\"resource://config/app\")\n",
    "\n",
    "    pretty_print.wrapped(\n",
    "        json.loads(content[0].text),\n",
    "        title=\"App Configuration\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the character profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------------- Character Profile ----------------------------------------\u001b[0m\n",
      "  ## About Paul Iusztin\n",
      "\n",
      "Iâ€™m **Paul Iusztin**. A 29 years old senior AI Engineer and content creator.\n",
      "\n",
      "I help engineers ship AI products.\n",
      "\n",
      "Iâ€™m the author of the bestseller LLM Engineerâ€™s Handbook, lead instructor of the Agentic AI Engineering course, founding AI Engineer of a San Francisco start-up, and obsessed with making knowledge accessible through AI.\n",
      "\n",
      "With over 10 years of experience and 20 apps shipped, I teach AI Engineering as I wanted to at the beginning of my career. End-to-end. From idea to production. From data collection to deploying, monitoring and evaluation. With a focus on AI principles, software patterns and infrastructure systems that will thrive in a future dominated by AI coding tools.\n",
      "\n",
      "My ultimate goal is to help other engineers escape the PoC purgatory and x10 their AI Engineering skills.\n",
      "\n",
      "I'm also the founder of the **Decoding AI Magazine**, a place for real-world guides takingÂ you from the PoC purgatoryÂ to shipping AI products that work.\n",
      "\n",
      "I founded this magazine to solve the problem I faced for the first five years of my career: escaping the â€œPoC purgatory.â€ I realized that finding a team that knows how to ship AI software is rare. Too many AI projects get stuck at Jupyter Notebooks or fancy demos that never see a real user.\n",
      "\n",
      "Decoding AI is the solution. Itâ€™s your weekly hub for learning how to design, build, and ship production-grade AI systems. End-to-end. From idea to production. From data collection to deploying, monitoring and evaluation. With a focus on AI principles, software patterns and infrastructure systems that will thrive in a future dominated by AI coding tools.\n",
      "\n",
      "Stop building prototypes. Start shipping AI that works.\n",
      "\n",
      "## Niche\n",
      "\n",
      "**Broad:** AI Engineering, AI Systems, Software Engineering, Ops\n",
      "**Specialized**: RAG, LLMs, AI Agents, AI Workflows, LLMOps, AI Evals, AI Monitoring, AI Infrastructure, Serving AI Applications, Memory\n",
      "**Vibe:** premium, minimalistic, high-quality content, straight-to-the-point content (the opposite of FOMO), zero hype, artsy, builder mindset, deep and real\n",
      "\n",
      "## Similar Personas\n",
      "\n",
      "- Andrew Ng\n",
      "- Chip Huyen\n",
      "- Sebastian Raschka\n",
      "- Louis-FranÃ§ois Bouchard\n",
      "- Maxime Labonne\n",
      "- Jason Liu\n",
      "- Lex Fridman\n",
      "- Aleksa Gordic\n",
      "\n",
      "## My Core Content Pillars I Always Talk About\n",
      "\n",
      "1. Shipping Production-Ready AI\n",
      "2. Practical Learning for AI Engineers\n",
      "3. Behind-the-Scenes of Building in Public\n",
      "4. AI for Founders & Technical Teams \n",
      "\n",
      "## Style\n",
      "\n",
      "- **Real:** Showing the engineering, social, and economic truth behind AI and content creation\n",
      "- **Trust:** No FOMO, just real engineering focusing on what matters\n",
      "- **Minimalist:** Straight to the point engineering. Use only what is required to get shit done.\n",
      "- **Simple:** â€œKeep it simpleâ€ should be the motto of your persona. Focus on what matters while avoiding FOMO and fluff just to get attention\n",
      "- **Controversy:**\n",
      "    - Talk about what everybody thinks, but they're too afraid to say out loud.\n",
      "    - Going against the flow, Gary Marcus style: \"LLMs are stupid,\" \"Agents are stupid,â€ \"LangChain is stupid\".\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    content = await mcp_client.read_resource(\"resource://profiles/character\")\n",
    "\n",
    "    pretty_print.wrapped(\n",
    "        content[0].text,\n",
    "        title=\"Character Profile\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Clean Separation of MCP Layer\n",
    "\n",
    "Notice how all the MCP code lives in the `brown.mcp` module and simply imports from other layers:\n",
    "\n",
    "- **Domain layer**: Imports entities like `Article`, `HumanFeedback`, `Review`\n",
    "- **App layer**: Imports workflows like `build_edit_article_workflow`, `build_edit_selected_text_workflow`\n",
    "- **Infrastructure layer**: Imports builders like `build_loaders`, `build_short_term_memory`\n",
    "\n",
    "The MCP layer is just a thin serving/interface layer that orchestrates the other components. This separation means:\n",
    "\n",
    "- We can serve Brown through different methods (CLI, FastAPI, gRPC) without changing core logic\n",
    "- The MCP code is independent and can be modified without affecting other layers\n",
    "- We can easily add new MCP tools, prompts, or resources\n",
    "- Testing is easier because each layer has clear boundaries\n",
    "\n",
    "This is a key advantage of using clean architecture principles throughout the Brown project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Brown MCP CLI Script\n",
    "\n",
    "Brown includes a command-line interface that lets you interact with the MCP server directly from your terminal. This is useful for scripting, automation, and quick testing.\n",
    "\n",
    "The CLI script is located at `lessons/writing_workflow/scripts/brown_mcp_cli.py` and provides three main commands:\n",
    "\n",
    "1. **generate-article**: Generate an article from scratch\n",
    "2. **edit-article**: Edit an entire article based on human feedback\n",
    "3. **edit-selected-text**: Edit a selected section of an article\n",
    "\n",
    "### Usage Examples\n",
    "\n",
    "First change your directory to `lessons/writing_workflow` and then you can run:\n",
    "\n",
    "\n",
    "```bash\n",
    "# Generate an article\n",
    "python scripts/brown_mcp_cli.py generate-article --dir-path /path/to/article\n",
    "\n",
    "# Edit an entire article\n",
    "python scripts/brown_mcp_cli.py edit-article \\\n",
    "    --dir-path /path/to/article \\\n",
    "    --human-feedback \"Improve the introduction\"\n",
    "\n",
    "# Edit selected text\n",
    "python scripts/brown_mcp_cli.py edit-selected-text \\\n",
    "    --dir-path /path/to/article \\\n",
    "    --human-feedback \"Make this clearer\" \\\n",
    "    --first-line 10 \\\n",
    "    --last-line 20\n",
    "```\n",
    "\n",
    "The CLI uses the in-memory MCP client to call the MCP server tools, providing a simple interface for Brown's capabilities.\n",
    "\n",
    "For more details on using Brown as a standalone project, see the documentation at `lessons/writing_workflow/README.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cursor Integration\n",
    "\n",
    "The real power of Brown comes when integrating it with MCP clients like Cursor. This creates a writing experience similar to coding with AI assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Cursor Configuration\n",
    "\n",
    "To use Brown with Cursor, you need to configure it in your `.cursor/mcp.json` file:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"brown\": {\n",
    "            \"command\": \"uv\",\n",
    "            \"args\": [\n",
    "                \"--directory\",\n",
    "                \"lessons/writing_workflow/\",\n",
    "                \"run\",\n",
    "                \"python\",\n",
    "                \"-m\",\n",
    "                \"brown.mcp.server\"\n",
    "            ],\n",
    "            \"cwd\": \"${workspaceFolder}\",\n",
    "            \"env\": {\n",
    "                \"ENV_FILE_PATH\": \"${workspaceFolder}/lessons/writing_workflow/.env\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "This configuration tells Cursor:\n",
    "- The name of the MCP server (\"brown\")\n",
    "- How to launch the server using `uv` and Python\n",
    "- The working directory and environment variables\n",
    "\n",
    "Once configured, Cursor can discover and use Brown's MCP tools automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 The Brown + Human-in-the-Loop Writing Experience\n",
    "\n",
    "With Brown integrated into Cursor, your writing workflow becomes:\n",
    "\n",
    "1. **Generate Initial Article**: Use the `generate_article` tool or prompt to create a first draft\n",
    "2. **Review as Human Expert**: Read through the generated article with your domain expertise\n",
    "3. **Provide Feedback**: Select sections that need improvement and provide specific feedback\n",
    "4. **AI Edits**: Use `edit_article` or `edit_selected_text` tools to refine based on your feedback\n",
    "5. **Iterate**: Repeat steps 2-4 until satisfied with the article\n",
    "\n",
    "This creates a collaborative experience where:\n",
    "- AI handles the heavy lifting of writing and editing\n",
    "- You guide the direction with your expertise and feedback\n",
    "- The workflow is fast and iterative\n",
    "- You maintain full control over the final output\n",
    "\n",
    "### Video Demonstration\n",
    "\n",
    "We've created a video demonstration showing Brown in action with Cursor. The video shows:\n",
    "- How to set up Brown in Cursor\n",
    "- Generating an article from research and guidelines\n",
    "- Reviewing the generated content\n",
    "- Using human-in-the-loop editing to refine specific sections\n",
    "- The iterative refinement process until the article is complete\n",
    "\n",
    "[Link to video demonstration will be provided]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this lesson, we've explored how to implement human-in-the-loop capabilities in the Brown writing workflow. Let's recap what we've learned and look at future possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We've Learned\n",
    "\n",
    "1. **Human-in-the-Loop**: We learned how to design AI workflows that balance automation with human expertise, allowing AI to handle heavy lifting while keeping humans in control\n",
    "\n",
    "2. **Edit Article Workflow**: We implemented the `edit_article` workflow that reviews and edits entire articles based on human feedback and expected requirements\n",
    "\n",
    "3. **Edit Selected Text Workflow**: We built the `edit_selected_text` workflow for precise, focused edits on specific article sections\n",
    "\n",
    "4. **MCP Server**: We served Brown as an MCP server with tools, prompts, and resources while respecting clean architecture principles\n",
    "\n",
    "5. **Cursor Integration**: We learned how to integrate Brown with Cursor to create a coding-like writing experience with human-in-the-loop editing\n",
    "\n",
    "The key insight is that we can use a low number of review loops during initial article generation, then dynamically run additional editing workflows with human feedback when necessary. This approach is both efficient and effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Extension Ideas\n",
    "\n",
    "Here are some ways you can extend Brown to fit your needs:\n",
    "\n",
    "1. **Hook Brown to Claude Desktop**: Instead of using Cursor, integrate Brown with Claude Desktop for a different AI assistant experience\n",
    "\n",
    "2. **Use Resource Templates** to parameterize the writing profiles and easily add support for all the available profiles. [More here](https://gofastmcp.com/servers/resources#resource-templates).\n",
    "\n",
    "3. **Serve Brown through FastAPI**: Replace the MCP server with a FastAPI REST API for web-based integrations\n",
    "\n",
    "4. **Add Guideline Review Tool**: Create a workflow to review and edit your article guidelines themselves, helping you refine your inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Up Brown\n",
    "\n",
    "With this lesson, we've wrapped up our exploration of the Brown writing workflow. We've covered:\n",
    "\n",
    "- **Lesson 22**: Foundation of the writing workflow with entities, nodes, and basic workflows\n",
    "- **Lesson 23**: The evaluator-optimizer pattern with article reviews and iterative refinement\n",
    "- **Lesson 24**: Human-in-the-loop implementation with MCP server integration\n",
    "\n",
    "Together, these lessons show how to build a production-ready AI writing system that:\n",
    "- Generates high-quality articles from research and guidelines\n",
    "- Uses multiple review loops to ensure quality\n",
    "- Integrates human feedback for iterative refinement\n",
    "- Exposes capabilities through standard protocols like MCP\n",
    "- Maintains clean architecture for extensibility and maintainability\n",
    "\n",
    "In future lessons, we'll explore how to orchestrate Nova and Brown as a multi-agent system. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
