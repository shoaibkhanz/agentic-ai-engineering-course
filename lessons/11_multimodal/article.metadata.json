{
    "num_chars_article": 35206,
    "num_chars_conclusion": 547,
    "num_chars_introduction": 1743,
    "num_sections": 7,
    "num_words_article": 4472,
    "num_words_conclusion": 82,
    "num_words_introduction": 283,
    "sections": {
        "Why Traditional Document Processing Fails": {
            "num_chars": 2360,
            "num_words": 314
        },
        "How Multimodal LLMs Understand a Visual World": {
            "num_chars": 3792,
            "num_words": 493
        },
        "Hands-On: Working with Images and PDFs in Multimodal LLMs": {
            "num_chars": 6323,
            "num_words": 894
        },
        "Foundations of Multimodal Embedding Models": {
            "num_chars": 4040,
            "num_words": 497
        },
        "Advanced Multimodal RAG: The ColPali Architecture": {
            "num_chars": 3207,
            "num_words": 402
        },
        "Building a Simple Multimodal RAG System": {
            "num_chars": 4901,
            "num_words": 591
        },
        "Building Your First Multimodal AI Agent": {
            "num_chars": 4613,
            "num_words": 599
        }
    },
    "seo": {
        "title": "Multimodal AI: See, Hear, Act!",
        "description": "Unlock AI's full potential! Explore multimodal AI, going beyond text to process images, PDFs, and more. Learn about Multimodal LLMs, RAG, and building AI agents that truly see, hear, and act."
    }
}